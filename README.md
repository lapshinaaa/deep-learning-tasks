# Deep Learning Tasks Repository

Welcome to my Deep Learning Tasks repository! ğŸš€  
This repo contains a collection of completed deep learning exercises and experiments, implemented in Jupyter Notebooks (.ipynb). Each notebook explores a different aspect of deep learning â€” from fundamentals to advanced architectures.  

All tasks were completed as part of the *Deep Learning course (minor: Intellectual Data Analysis)* at HSE.  
Each notebook is self-contained; imports are provided inline, and main libraries are also listed in `requirements.txt`.  

---

## ğŸ“‚ Repository Structure  

â”œâ”€â”€ DL1_introductory_tasks.ipynb  
â”œâ”€â”€ DL2_image_classification.ipynb  
â”œâ”€â”€ DL3_time_series.ipynb  
â”œâ”€â”€ DL4_text_classification.ipynb  
â”œâ”€â”€ requirements.txt  
â””â”€â”€ README.md  

---

## ğŸ“‘ Task Overview  

| Notebook | Topic | Key Concepts | Notes |
|----------|-------|--------------|-------|
| `DL1_introductory_tasks.ipynb` | ğŸ”° Introduction to Deep Learning | PyTorch basics, tensors, autograd | Introductory exercises to get familiar with PyTorch and essential DL libraries. |
| `DL2_image_classification.ipynb` | ğŸŒ± Plant Species Classification | CNNs, custom architectures, optimization | Built and trained CNNs in PyTorch for image classification, experimented with model customization and training strategies. |
| `DL3_time_series.ipynb` | ğŸ“ˆ Time Series Forecasting | ETNA library, forecasting models, evaluation | Real-world case study: forecasting cash demand for ATMs. Used multi-segment daily data and ETNA toolkit to improve prediction quality â€” a critical task for financial institutions. |
| `DL4_text_classification.ipynb` | ğŸ“° News & Comment Classification | NLP, text classification, Hugging Face models | Trained models to classify news articles, predicted categories for unseen items, applied sentiment analysis with Hugging Face, and built analytics on most positive/negative news/comment categories. |

---

## âš™ï¸ Setup & Installation  

To run the notebooks locally, youâ€™ll need Python 3.8+ and the dependencies listed in `requirements.txt`.  

```bash
git clone https://github.com/yourusername/deep-learning-tasks.git
cd deep-learning-tasks
pip install -r requirements.txt
```

Or, open directly in Google Colab.  

---

## ğŸ§‘â€ğŸ’» Usage  

1. Launch Jupyter Notebook or Jupyter Lab:  

```bash
jupyter notebook
```

2. Open the notebook of interest (e.g., `DL1_introductory_tasks.ipynb`).  
3. Run cells step by step to explore code, results, and commentary.  

---

## ğŸ“Š Results & Visualizations  

Each notebook includes:  
 â€¢ Explanations of the approach  
 â€¢ Training/validation metrics (accuracy, loss curves)  
 â€¢ Key visualizations (e.g., confusion matrices, generated images)  
 â€¢ Reflections on results and limitations  

---

## ğŸ›  Dependencies  

Main libraries used across notebooks:  
 â€¢ [PyTorch](https://pytorch.org/)  
 â€¢ NumPy, Pandas  
 â€¢ Matplotlib, Seaborn  
 â€¢ scikit-learn  

See `requirements.txt` for the full list.  

---

## ğŸŒŸ Future Work  

Planned extensions:  
 â€¢ More tasks on NLP and transformers  
 â€¢ Advanced optimization and hyperparameter tuning experiments  
 â€¢ Applied case studies (healthcare, finance, etc.)  

---

## ğŸ“œ License  

This repository is released under the MIT License.  
Feel free to fork, explore, and build upon it!  

---

## ğŸ‘¤ Author  

Created by [Anastasiia Lapshina](https://github.com/lapshinaaa).  
Feel free to reach out via GitHub Issues if youâ€™d like to collaborate or discuss ideas.  
