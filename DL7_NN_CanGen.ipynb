{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lapshinaaa/deep-learning-tasks/blob/main/DL7_NN_CanGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWCQnbMRfjjQ"
      },
      "source": [
        "<h1><center>NN Approaches to CanGen in RecSys</center></h1>\n",
        "\n",
        "Author of the tasks: Vladimir Baikalov (Telegram: @noname_untitled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfXKc8fbfjjR"
      },
      "source": [
        "In this assignment, you will implement and study neural network models for the candidate generation task in recommender systems. Using the Yandex Music logs dataset [\"Yambda\"](https://huggingface.co/datasets/yandex/yambda), you will:\n",
        "\n",
        "1) Prepare data for training neural recommendation models  \n",
        "2) Implement SASRec â€” one of the most effective architectures for modeling user sequences  \n",
        "3) Experiment with different loss functions and analyze their impact on model quality and performance  \n",
        "4) Evaluate the results and draw conclusions about how the choice of loss function affects the final model quality  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olc1prCGfjjR"
      },
      "source": [
        "In this assignment, you are expected to independently implement the key stages of the training pipeline for candidate generation on sequential user data â€” from raw data preparation to metric computation on validation and test sets.\n",
        "\n",
        "In all code cells marked with `# TODO: your code here`, you need to write your own code implementing the corresponding stage of processing, filtering, mapping, dataset construction, or model components. This may include functions, filters, pipeline structures, class implementations, and methods.\n",
        "\n",
        "At the end of each subtask, you will encounter sanity checks â€” lightweight tests that provide basic validation of your solutions but are NOT exhaustive. Passing these checks does not guarantee full correctness, but they help quickly catch common mistakes and typos at early stages.\n",
        "\n",
        "Your task is to complete the entire pipeline â€” from raw data to trained models and final quality metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1F06lkjfjjR"
      },
      "source": [
        "# ğŸ”§ Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BHw4JjTfjjR"
      },
      "source": [
        "## ğŸ“¦ Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtyobnaKfjjR",
        "outputId": "c023c2f5-ca3a-47bf-c351-e429a882b851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==4.4.1\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (2.0.2)\n",
            "Collecting pyarrow>=21.0.0 (from datasets==4.4.1)\n",
            "  Downloading pyarrow-23.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (3.13.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets==4.4.1) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets==4.4.1) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets==4.4.1) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets==4.4.1) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets==4.4.1) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets==4.4.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets==4.4.1) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==4.4.1) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==4.4.1) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.4.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.4.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.4.1) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==4.4.1) (1.17.0)\n",
            "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-23.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed datasets-4.4.1 pyarrow-23.0.0\n",
            "Collecting polars==1.33.1\n",
            "  Downloading polars-1.33.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Downloading polars-1.33.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: polars\n",
            "  Attempting uninstall: polars\n",
            "    Found existing installation: polars 1.31.0\n",
            "    Uninstalling polars-1.31.0:\n",
            "      Successfully uninstalled polars-1.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-polars-cu12 25.10.0 requires polars<1.33,>=1.28, but you have polars 1.33.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed polars-1.33.1\n"
          ]
        }
      ],
      "source": [
        "# keep the versions\n",
        "!pip install datasets==4.4.1 -i https://pypi.org/simple\n",
        "!pip install polars==1.33.1 -i https://pypi.org/simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j0dQ5KafjjS"
      },
      "source": [
        "## ğŸ“š Library Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SbkKok0dfjjS"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import polars as pl\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAKFAslVfjjS"
      },
      "source": [
        "## âš™ï¸ Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VBLvaJ4byhXk"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(1337)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MXXnSQUzfjjS"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "HOUR_SECONDS = 60 * 60\n",
        "DAY_SECONDS = 24 * HOUR_SECONDS\n",
        "\n",
        "VAL_SIZE = 1 * DAY_SECONDS\n",
        "TEST_SIZE = 1 * DAY_SECONDS\n",
        "\n",
        "LAST_TIMESTAMP = 26000000\n",
        "TEST_TIMESTAMP = LAST_TIMESTAMP - TEST_SIZE\n",
        "\n",
        "# Model\n",
        "HASH_DIM = 64\n",
        "LEARNING_RATE = 1e-3\n",
        "TRAIN_BATCH_SIZE = 256\n",
        "VALID_BATCH_SIZE = 1024\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "EMBEDDING_DIM = 64\n",
        "NUM_HEADS = 2\n",
        "MAX_SEQ_LEN = 200\n",
        "MIN_SEQ_LEN = 2\n",
        "DROPOUT_RATE = 0.1\n",
        "NUM_TRANSFORMER_LAYERS = 2\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZlHMLqRfjjS"
      },
      "source": [
        "# ğŸ—‚ï¸ Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik2EZ_EkfjjS"
      },
      "source": [
        "## ğŸµ Dataset: Yandex Music Behavior (Yambda)\n",
        "\n",
        "The Yandex Music user behavior dataset contains real listening histories from a music streaming service, including detailed information about userâ€“track interactions. Each record represents a sequence of events for a user, capturing timestamps, track metadata, and engagement metrics.\n",
        "\n",
        "Data structure:\n",
        "- uid: unique user identifier  \n",
        "- item_id: sequence of track identifiers listened to by the user  \n",
        "- timestamp: event time in seconds since the Unix epoch  \n",
        "- played_ratio_pct: percentage of the track that was listened to (0â€“100%)  \n",
        "- is_organic: organic interaction flag (1 = user actively chose the track, 0 = recommendation)  \n",
        "- track_length_seconds: track duration in seconds  \n",
        "\n",
        "The dataset is well suited for evaluating sequential recommendation models due to its scale, chronological structure, and rich signals of real user behavior.\n",
        "\n",
        "---\n",
        "\n",
        "### Yambda dataset variants\n",
        "\n",
        "Yambda is available in multiple formats and sizes.\n",
        "\n",
        "Formats:\n",
        "- flat: raw event logs without grouping (each event is a separate row)  \n",
        "- sequence: pre-grouped user interaction sequences (ready-to-use histories)\n",
        "\n",
        "Sizes:\n",
        "- 50m: 50 million events (compact version for local experimentation)  \n",
        "- 500m: 500 million events (medium scale)  \n",
        "- 5b: 5 billion events (full dataset)\n",
        "\n",
        "In this work, we use the sequence format with size 50m for speed and resource accessibility. However, it is worth noting that on larger variants (500m and 5b), the advantages of neural approaches over classical methods become much more pronounced. Interested readers can explore this further in the [Yandex research paper](https://arxiv.org/abs/2505.22238)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TZN_kALfjjT"
      },
      "source": [
        "#### Func for sequential split into train/val/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9n-mLfydfjjT"
      },
      "outputs": [],
      "source": [
        "# Source: https://huggingface.co/datasets/yandex/yambda\n",
        "\n",
        "def sequential_split_train_val_test(\n",
        "    df: pl.LazyFrame,\n",
        "    test_timestamp: int,\n",
        "    val_size: int = 0,\n",
        "    gap_size: int = 0,\n",
        "    drop_non_train_items: bool = False,\n",
        "    engine: str = 'streaming',\n",
        ") -> tuple[pl.LazyFrame, pl.LazyFrame | None, pl.LazyFrame]:\n",
        "    \"\"\"\n",
        "    Splits the dataset into training, validation, and test segments based on the provided timestamps.\n",
        "\n",
        "    The segments are defined as follows:\n",
        "    - Training set: [0, test_timestamp - gap_size - val_size - gap_size) if val_size != 0,\n",
        "                    otherwise [0, test_timestamp - gap_size)\n",
        "    - Validation set: [test_timestamp - val_size - gap_size, test_timestamp - gap_size), if val_size != 0\n",
        "    - Test set: [test_timestamp, +inf)\n",
        "\n",
        "    It retains only those users and items in the validation and test sets that exist in the training set.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    df : LazyFrame\n",
        "        The dataset in Polars' LazyFrame format.\n",
        "    test_timestamp : int | None\n",
        "        The timestamp marking the start of the test set;\n",
        "    val_size : int | None\n",
        "        The size of validation. If 0, no validation set is created.\n",
        "    gap_size : int\n",
        "        The duration of gap between training and validation/test sets.\n",
        "    drop_non_train_items : bool\n",
        "        Whether to drop items that are not in the training set.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    tuple[LazyFrame, LazyFrame | None, LazyFrame]\n",
        "        A tuple containing LazyFrames for the training, validation (if applicable), and test sets.\n",
        "    \"\"\"\n",
        "\n",
        "    def drop(df: pl.LazyFrame, unique_train_item_ids) -> pl.LazyFrame:\n",
        "        if not drop_non_train_items:\n",
        "            return df\n",
        "\n",
        "        return df.select(\n",
        "            'uid',\n",
        "            pl.all()\n",
        "            .exclude('uid')\n",
        "            .list.gather(\n",
        "                pl.col('item_id').list.eval(\n",
        "                    pl.arg_where(pl.element().is_in(unique_train_item_ids.get_column('item_id').implode()))\n",
        "                )\n",
        "            ),\n",
        "        ).filter(pl.col('item_id').list.len() > 0)\n",
        "\n",
        "    train_timestamp = test_timestamp - gap_size - val_size - (gap_size if val_size != 0 else 0)\n",
        "\n",
        "    assert gap_size >= 0\n",
        "    assert val_size >= 0\n",
        "    assert train_timestamp > 0\n",
        "\n",
        "    df_lazy = df.lazy()\n",
        "\n",
        "    train = df_lazy.select(\n",
        "        'uid',\n",
        "        pl.all()\n",
        "        .exclude('uid')\n",
        "        .list.gather(pl.col('timestamp').list.eval(pl.arg_where(pl.element() < train_timestamp))),\n",
        "    ).filter(pl.col('item_id').list.len() > 0)\n",
        "\n",
        "    unique_train_uids = train.select('uid').unique().collect(engine=engine)\n",
        "    unique_train_item_ids = train.explode('item_id').select('item_id').unique().collect(engine=engine)\n",
        "\n",
        "    validation = None\n",
        "    if val_size != 0:\n",
        "        validation = (\n",
        "            df_lazy.select(\n",
        "                'uid',\n",
        "                pl.all()\n",
        "                .exclude('uid')\n",
        "                .list.gather(\n",
        "                    pl.col('timestamp').list.eval(\n",
        "                        pl.arg_where(\n",
        "                            (pl.element() >= test_timestamp - val_size - gap_size)\n",
        "                            & (pl.element() < test_timestamp - gap_size)\n",
        "                        )\n",
        "                    )\n",
        "                ),\n",
        "            )\n",
        "            .with_columns(\n",
        "                pl.col('uid').is_in(unique_train_uids.get_column('uid').implode()).alias('uid_in_train')\n",
        "            )  # to prevent filter reordering\n",
        "            .filter('uid_in_train')\n",
        "            .drop('uid_in_train')\n",
        "        )\n",
        "\n",
        "        validation = drop(validation, unique_train_item_ids).filter(pl.col('item_id').list.len() > 0)\n",
        "\n",
        "    test = (\n",
        "        df_lazy.select(\n",
        "            'uid',\n",
        "            pl.all()\n",
        "            .exclude('uid')\n",
        "            .list.gather(pl.col('timestamp').list.eval(pl.arg_where(pl.element() >= test_timestamp))),\n",
        "        )\n",
        "        #\n",
        "        .with_columns(\n",
        "            pl.col('uid').is_in(unique_train_uids.get_column('uid').implode()).alias('uid_in_train')\n",
        "        )  # to prevent filter reordering\n",
        "        .filter('uid_in_train')\n",
        "        .drop('uid_in_train')\n",
        "    )\n",
        "\n",
        "    test = drop(test, unique_train_item_ids).filter(pl.col('item_id').list.len() > 0)\n",
        "\n",
        "    return train, validation, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2osV0__OfjjT"
      },
      "source": [
        "## ğŸ” About data preprocessing for model training\n",
        "\n",
        "In modern recommender system research, a standardized data preprocessing pipeline is commonly used to ensure reproducibility of results. Many papers on recommender systems follow a well-established dataset preprocessing scheme:\n",
        " 1. Filtering rare entities\n",
        "\n",
        "Users and items (products / movies / etc.) with fewer interactions than a predefined threshold are removed. This reduces the sparsity of the interaction matrix and minimizes noise.\n",
        "For Amazon datasets, which are very popular in academia, a special notation such as â€œ5-coreâ€ is often used. However, for Yambda, we skip this step, since similar filtering has already been applied during dataset construction.\n",
        "\n",
        " 2. Data splitting strategies\n",
        "\n",
        "A common approach in the literature is leave-one-out (LOO) splitting (the last item is used for testing, the second-to-last for validation, and the rest for training).\n",
        "In this work, we instead use a time-based split, because LOO introduces data leakage â€” the model should not observe future events during training. Moreover, LOO poorly correlates with real-world production scenarios.\n",
        "\n",
        " 3. Training and evaluation process\n",
        "\n",
        "    â€¢ The training set is used to learn the model parameters.\n",
        "\n",
        "    â€¢ The validation set is used for hyperparameter tuning and early stopping.\n",
        "\n",
        "    â€¢ The test set is used to compute the final evaluation metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwwdsnwBfjjT"
      },
      "source": [
        "## ğŸ› ï¸ Task 1. Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQtfWFWIfjjT"
      },
      "source": [
        "1ï¸âƒ£ Download a dataset of user-track interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "a19f38e77ca343d8891603ba1371c27d",
            "7998c1d3b9314cf195a3b75aa04f8f65",
            "1241b01b94e1464695f519e5a399b4c1",
            "d24ddbda0a154d579652b340394c3f18",
            "b0e63cf89b66449f811dd2b91a0bea0a",
            "f12cc45275234b10a03e0ed04839dfbf",
            "c9a7e02e565f4bc486cc818f49b01906",
            "e626216099c740f6b0316eda58639e60",
            "f271932ca6604856bd6e01ae44384bc1",
            "b59a67ece2d34349a58bbd7b59cb1723",
            "9e0dc61a030b4f8e95ab05a581e45ece",
            "741b63b59b4e45bfb97ea85050cbbd51",
            "ee4bbb16e4a74c81ad93db2322cab9da",
            "2334192d66484be083cce210808553df",
            "3a5c4f4a9242445392f49c09adfa1efe",
            "3f03450e18b24d5b9757cc069aaa3240",
            "3f96f92842744c8cb891180fbfc4140c",
            "0ef6463ec67440e39fd1268b87cd5807",
            "89a4e953129646c79e44c68b21cb649c",
            "faf91d36d9c647d0a376951b849bf7a1",
            "7001ce47bbe04751b12d9ff05019bf99",
            "97778bf609df4aee87efd361cc3cd3d0",
            "b835109422f14b868bb52affb65e7cdc",
            "3f166891335d42c7b4d842dcaae0f730",
            "22f48b12a5c94d4f9daf6918d308434d",
            "46056633d40b4565b71c29acf779254e",
            "a6c5bccfa5a7407eb46b125f7fd932b7",
            "4c3b91d0190f423ebcdab728b8ee8868",
            "ad9b1ed288e64a41a88c57993a623fd8",
            "76ccde9ffa234c57bc0b0e755851b42d",
            "d28149e272474d04aa91138ba04659af",
            "d83a163030dc40e9a471356a618afe5a",
            "483b199c92fe4c23828f70dedae7112b"
          ]
        },
        "id": "viKiSaEKfjjT",
        "outputId": "d4a0342a-392d-4b02-9bed-c61c332de364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a19f38e77ca343d8891603ba1371c27d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sequential/50m/listens.parquet:   0%|          | 0.00/426M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "741b63b59b4e45bfb97ea85050cbbd51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b835109422f14b868bb52affb65e7cdc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "format = 'sequential'\n",
        "size = '50m'\n",
        "events = 'listens'\n",
        "\n",
        "# Load data from Hugging Face Hub\n",
        "listens_data = load_dataset('yandex/yambda', data_dir=f'{format}/{size}', data_files=f'{events}.parquet')\n",
        "\n",
        "# Convert into Polars DataFrame for further processing\n",
        "yambda_df = pl.from_arrow(listens_data['train'].data.table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNanksDRfjjT",
        "outputId": "9fe9e020-4283-4890-f464-7855f35cca89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_yambda_data_loading: OK\n"
          ]
        }
      ],
      "source": [
        "def test_yambda_data_loading():\n",
        "    assert isinstance(yambda_df, pl.DataFrame), 'yambda_df must be Polars DataFrame'\n",
        "    assert yambda_df.shape == (9238, 6), f'Wrong shape: {yambda_df.shape}'\n",
        "\n",
        "    expected_cols = {'uid', 'timestamp', 'item_id', 'is_organic', 'played_ratio_pct', 'track_length_seconds'}\n",
        "    assert set(yambda_df.columns) == expected_cols, f'Wrong columns: {yambda_df.columns}'\n",
        "\n",
        "    assert yambda_df['item_id'].dtype == pl.List(pl.UInt32), 'item_id must be List[UInt32]'\n",
        "    assert yambda_df['timestamp'].dtype == pl.List(pl.UInt32), 'timestamp must be List[UInt32]'\n",
        "\n",
        "    assert yambda_df['item_id'].list.len().min() > 0, 'Contains empty histories'\n",
        "\n",
        "    print('âœ… test_yambda_data_loading: OK')\n",
        "\n",
        "test_yambda_data_loading()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMbeUvWHfjjT"
      },
      "source": [
        "2ï¸âƒ£ Filter the dataset by applying the following conditions:\n",
        "\n",
        " â€¢ Keep only users whose user_id is divisible by 200.\n",
        "\n",
        " â€¢ Keep only events that were organically generated (i.e., explicitly chosen by the user, not recommended).\n",
        "\n",
        " â€¢ Keep only events where the track was listened to for more than 50% of its duration.\n",
        "\n",
        " â€¢ Remove user histories that become empty after filtering.\n",
        "\n",
        "This filtering step allows the model to train on higher-quality and more representative data, reducing noise from weak or accidental interactions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#yambda_df.head(5)"
      ],
      "metadata": {
        "id": "On4EQH1Gnt5k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # TODO: your code here\n",
        "list_cols = [\"timestamp\", \"item_id\", \"is_organic\", \"played_ratio_pct\", \"track_length_seconds\"]\n",
        "\n",
        "yambda_df = (\n",
        "    yambda_df\n",
        "    # keep only users divisible by 200\n",
        "    .filter((pl.col(\"uid\") % 200) == 0)\n",
        "\n",
        "    # explode lists into per-event rows (alignment is preserved across these columns)\n",
        "    .explode(list_cols)\n",
        "\n",
        "    # keep only organic events + listened > 50%\n",
        "    .filter(\n",
        "        (pl.col(\"is_organic\") == 0) &\n",
        "        (pl.col(\"played_ratio_pct\") >= 50)\n",
        "    )\n",
        "\n",
        "    # group events back into user sequences (lists)\n",
        "    .group_by(\"uid\", maintain_order=True)\n",
        "    .agg([\n",
        "        pl.col(\"timestamp\").alias(\"timestamp\"),\n",
        "        pl.col(\"item_id\").alias(\"item_id\"),\n",
        "        pl.col(\"is_organic\").alias(\"is_organic\"),\n",
        "        pl.col(\"played_ratio_pct\").alias(\"played_ratio_pct\"),\n",
        "        pl.col(\"track_length_seconds\").alias(\"track_length_seconds\"),\n",
        "    ])\n",
        "\n",
        "    # drop users with empty histories (after filtering)\n",
        "    .filter(pl.col(\"item_id\").list.len() > 0)\n",
        "    .select([\"uid\", \"timestamp\", \"item_id\"])\n",
        ")"
      ],
      "metadata": {
        "id": "-PawLib2oaP9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#yambda_df = yambda_df.select([\"uid\", \"timestamp\", \"item_id\"])"
      ],
      "metadata": {
        "id": "CTPRUgV3wh9e"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_lengths = yambda_df['item_id'].list.len()"
      ],
      "metadata": {
        "id": "pEEvkkNytuhI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_lengths.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XG2APS5tvb9",
        "outputId": "bfcc8f46-bff0-4f2a-8d0a-cb474278f82d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7587469"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HTturbHfjjU",
        "outputId": "1f8b5264-f4df-4ff8-b070-c11a9f5af760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_yambda_filtering: OK\n"
          ]
        }
      ],
      "source": [
        "def test_yambda_filtering():\n",
        "    assert yambda_df.shape[0] == 4289, \\\n",
        "        f'Wrong number of users: {yambda_df.shape[0]}'\n",
        "\n",
        "    expected_columns = {'uid', 'timestamp', 'item_id'}\n",
        "    actual_columns = set(yambda_df.columns)\n",
        "    assert actual_columns == expected_columns, \\\n",
        "        f'Wrong columns. Expected: {expected_columns}, got: {actual_columns}'\n",
        "\n",
        "    assert yambda_df['timestamp'].dtype == pl.List(pl.UInt32), \\\n",
        "        f\"timestamp mist be List[UInt32], received: {yambda_df['timestamp'].dtype}\"\n",
        "    assert yambda_df['item_id'].dtype == pl.List(pl.UInt32), \\\n",
        "        f\"item_id muste be List[UInt32], received: {yambda_df['item_id'].dtype}\"\n",
        "\n",
        "    seq_lengths = yambda_df['item_id'].list.len()\n",
        "    assert seq_lengths.min() >= 1, \\\n",
        "        f'Minimum length of sequence must be >= 1, got: {seq_lengths.min()}'\n",
        "    assert seq_lengths.sum() == 7587469, \\\n",
        "        f'Overall number of events is wrong. Expected: 7587469, got: {seq_lengths.sum()}'\n",
        "\n",
        "    unique_items = yambda_df.select('item_id').explode('item_id').unique().shape[0]\n",
        "    assert unique_items == 304787, \\\n",
        "        f'The number of unique items is wrong. Expected: 304787, got: {unique_items}'\n",
        "\n",
        "    print('âœ… test_yambda_filtering: OK')\n",
        "\n",
        "test_yambda_filtering()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKFs6KQRfjjU"
      },
      "source": [
        "3ï¸âƒ£ Task: Remap Track IDs to a Dense Range\n",
        "\n",
        "Extract all unique track IDs from the dataset and create a mapping  \n",
        "old_id â†’ new_id, where new_id âˆˆ `{0, â€¦, Nâˆ’1}`.\n",
        "\n",
        "Deep learning models require categorical features (such as item / track IDs)\n",
        "to be represented as contiguous integer indices starting from 0.\n",
        "This is especially important for embedding layers, which assume indices\n",
        "in the range` [0, num_embeddings - 1]`.\n",
        "\n",
        "The Yambda dataset contains original track IDs that are sparse and non-contiguous\n",
        "(e.g. `[7, 100, 5000, 12000, â€¦]`), which is inefficient and incompatible with\n",
        "embedding tables.\n",
        "\n",
        "Therefore, we:\n",
        "1. Collect all unique track IDs from the dataset\n",
        "2. Build a mapping from original IDs to new compact IDs\n",
        "3. Replace original IDs in user sequences using this mapping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items = (\n",
        "    yambda_df\n",
        "    .select(\"item_id\")\n",
        "    .explode(\"item_id\")\n",
        "    .get_column(\"item_id\")\n",
        "    .unique()\n",
        "    .sort()\n",
        ")"
      ],
      "metadata": {
        "id": "AwLNuuRtMczO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#items.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "DBEmCl9WNDzD",
        "outputId": "62b6fd0e-f6b6-4a30-e549-4b8aea6dca2a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (2,)\n",
              "Series: 'item_id' [u32]\n",
              "[\n",
              "\t50\n",
              "\t175\n",
              "]"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (2,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>item_id</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>50</td></tr><tr><td>175</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unique_items as a dataframe with shape (N, 2) to pass assert statements below\n",
        "unique_items = pl.DataFrame({\n",
        "    \"new_item_id\": pl.arange(0, len(items), eager=True, dtype=pl.UInt32),\n",
        "    \"item_id\": items,\n",
        "})"
      ],
      "metadata": {
        "id": "gR8H_5t5NIjq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_items.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "lSZ8kHW9Kjy8",
        "outputId": "cb41f737-73eb-44c9-8c85-a1b107b50680"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (3, 2)\n",
              "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
              "â”‚ new_item_id â”† item_id â”‚\n",
              "â”‚ ---         â”† ---     â”‚\n",
              "â”‚ u32         â”† u32     â”‚\n",
              "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•¡\n",
              "â”‚ 0           â”† 50      â”‚\n",
              "â”‚ 1           â”† 175     â”‚\n",
              "â”‚ 2           â”† 195     â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>new_item_id</th><th>item_id</th></tr><tr><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>50</td></tr><tr><td>1</td><td>175</td></tr><tr><td>2</td><td>195</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# item_mapping: dict old_id -> new_id\n",
        "item_mapping = dict(zip(unique_items[\"item_id\"].to_list(),\n",
        "                        unique_items[\"new_item_id\"].to_list()))"
      ],
      "metadata": {
        "id": "DYFBGRg6Kf57"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yambda_df = yambda_df.with_columns([\n",
        "    pl.col('item_id')\n",
        "        .map_elements(\n",
        "            lambda items: [item_mapping[item] for item in items],\n",
        "            return_dtype=pl.List(pl.UInt32)\n",
        "        )\n",
        "        .alias('item_id')\n",
        "])"
      ],
      "metadata": {
        "id": "7omNNNoZIVdo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_mapping[50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuqDJOTbLDqu",
        "outputId": "69170510-78bc-4d83-bcf6-f491d5c9a232"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MltQKQ8cfjjU",
        "outputId": "4a86da6e-64c9-4b8f-acc9-0ebe0651e60e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_item_mapping: OK\n"
          ]
        }
      ],
      "source": [
        "def test_item_mapping():\n",
        "    assert unique_items.shape == (304787, 2), f'Wrong size of unique_items: {unique_items.shape}'\n",
        "    assert set(unique_items.columns) == {'new_item_id', 'item_id'}, 'Wrong columns unique_items'\n",
        "\n",
        "    assert len(item_mapping) == 304787, f'Wrong size of item_mapping: {len(item_mapping)}'\n",
        "    assert item_mapping[50] == 0 and item_mapping[175] == 1 and item_mapping[195] == 2, \\\n",
        "        'Wrong first mappings'\n",
        "\n",
        "    new_ids = unique_items['new_item_id']\n",
        "    assert new_ids.min() == 0 and new_ids.max() == 304786, 'new_item_id must be in range [0, 304786]'\n",
        "\n",
        "    all_ids = yambda_df.select('item_id').explode('item_id')['item_id']\n",
        "    assert all_ids.min() == 0 and all_ids.max() == 304786, 'item_id in yambda_df not updated'\n",
        "    assert all_ids.n_unique() == 304787, 'Unique number of item_id has changed'\n",
        "\n",
        "    print('âœ… test_item_mapping: OK')\n",
        "\n",
        "test_item_mapping()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHnmCq7XfjjU"
      },
      "source": [
        "4ï¸âƒ£ Sequential Train / Validation / Test Split (Time-based)\n",
        "\n",
        "Split each userâ€™s listening history into three non-overlapping time periods:\n",
        "\n",
        "- Validation and test must each contain exactly one day of events.\n",
        "- Training must contain all earlier events (everything before validation and test).\n",
        "- There must be no gaps between the periods â€” the time windows must be adjacent (go â€œback-to-backâ€).\n",
        "\n",
        "This split is time-based to avoid data leakage: the model should not train on events that occur in the future relative to validation/test."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_ts = (\n",
        "    yambda_df\n",
        "    .select(pl.col(\"timestamp\").explode().max().alias(\"max_ts\"))\n",
        "    .item()\n",
        ")  # calculating the max timestamp in seconds"
      ],
      "metadata": {
        "id": "k5DDbkLKPnsW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#max_ts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iUGCTF2QNjV",
        "outputId": "56809cb6-4f5e-413d-d4a9-e4ce4cc2a4a4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25999985"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_timestamp = max_ts - DAY_SECONDS\n",
        "val_size = DAY_SECONDS - 1"
      ],
      "metadata": {
        "id": "4r4duoimPtZB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BDS06D6vfjjU"
      },
      "outputs": [],
      "source": [
        "train_events_df, valid_events_df, eval_events_df = sequential_split_train_val_test(df=yambda_df, test_timestamp=test_timestamp, val_size=val_size)  # TODO: your code here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert into DF because it doesnt pass asserts otherwise\n",
        "train_events_df = train_events_df.collect()\n",
        "valid_events_df = valid_events_df.collect()\n",
        "eval_events_df  = eval_events_df.collect()"
      ],
      "metadata": {
        "id": "WqEiU1p-QxvT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_events_df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DPsLS3ZRD0U",
        "outputId": "8617f45b-375b-4e55-f5ec-5ed845fc56ef"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4284"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_events_df.select(pl.col('item_id').list.len()).sum().item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK1Slt2ARe9c",
        "outputId": "85d842d6-9cd0-4696-9a71-2f1afe664faf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35933"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13X5uop0fjjU",
        "outputId": "4389cd9f-34f8-459a-d791-3ad7bb5c6ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_yambda_train_val_test_split: OK\n"
          ]
        }
      ],
      "source": [
        "def test_yambda_train_val_test_split():\n",
        "    assert train_events_df.shape[0] == (4284), \\\n",
        "        f'Wrong number of users: {train_events_df.shape[0]}'\n",
        "    assert valid_events_df.shape[0] == (1356), \\\n",
        "        f'Wrong number of users: {valid_events_df.shape[0]}'\n",
        "    assert eval_events_df.shape[0] == (1407), \\\n",
        "        f'Wrong number of users: {eval_events_df.shape[0]}'\n",
        "\n",
        "    assert isinstance(train_events_df, pl.DataFrame), 'Incorrect type'\n",
        "    assert isinstance(valid_events_df, pl.DataFrame), 'Incorrect type'\n",
        "    assert isinstance(eval_events_df, pl.DataFrame), 'Incorrect type'\n",
        "\n",
        "    assert train_events_df.select(pl.col('item_id').list.len()).sum().item() == 7510554, \\\n",
        "        'Wrong number of events in train'\n",
        "    assert valid_events_df.select(pl.col('item_id').list.len()).sum().item() == 35933, \\\n",
        "        'Wrong number of events in val'\n",
        "    assert eval_events_df.select(pl.col('item_id').list.len()).sum().item() == 40961, \\\n",
        "        'Wrong number of events in test'\n",
        "\n",
        "    print('âœ… test_yambda_train_val_test_split: OK')\n",
        "\n",
        "test_yambda_train_val_test_split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGwbwJmvfjjU"
      },
      "source": [
        "5ï¸âƒ£ Merge train/val/test splits by user\n",
        "\n",
        "Combine the three split datasets (`train / val / test`) into a single table by users (`uid`).\n",
        "\n",
        "The resulting table should contain, for each user, their listening history from all three stages:\n",
        "- training history\n",
        "- validation history\n",
        "- test history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#max(list(map(len, joined_events_df['item_id'].to_list())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChVuCIpnanp4",
        "outputId": "c3ac4b96-ae29-4407-dc04-fe2673f91a1a"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26010"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_events_df = (\n",
        "    train_events_df\n",
        "    .join(valid_events_df, on=\"uid\", how=\"left\", suffix=\"_val\")\n",
        "    .join(eval_events_df,  on=\"uid\", how=\"left\", suffix=\"_test\")\n",
        "    .select([\n",
        "        \"uid\",\n",
        "        \"item_id\", \"timestamp\",                      # train\n",
        "        pl.col(\"item_id_val\"), pl.col(\"timestamp_val\"),  # val\n",
        "        pl.col(\"item_id_test\"), pl.col(\"timestamp_test\") # test\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "ixp3cNGcbuSQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joined_events_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "wPVl-zUlciUG",
        "outputId": "40f55683-9e3a-489f-df24-f5f71c46ffb6"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (2, 7)\n",
              "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
              "â”‚ uid â”† item_id   â”† timestamp  â”† item_id_val â”† timestamp_val   â”† item_id_test    â”† timestamp_test  â”‚\n",
              "â”‚ --- â”† ---       â”† ---        â”† ---         â”† ---             â”† ---             â”† ---             â”‚\n",
              "â”‚ u32 â”† list[u32] â”† list[u32]  â”† list[u32]   â”† list[u32]       â”† list[u32]       â”† list[u32]       â”‚\n",
              "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
              "â”‚ 600 â”† [262291,  â”† [1329190,  â”† [257175,    â”† [25852420,      â”† [14322, 194515, â”† [25939985,      â”‚\n",
              "â”‚     â”† 60566, â€¦  â”† 1329405, â€¦ â”† 195370, â€¦   â”† 25852635, â€¦     â”† â€¦ 210156]       â”† 25940245, â€¦     â”‚\n",
              "â”‚     â”† 215130]   â”† 25819590]  â”† 285767]     â”† 2590215â€¦        â”†                 â”† 2599754â€¦        â”‚\n",
              "â”‚ 800 â”† [21707,   â”† [121100,   â”† null        â”† null            â”† [112823, 28553, â”† [25975185,      â”‚\n",
              "â”‚     â”† 206290, â€¦ â”† 121290, â€¦  â”†             â”†                 â”† â€¦ 62936]        â”† 25975410, â€¦     â”‚\n",
              "â”‚     â”† 192318]   â”† 25805770]  â”†             â”†                 â”†                 â”† 2597731â€¦        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>uid</th><th>item_id</th><th>timestamp</th><th>item_id_val</th><th>timestamp_val</th><th>item_id_test</th><th>timestamp_test</th></tr><tr><td>u32</td><td>list[u32]</td><td>list[u32]</td><td>list[u32]</td><td>list[u32]</td><td>list[u32]</td><td>list[u32]</td></tr></thead><tbody><tr><td>600</td><td>[262291, 60566, â€¦ 215130]</td><td>[1329190, 1329405, â€¦ 25819590]</td><td>[257175, 195370, â€¦ 285767]</td><td>[25852420, 25852635, â€¦ 25902150]</td><td>[14322, 194515, â€¦ 210156]</td><td>[25939985, 25940245, â€¦ 25997540]</td></tr><tr><td>800</td><td>[21707, 206290, â€¦ 192318]</td><td>[121100, 121290, â€¦ 25805770]</td><td>null</td><td>null</td><td>[112823, 28553, â€¦ 62936]</td><td>[25975185, 25975410, â€¦ 25977310]</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaQgBvssfjjU",
        "outputId": "1dc2014a-9b9d-49c9-9dcb-1996e24c22f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_yambda_all_join: OK\n"
          ]
        }
      ],
      "source": [
        "def test_yambda_all_join():\n",
        "    assert joined_events_df.shape[0] == 4284, \\\n",
        "        f'Wrong number of users: {joined_events_df.shape[0]}'\n",
        "\n",
        "    assert min(list(map(len, joined_events_df['item_id'].to_list()))) == 1\n",
        "    assert max(list(map(len, joined_events_df['item_id'].to_list()))) == 25643\n",
        "\n",
        "    print('âœ… test_yambda_all_join: OK')\n",
        "\n",
        "test_yambda_all_join()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_events_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWqjUDk7VgBj",
        "outputId": "8933f741-6cc5-47da-fb4f-f2c2ad2e1da8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['uid',\n",
              " 'item_id',\n",
              " 'timestamp',\n",
              " 'item_id_val',\n",
              " 'timestamp_val',\n",
              " 'item_id_test',\n",
              " 'timestamp_test']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHBKhHb6fjjU"
      },
      "source": [
        "6ï¸âƒ£ **Building Train, Validation, and Test Datasets**\n",
        "\n",
        "Construct training, validation, and test datasets for sequential recommendation.\n",
        "\n",
        "Training set\n",
        "- Keep only users whose interaction histories contain at least `MIN_SEQ_LEN` events.\n",
        "- These sequences will be used to train the model.\n",
        "\n",
        "Validation set\n",
        "- Create *incremental sequences* for each user from the validation period.\n",
        "- For every user, generate multiple samples where:\n",
        "  - The history consists of all training events for the user\n",
        "  - Plus progressively more validation events:\n",
        "    - train + vâ‚\n",
        "    - train + vâ‚, vâ‚‚\n",
        "    - train + vâ‚, vâ‚‚, vâ‚ƒ\n",
        "    - ...\n",
        "- This setup evaluates how well the model predicts the *next item* as user history grows.\n",
        "\n",
        "Test set\n",
        "- Construct incremental sequences similarly to validation, but:\n",
        "  - Start with full train + full validation history\n",
        "  - Incrementally add test events:\n",
        "    - train + valid + tâ‚\n",
        "    - train + valid + tâ‚, tâ‚‚\n",
        "    - ...\n",
        "- This reflects the real production scenario: predicting future user actions given all past behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VkiHBdKdfjjU"
      },
      "outputs": [],
      "source": [
        "train_data = (\n",
        "    joined_events_df\n",
        "    .select([\"uid\", \"timestamp\", \"item_id\"])\n",
        "    .filter(pl.col(\"item_id\").list.len() >= MIN_SEQ_LEN)\n",
        ") # TODO: your code here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLvo72H9XDhz",
        "outputId": "41555813-fe67-48c5-93ba-c34a86c9895d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['uid', 'item_id', 'timestamp']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSppjCNkfjjU",
        "outputId": "854cb00b-a556-41a6-fb08-849d1f015ee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_train_data: OK\n"
          ]
        }
      ],
      "source": [
        "def test_train_data():\n",
        "    assert train_data.shape == (4228, 3), f'Wrong shape: {train_data.shape}'\n",
        "    assert train_data.columns == ['uid', 'item_id', 'timestamp'], 'Wrong columns'\n",
        "\n",
        "    assert train_data['item_id'].list.len().min() >= MIN_SEQ_LEN, \\\n",
        "        'Sequences shorter than MIN_SEQ_LEN are present'\n",
        "\n",
        "    assert train_data['item_id'].list.len().sum() == 7510498, 'Wrong number of events'\n",
        "\n",
        "    assert train_data['uid'].head(5).to_list() == [600, 800, 1000, 1400, 1600], 'Wrong first uid'\n",
        "\n",
        "    print('âœ… test_train_data: OK')\n",
        "\n",
        "test_train_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#valid_events_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gVYbRvAalXA",
        "outputId": "58b85a73-e716-4c10-9ef2-8eaf0078556c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1356, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "z1pZSBDofjjU"
      },
      "outputs": [],
      "source": [
        "valid_data = (\n",
        "    train_data\n",
        "    .join(\n",
        "        valid_events_df.select([\"uid\", \"item_id\", \"timestamp\"]).rename({\n",
        "            \"item_id\": \"item_id_val\",\n",
        "            \"timestamp\": \"timestamp_val\",\n",
        "        }),\n",
        "        on=\"uid\",\n",
        "        how=\"inner\"\n",
        "    )\n",
        "    .with_columns(\n",
        "        pl.col(\"item_id_val\").list.len().alias(\"val_len\")\n",
        "    )\n",
        "    .with_columns(\n",
        "        pl.int_ranges(1, pl.col(\"val_len\") + 1).alias(\"prefix_len\")\n",
        "    )\n",
        "    .explode(\"prefix_len\")\n",
        "    .with_columns([\n",
        "        pl.concat_list([\n",
        "            pl.col(\"item_id\"),\n",
        "            pl.col(\"item_id_val\").list.slice(0, pl.col(\"prefix_len\"))\n",
        "        ]).alias(\"item_id\"),\n",
        "        pl.concat_list([\n",
        "            pl.col(\"timestamp\"),\n",
        "            pl.col(\"timestamp_val\").list.slice(0, pl.col(\"prefix_len\"))\n",
        "        ]).alias(\"timestamp\"),\n",
        "    ])\n",
        "    .select([\"uid\", \"timestamp\", \"item_id\"])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_ujdnNGfjjV",
        "outputId": "abd9cb67-744a-484e-d1ef-37d8f4354724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_valid_data: OK\n"
          ]
        }
      ],
      "source": [
        "def test_valid_data():\n",
        "    assert valid_data.shape == (35933, 3), f'Wrong shape: {valid_data.shape}'\n",
        "    assert valid_data.columns == ['uid', 'timestamp', 'item_id'], 'Wrong columns'\n",
        "\n",
        "    assert valid_data['item_id'].list.len().min() >= MIN_SEQ_LEN, \\\n",
        "        'Sequences shorter than MIN_SEQ_LEN are present'\n",
        "\n",
        "    assert valid_data['item_id'].list.len().sum() == 195225055, 'Wrong number of events'\n",
        "    assert valid_data['uid'].head(5).to_list() == [600, 600, 600, 600, 600], 'Wrong first uid'\n",
        "\n",
        "    first_user_lens = valid_data.filter(pl.col('uid') == 100)['item_id'].list.len().to_list()[:5]\n",
        "    assert first_user_lens == sorted(first_user_lens), 'Lengths must be increasing incrementally'\n",
        "\n",
        "    print('âœ… test_valid_data: OK')\n",
        "\n",
        "test_valid_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "TZtGyiqcfjjV"
      },
      "outputs": [],
      "source": [
        "base_train = joined_events_df.select([\"uid\", \"timestamp\", \"item_id\"])  # NO MIN_SEQ_LEN filter here\n",
        "\n",
        "eval_data = (\n",
        "    base_train\n",
        "    .join(\n",
        "        valid_events_df.select([\"uid\", \"item_id\", \"timestamp\"]).rename({\n",
        "            \"item_id\": \"item_id_val\",\n",
        "            \"timestamp\": \"timestamp_val\",\n",
        "        }),\n",
        "        on=\"uid\",\n",
        "        how=\"left\"\n",
        "    )\n",
        "    .with_columns([\n",
        "        pl.col(\"item_id_val\").fill_null(pl.lit([], dtype=pl.List(pl.UInt32))),\n",
        "        pl.col(\"timestamp_val\").fill_null(pl.lit([], dtype=pl.List(pl.UInt32))),\n",
        "    ])\n",
        "    .join(\n",
        "        eval_events_df.select([\"uid\", \"item_id\", \"timestamp\"]).rename({\n",
        "            \"item_id\": \"item_id_test\",\n",
        "            \"timestamp\": \"timestamp_test\",\n",
        "        }),\n",
        "        on=\"uid\",\n",
        "        how=\"inner\"\n",
        "    )\n",
        "    .with_columns(pl.col(\"item_id_test\").list.len().alias(\"test_len\"))\n",
        "    .with_columns(pl.int_ranges(1, pl.col(\"test_len\") + 1).alias(\"prefix_len\"))\n",
        "    .explode(\"prefix_len\")\n",
        "    .with_columns([\n",
        "        pl.concat_list([\n",
        "            pl.col(\"item_id\"),\n",
        "            pl.col(\"item_id_val\"),\n",
        "            pl.col(\"item_id_test\").list.slice(0, pl.col(\"prefix_len\")),\n",
        "        ]).alias(\"item_id\"),\n",
        "        pl.concat_list([\n",
        "            pl.col(\"timestamp\"),\n",
        "            pl.col(\"timestamp_val\"),\n",
        "            pl.col(\"timestamp_test\").list.slice(0, pl.col(\"prefix_len\")),\n",
        "        ]).alias(\"timestamp\"),\n",
        "    ])\n",
        "    .select([\"uid\", \"timestamp\", \"item_id\"])\n",
        "    # NOW enforcing MIN_SEQ_LEN\n",
        "    .filter(pl.col(\"item_id\").list.len() >= MIN_SEQ_LEN)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eCGOhRBfjjV",
        "outputId": "b9fa6808-18fb-48b6-e1b7-c3b431f101ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_eval_data: OK\n"
          ]
        }
      ],
      "source": [
        "def test_eval_data():\n",
        "    assert eval_data.shape == (40961, 3), f'Wrong shape: {eval_data.shape}'\n",
        "    assert eval_data.columns == ['uid', 'timestamp', 'item_id'], 'Wrong columns'\n",
        "\n",
        "    assert eval_data['item_id'].list.len().min() >= MIN_SEQ_LEN, \\\n",
        "        'Sequences shorter than MIN_SEQ_LEN are present'\n",
        "\n",
        "    assert eval_data['item_id'].list.len().sum() == 212124968, 'Long number of events'\n",
        "    assert eval_data['uid'].head(5).to_list() == [600, 600, 600, 600, 600], 'Wrong first uid'\n",
        "\n",
        "    first_user_lens = eval_data.filter(pl.col('uid') == 100)['item_id'].list.len().head(5).to_list()\n",
        "    assert first_user_lens == sorted(first_user_lens), 'Lengths must be increasing incrementally'\n",
        "\n",
        "    assert eval_data['item_id'].list.len().sum() > valid_data['item_id'].list.len().sum(), \\\n",
        "        'eval_data must be bigger than valid_data'\n",
        "\n",
        "    print('âœ… test_eval_data: OK')\n",
        "\n",
        "test_eval_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8oyiPe0fjjV"
      },
      "source": [
        "Samples that we will be passing to a model have the following structure:\n",
        "\n",
        "- `history`\n",
        "    - `item_id` (user's interactions from their history)\n",
        "    - `lengths` (number of interactions in user's history)\n",
        "    - `positions` (numbers of positions in reverse order)\n",
        "- `labels`\n",
        "    - `item_id` (positives that the model must predict, a.k.a. next interaction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kfhnDEDfjjV"
      },
      "source": [
        "7ï¸âƒ£ Implement the `YambdaDataset` class, which transforms prepared user interaction histories into a format suitable for training neural network models.\n",
        "\n",
        "Requirements:\n",
        "\n",
        " â€¢ In the `__len__` method: return the number of samples in the dataset.\n",
        "\n",
        " â€¢ In the `__getitem__` method: given an index, retrieve a sample and return a dictionary with two keys:\n",
        "\n",
        " â€¢ `history` â€” a dictionary representing the context (what the model sees):\n",
        "\n",
        " â€¢ `item_id` â€” a sequence of track IDs excluding the last event from the original history\n",
        "\n",
        " â€¢ `lengths` â€” the length of this sequence\n",
        "\n",
        " â€¢ `positions` â€” ordinal indices of events (from 0 to length - 1)\n",
        "\n",
        " â€¢ `labels` â€” a dictionary representing the targets (what the model should predict):\n",
        "\n",
        " â€¢ `item_id` â€” a sequence of target track IDs excluding the first event from the original history\n",
        "\n",
        " â€¢ Truncate both` history['item_id']` and `labels['item_id'] `to max_seq_len, keeping the most recent events, since they best reflect the userâ€™s current interests.\n",
        "\n",
        "The shift between history/item_id and labels/item_id creates (context â†’ target) pairs required for autoregressive training.\n",
        "Each event in the history corresponds to a target (the next item), enabling the model to learn how to predict the next track based on previous interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0wQcZmkfjjV"
      },
      "outputs": [],
      "source": [
        "class YambdaDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset for sequential user interaction histories.\n",
        "\n",
        "    Transforms user listening sequences into format suitable for training autoregressive\n",
        "    recommendation models. Creates (history, target) pairs where the target is shifted\n",
        "    by one event forward relative to the history.\n",
        "\n",
        "    For each user:\n",
        "    - history: events [0:-1] (all except last)\n",
        "    - labels: events [1:] (all except first)\n",
        "\n",
        "    This enables the model to learn predicting the next track based on previous events\n",
        "    in the user's history.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe : pl.DataFrame\n",
        "        DataFrame with columns 'uid', 'timestamp', 'item_id', where item_id\n",
        "        contains sequences (lists) of user interaction events.\n",
        "    max_seq_len : int\n",
        "        Maximum sequence length. Histories are truncated keeping the last\n",
        "        (most recent) events.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, Dict[str, Any]]\n",
        "        Dictionary with keys 'history' and 'labels':\n",
        "        - history['item_id']: list of track IDs\n",
        "        - history['lengths']: sequence length\n",
        "        - history['positions']: ordinal numbers [0, 1, ..., len-1]\n",
        "        - labels['item_id']: list of target IDs (targets)\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> dataset = YambdaDataset(train_data, max_seq_len=200)\n",
        "    >>> sample = dataset[0]\n",
        "    >>> sample['history']['item_id']  # [track_id_1, track_id_2, track_id_3, ...]\n",
        "    >>> sample['labels']['item_id']   # [track_id_2, track_id_3, track_id_4, ...]\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            dataframe: pl.DataFrame,\n",
        "            max_seq_len: int,\n",
        "        ) -> None:\n",
        "        super().__init__()\n",
        "        # TODO: your code here\n",
        "        self.dataframe = dataframe\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns the number of samples in the dataset.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        int\n",
        "            Number of rows in the DataFrame.\n",
        "        \"\"\"\n",
        "        # TODO: your code here\n",
        "        return self.dataframe.height\n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict[str, List[int]]:\n",
        "        \"\"\"\n",
        "        Retrieves a sample by index and transforms it into format for training.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        index : int\n",
        "            Index of the sample in the dataset.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict[str, Dict[str, Any]]\n",
        "            Dictionary with 'history' (context) and 'labels' (targets).\n",
        "            History is truncated to max_seq_len, keeping last events.\n",
        "        \"\"\"\n",
        "        # TODO: your code here\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZWn6SDFfjjV"
      },
      "outputs": [],
      "source": [
        "def test_yambda_dataset():\n",
        "    max_seq_len = 20\n",
        "    dataset = YambdaDataset(train_data, max_seq_len=max_seq_len)\n",
        "\n",
        "    assert len(dataset) == train_data.shape[0], \\\n",
        "        f'Wrong length of dataset. Expected: {train_data.shape[0]}, received: {len(dataset)}'\n",
        "\n",
        "    sample = dataset[0]\n",
        "    assert isinstance(sample, dict), 'Sample must be a dictionary'\n",
        "    assert 'history' in sample and 'labels' in sample, \"Keys 'history' and 'labels' are required\"\n",
        "\n",
        "    hist = sample['history']\n",
        "    assert 'item_id' in hist and 'lengths' in hist and 'positions' in hist, \"Missing keys in 'history'\"\n",
        "    assert isinstance(hist['item_id'], list), \"'history/item_id' must be of list type\"\n",
        "    assert isinstance(hist['positions'], list), \"'history/positions' must be of list type\"\n",
        "    assert isinstance(hist['lengths'], int), \"'history/lengths' must be int\"\n",
        "    assert len(hist['positions']) == hist['lengths'] == len(hist['item_id']), 'Length of positions sand histories dont match'\n",
        "    assert hist['lengths'] <= max_seq_len, 'Length of history exceeds max_seq_len'\n",
        "\n",
        "    labels = sample['labels']\n",
        "    assert 'item_id' in labels, \"'labels' must contain'item_id'\"\n",
        "    assert isinstance(labels['item_id'], list), \"'labels/item_id' must be of list type\"\n",
        "    assert len(labels['item_id']) == hist['lengths'], 'Len of history Ğ¸ labels do not match'\n",
        "\n",
        "    row_item_id = train_data['item_id'][0]\n",
        "    if len(row_item_id) > max_seq_len:\n",
        "        row_item_id = row_item_id[-(max_seq_len+1):]\n",
        "    expected_history = row_item_id[:-1]\n",
        "    expected_labels = row_item_id[1:]\n",
        "    assert tuple(hist['item_id']) == tuple(expected_history), f\"Wrong history! {hist['item_id']} vs {expected_history}\"\n",
        "    assert tuple(labels['item_id']) == tuple(expected_labels), f\"Wrong targets! {labels['item_id']} vs {expected_labels}\"\n",
        "\n",
        "    print('âœ… test_yambda_dataset: OK')\n",
        "\n",
        "test_yambda_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8mF58JTfjjV"
      },
      "source": [
        "8ï¸âƒ£ Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞ¹Ñ‚Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ `collate_fn`, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ² Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ°Ñ‚Ñ‡Ğ° ÑĞµĞ¼Ğ¿Ğ»Ğ¾Ğ² Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚, ÑƒĞ´Ğ¾Ğ±Ğ½Ñ‹Ğ¹ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ¸ Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ.\n",
        "\n",
        "Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ°:\n",
        "- ĞŸÑ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº ÑĞ»Ğ¾Ğ²Ğ°Ñ€ĞµĞ¹ (Ğ±Ğ°Ñ‚Ñ‡ ÑĞµĞ¼Ğ¿Ğ»Ğ¾Ğ² Ğ¸Ğ· `YambdaDataset`)\n",
        "- ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ²ÑĞµ ÑĞ¿Ğ¸ÑĞºĞ¸ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ĞµĞ´Ğ¸Ğ½Ñ‹Ğ¹ PyTorch Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€\n",
        "- ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ²ÑĞµ ÑĞºĞ°Ğ»ÑÑ€Ğ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ² Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€Ñ‹\n",
        "- Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°Ñ‚ÑŒ ĞµĞ´Ğ¸Ğ½Ñ‹Ğ¹ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ, Ğ³Ğ´Ğµ Ğ²ÑĞµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ¼ĞµÑÑ‚ Ñ‚Ğ¸Ğ¿ `torch.Tensor`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dgA4KZlfjjV"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Collates a batch of samples into a single batched tensor representation.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    batch : List[Dict[str, Any]]\n",
        "        A list of samples returned by __getitem__, where each sample is a dictionary.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, Any]\n",
        "        A dictionary with the same structure as input samples, but where all leaf values\n",
        "        are PyTorch tensors of dtype torch.long. Nested dictionaries are preserved,\n",
        "        with tensors at the leaf level.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> batch = [\n",
        "    ...     {\n",
        "    ...         'history': {'item_id': [1, 2, 3], 'lengths': 3, 'positions': [0, 1, 2]},\n",
        "    ...         'labels': {'item_id': [2, 3, 4]}\n",
        "    ...     },\n",
        "    ...     {\n",
        "    ...         'history': {'item_id': [5, 6], 'lengths': 2, 'positions': [0, 1]},\n",
        "    ...         'labels': {'item_id': [6, 7]}\n",
        "    ...     }\n",
        "    ... ]\n",
        "    >>> result = collate_fn(batch)\n",
        "    >>> result['history']['item_id']\n",
        "    tensor([[1, 2, 3, 5, 6]], dtype=torch.long)\n",
        "    >>> result['history']['lengths']\n",
        "    tensor([3, 2], dtype=torch.long)\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy24_uSOfjjV"
      },
      "outputs": [],
      "source": [
        "def test_collate_fn():\n",
        "    \"\"\"ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ±Ğ°Ñ‚Ñ‡Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸ĞµĞ¹ collate_fn.\"\"\"\n",
        "\n",
        "    batch = [\n",
        "        {'history': {'item_id': [1, 2, 3], 'lengths': 3, 'positions': [0, 1, 2]}, 'labels': {'item_id': [2, 3, 4]}},\n",
        "        {'history': {'item_id': [5, 6], 'lengths': 2, 'positions': [0, 1]}, 'labels': {'item_id': [6, 7]}},\n",
        "    ]\n",
        "\n",
        "    result = collate_fn(batch)\n",
        "\n",
        "    assert isinstance(result['history']['item_id'], torch.Tensor), 'item_id Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€Ğ¾Ğ¼'\n",
        "    assert result['history']['item_id'].dtype == torch.long, 'dtype Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ long'\n",
        "\n",
        "    assert result['history']['item_id'].tolist() == [1, 2, 3, 5, 6], 'ĞĞµĞ²ĞµÑ€Ğ½Ğ°Ñ ĞºĞ¾Ğ½ĞºĞ°Ñ‚ĞµĞ½Ğ°Ñ†Ğ¸Ñ item_id'\n",
        "    assert result['history']['positions'].tolist() == [0, 1, 2, 0, 1], 'ĞĞµĞ²ĞµÑ€Ğ½Ğ°Ñ ĞºĞ¾Ğ½ĞºĞ°Ñ‚ĞµĞ½Ğ°Ñ†Ğ¸Ñ positions'\n",
        "\n",
        "    assert result['history']['lengths'].tolist() == [3, 2], 'ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğµ lengths'\n",
        "\n",
        "    assert result['labels']['item_id'].tolist() == [2, 3, 4, 6, 7], 'ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğµ labels'\n",
        "\n",
        "    assert result['history']['lengths'].sum().item() == len(result['history']['item_id']), \\\n",
        "        'Ğ¡ÑƒĞ¼Ğ¼Ğ° lengths != Ğ´Ğ»Ğ¸Ğ½Ğ° item_id'\n",
        "\n",
        "    print('âœ… test_collate_fn: OK')\n",
        "\n",
        "test_collate_fn()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_gC5wKZfjjW"
      },
      "source": [
        "# ĞŸÑ€Ğ¾ SASRec Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KxkgUKXfjjW"
      },
      "source": [
        "## ğŸ“– ĞĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞ¾Ñ€Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾ SASRec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi01CWt3fjjW"
      },
      "source": [
        "<img src=\"sasrec.png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd7Hnmo_fjjW"
      },
      "source": [
        "### ğŸ§ **Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ SASRec?**\n",
        "SASRec (Self-Attentive Sequential Recommendation) - ÑÑ‚Ğ¾ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ĞµĞ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ½Ğ° Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğµ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ° Ğ¸ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ğµ ÑĞ°Ğ¼Ğ¾Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ (self-attention). ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ±Ñ‹Ğ»Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° Ğ² 2018 Ğ³Ğ¾Ğ´Ñƒ (Wang-Cheng Kang, Julian McAuley). Ğ•Ñ‘ Ñ†ĞµĞ»ÑŒ - ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ ĞºĞ°Ğº ĞºÑ€Ğ°Ñ‚ĞºĞ¾ÑÑ€Ğ¾Ñ‡Ğ½Ñ‹Ğµ, Ñ‚Ğ°Ğº Ğ¸ Ğ´Ğ¾Ğ»Ğ³Ğ¾ÑÑ€Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ ĞµĞ³Ğ¾ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ğµ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑÑ‹. SASRec Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸Ğ´ĞµĞ¸ self-attention Ğ¸Ğ· NLP Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ĞµĞ¹ Ğ±Ñ‹Ñ‚ÑŒ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ¹, Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ¹ Ğ¸ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ¹ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ RNN Ğ¸ CNN. ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚ÑŒÑ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ğ²Ğ¾Ñ‚ [Ñ‚ÑƒÑ‚](http://arxiv.org/abs/1808.09781).\n",
        "\n",
        "\n",
        "### ğŸ‘€ **ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:**\n",
        "\n",
        "- Embedding Layer: ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼Ñƒ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñƒ ÑĞ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼Ñ‹Ğ¹ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³ Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚Ğ¸ $d$. Ğ¢Ğ°ĞºĞ¶Ğµ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑÑÑ‚ÑÑ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğµ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑƒÑ‡Ñ‘Ñ‚Ğ° Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞ° ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹.\n",
        "- Transformer Encoder: Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ $l$ Ğ±Ğ»Ğ¾ĞºĞ¾Ğ² ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ° Ğ¸Ğ· Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€ĞµÑ€Ğ° Ñ ĞºĞ°ÑƒĞ·Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¼Ğ°ÑĞºĞ¾Ğ¹. ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ±Ğ»Ğ¾Ğº ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ self-attention ÑĞ»Ğ¾Ğ¹ Ğ¸ position-wise feed-forward ÑĞ»Ğ¾Ğ¹, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ residual connection Ğ¸ layernorm.\n",
        "- Prediction Layer: Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ $t$ Ğ²Ñ‹Ñ…Ğ¾Ğ´ ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ° $\\mathbf{F}^{(b)}_t$ ÑĞºĞ°Ğ»ÑÑ€Ğ½Ğ¾ ÑƒĞ¼Ğ½Ğ¾Ğ¶Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ° ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ° $\\mathbf{M}_i$, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑĞºĞ¾Ñ€ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸ $r_{i, t}$ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¸Ğ· Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ².\n",
        "\n",
        "\n",
        "### ğŸ¤” **Ğ§Ñ‚Ğ¾ Ğ¿Ğ¾Ğ´Ğ°Ñ‘Ñ‚ÑÑ Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´?**\n",
        "ĞĞ° Ğ²Ñ…Ğ¾Ğ´ SASRec Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ñ… $|S^u|$ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ:\n",
        "\n",
        "$$\\Large{S^u = \\left( S^u_1, S^u_2, \\dots, S^u_{|S^u|} \\right)},$$\n",
        "Ğ³Ğ´Ğµ $S^u_t$ - Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ° (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ñ„Ğ¸Ğ»ÑŒĞ¼Ğ° Ğ¸Ğ»Ğ¸ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°), Ñ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¼ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ $u$ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ» Ğ² Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ $t$.\n",
        "\n",
        "\n",
        "### ğŸ¤·â€â™€ï¸ **Ğ§Ñ‚Ğ¾ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼?**\n",
        "ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ Ğ¾Ğ±ÑŠĞµĞºÑ‚ Ğ² Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ. Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾, Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ $t$ Ğ¾Ğ½Ğ° Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´ $(S^u_1, ..., S^u_{t-1})$ Ğ¸ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ñ‚ÑŒ $S^u_t$.\n",
        "Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ° $i$ Ğ¸Ğ· ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ÑÑ ÑĞºĞ¾Ñ€ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸ $r_{i, t}$ - Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒ Ñ‚Ğ¾Ğ³Ğ¾, Ğ½Ğ°ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ ÑÑ‚Ğ¾Ñ‚ Ğ¾Ğ±ÑŠĞµĞºÑ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ´Ğ»Ñ Ñ‚Ğ¾Ğ³Ğ¾, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ±Ñ‹Ñ‚ÑŒ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¼ Ğ² Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ $t$:\n",
        "\n",
        "$$\\Large{r_{i, t} = \\langle F_t^{l}, M_i \\rangle},$$\n",
        "\n",
        "Ğ³Ğ´Ğµ $\\mathbf{F}_t^{l}$ - Ğ²Ñ‹Ñ…Ğ¾Ğ´ l-Ğ³Ğ¾ ÑĞ»Ğ¾Ñ ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ $t$, Ğ° $\\mathbf{M}_i$ - ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ° $i$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teZUPalhfjjW"
      },
      "source": [
        "## ğŸš€ Task 2. Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ SASRecBackbone Ğ¸ SASRecModel (2 Ğ±Ğ°Ğ»Ğ»Ğ°)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZUbLAOcfjjW"
      },
      "source": [
        "### ğŸ”§ Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑƒÑ‚Ğ¸Ğ»Ğ¸Ñ‚Ğ°Ñ€Ğ½Ñ‹Ñ… Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nERZSUxZfjjW"
      },
      "source": [
        "1ï¸âƒ£ ĞĞ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ğ¼Ğ°ÑĞºÑƒ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ñ‹ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹. ĞœĞ°ÑĞºĞ° Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ±Ñ‹Ñ‚ÑŒ Ğ±ÑƒĞ»ĞµĞ²Ñ‹Ğ¼ Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€Ğ¾Ğ¼ Ñ„Ğ¾Ñ€Ğ¼Ñ‹ `(batch_size, max_seq_len)`, Ğ³Ğ´Ğµ `True` Ğ¾Ğ±Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ°ĞµÑ‚ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğµ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ñ‹, Ğ° `False` â€” Ğ¿Ğ°Ğ´Ğ´Ğ¸Ğ½Ğ³."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMfcgNCdfjjW"
      },
      "outputs": [],
      "source": [
        "def get_mask(lengths: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Creates a boolean mask for variable-length sequences.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lengths : torch.Tensor\n",
        "        1D tensor of shape (batch_size,) containing the actual length of each sequence\n",
        "        in the batch.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        Boolean mask of shape (batch_size, max_seq_len) where True indicates a valid\n",
        "        element and False indicates padding. Can be used directly in attention masks\n",
        "        or for selective loss computation.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> lengths = torch.tensor([3, 5, 2])\n",
        "    >>> mask = get_mask(lengths)\n",
        "    >>> mask\n",
        "    tensor([[ True,  True,  True, False, False],\n",
        "            [ True,  True,  True,  True,  True],\n",
        "            [ True,  True, False, False, False]])\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybJ8TwvrfjjW"
      },
      "outputs": [],
      "source": [
        "def test_get_mask():\n",
        "    lengths = torch.tensor([3, 5, 2])\n",
        "    mask = get_mask(lengths)\n",
        "\n",
        "    assert mask.shape == (3, 5), f'ĞĞµĞ²ĞµÑ€Ğ½Ğ°Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°: {mask.shape}'\n",
        "    assert mask.dtype == torch.bool, f'Ğ”Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ bool: {mask.dtype}'\n",
        "\n",
        "    assert (mask.sum(dim=1) == lengths).all(), 'ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ True != lengths'\n",
        "\n",
        "    expected = torch.tensor([\n",
        "        [True, True, True, False, False],\n",
        "        [True, True, True, True, True],\n",
        "        [True, True, False, False, False]\n",
        "    ])\n",
        "    assert torch.equal(mask, expected), f'ĞĞµĞ²ĞµÑ€Ğ½Ğ°Ñ Ğ¼Ğ°ÑĞºĞ°:\\n{mask}'\n",
        "\n",
        "    print('âœ… test_get_mask: OK')\n",
        "\n",
        "test_get_mask()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoUfilCVfjjW"
      },
      "source": [
        "2ï¸âƒ£ ĞĞ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚ Ğ¸Ğ· ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ² `flatten` Ğ±Ğ°Ñ‚Ñ‡Ğµ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRNReP0SfjjW"
      },
      "outputs": [],
      "source": [
        "def get_last(data: torch.Tensor, lengths: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Extracts the last valid element from each sequence in a flattened batch.\n",
        "\n",
        "    Given a flattened tensor of concatenated sequences and their lengths, extracts\n",
        "    the final element of each sequence. Useful for obtaining the last hidden state\n",
        "    or final prediction from variable-length sequences without padding overhead.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : torch.Tensor\n",
        "        Tensor of shape (total_elements, ...) containing flattened sequences concatenated\n",
        "        sequentially. For example: [seq1_embedding1, seq1_embedding2, seq2_embedding1, seq2_embedding2, seq2_embedding3, ...]\n",
        "    lengths : torch.Tensor\n",
        "        1D tensor of shape (batch_size,) containing the length of each sequence.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        Tensor of shape (batch_size, ...) containing the last elements of each sequence.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> data = torch.tensor([1, 2, 3, 4, 5, 6])  # 3 sequences: [1,2], [3,4,5], [6]\n",
        "    >>> lengths = torch.tensor([2, 3, 1])\n",
        "    >>> get_last(data, lengths)\n",
        "    tensor([2, 5, 6])\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYzftd_ufjjW"
      },
      "outputs": [],
      "source": [
        "def test_get_last():\n",
        "    data = torch.tensor([1, 2, 3, 4, 5, 6])  # [1,2], [3,4,5], [6]\n",
        "    lengths = torch.tensor([2, 3, 1])\n",
        "    result = get_last(data, lengths)\n",
        "    assert torch.equal(result, torch.tensor([2, 5, 6])), f'ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: {result}'\n",
        "\n",
        "    data_2d = torch.tensor([[1., 2.], [3., 4.], [5., 6.], [7., 8.], [9., 10.]])\n",
        "    lengths_2d = torch.tensor([2, 3])\n",
        "    result_2d = get_last(data_2d, lengths_2d)\n",
        "    expected_2d = torch.tensor([[3., 4.], [9., 10.]])\n",
        "    assert torch.equal(result_2d, expected_2d), f'ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ´Ğ»Ñ 2D: {result_2d}'\n",
        "\n",
        "    data_ones = torch.tensor([10, 20, 30])\n",
        "    lengths_ones = torch.tensor([1, 1, 1])\n",
        "    assert torch.equal(get_last(data_ones, lengths_ones), torch.tensor([10, 20, 30])), \\\n",
        "        'ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ´Ğ»Ñ ĞµĞ´Ğ¸Ğ½Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ»Ğ¸Ğ½'\n",
        "\n",
        "    print('âœ… test_get_last: OK')\n",
        "\n",
        "test_get_last()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4EkjjahfjjW"
      },
      "source": [
        "3ï¸âƒ£ Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞ¹Ñ‚Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ ÑĞ³Ğ»Ğ°Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ±Ğ°Ñ‚Ñ‡ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ñ‹ Ğ² padded Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw5Cd49AfjjW"
      },
      "outputs": [],
      "source": [
        "def create_masked_tensor(data: torch.Tensor, lengths: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Converts a batch of variable-length sequences into a padded tensor and corresponding mask.\n",
        "\n",
        "    Transforms a flattened concatenation of sequences into a padded 2D (or 3D for embeddings)\n",
        "    tensor with right-padding zeros, along with a boolean mask indicating valid positions.\n",
        "    This function is the inverse of the collate operation and prepares data for models\n",
        "    that require fixed-size inputs.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : torch.Tensor\n",
        "        Input tensor containing flattened sequences:\n",
        "        - For indices: shape (total_elements,) of dtype long\n",
        "        - For embeddings: shape (total_elements, embedding_dim)\n",
        "    lengths : torch.Tensor\n",
        "        1D tensor of sequence lengths, shape (batch_size,). Specifies the actual length\n",
        "        of each sequence before padding.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Tuple[torch.Tensor, torch.Tensor]\n",
        "        - padded_tensor: Padded tensor of shape:\n",
        "            - (batch_size, max_seq_len) for indices\n",
        "            - (batch_size, max_seq_len, embedding_dim) for embeddings\n",
        "            Shorter sequences are right-padded with zeros.\n",
        "        - mask: Boolean mask of shape (batch_size, max_seq_len) where True indicates\n",
        "            valid elements and False indicates padding. Can be used in attention or loss computation.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> data = torch.tensor([1, 2, 3, 4, 5, 6])  # sequences: [1,2], [3,4,5], [6]\n",
        "    >>> lengths = torch.tensor([2, 3, 1])\n",
        "    >>> padded, mask = create_masked_tensor(data, lengths)\n",
        "    >>> padded\n",
        "    tensor([[1, 2, 0],\n",
        "            [3, 4, 5],\n",
        "            [6, 0, 0]])\n",
        "    >>> mask\n",
        "    tensor([[ True,  True, False],\n",
        "            [ True,  True,  True],\n",
        "            [ True, False, False]])\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQOdDbN2fjjW"
      },
      "outputs": [],
      "source": [
        "def test_create_masked_tensor():\n",
        "    data = torch.tensor([1, 2, 3, 4, 5, 6])\n",
        "    lengths = torch.tensor([2, 3, 1])\n",
        "    padded, mask = create_masked_tensor(data, lengths)\n",
        "\n",
        "    expected_padded = torch.tensor([[1, 2, 0], [3, 4, 5], [6, 0, 0]])\n",
        "    expected_mask = torch.tensor([[True, True, False], [True, True, True], [True, False, False]])\n",
        "\n",
        "    assert torch.equal(padded, expected_padded), f'ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ padded:\\n{padded}'\n",
        "    assert torch.equal(mask, expected_mask), f'ĞĞµĞ²ĞµÑ€Ğ½Ğ°Ñ mask:\\n{mask}'\n",
        "    assert (padded[~mask] == 0).all(), 'ĞŸĞ°Ğ´Ğ´Ğ¸Ğ½Ğ³ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ½ÑƒĞ»ÑĞ¼Ğ¸'\n",
        "    assert (mask.sum(dim=1) == lengths).all(), 'Ğ¡ÑƒĞ¼Ğ¼Ğ° True != lengths'\n",
        "\n",
        "    data_2d = torch.randn(5, 4)  # 5 ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ², dim=4\n",
        "    lengths_2d = torch.tensor([2, 3])\n",
        "    padded_2d, mask_2d = create_masked_tensor(data_2d, lengths_2d)\n",
        "\n",
        "    assert padded_2d.shape == (2, 3, 4), f'ĞĞµĞ²ĞµÑ€Ğ½Ğ°Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ° 2D: {padded_2d.shape}'\n",
        "    assert (padded_2d[~mask_2d] == 0).all(), 'ĞŸĞ°Ğ´Ğ´Ğ¸Ğ½Ğ³ 2D Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ½ÑƒĞ»ÑĞ¼Ğ¸'\n",
        "\n",
        "    print('âœ… test_create_masked_tensor: OK')\n",
        "\n",
        "test_create_masked_tensor()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i0d_HVMfjjW"
      },
      "source": [
        "### ğŸ—ï¸ Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iREI-H4-fjjW"
      },
      "source": [
        "4ï¸âƒ£  Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞ¹Ñ‚Ğµ ĞºĞ»Ğ°ÑÑ `SASRecBackbone`, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.\n",
        "\n",
        "Ğ’ ÑÑ‚Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğµ Ğ²Ñ‹ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ backbone SASRec â€” Ñ‡Ğ°ÑÑ‚ÑŒ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ğ¾ Ğ²Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ $F_t^l$ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹. ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ / ÑĞ»Ğ¾Ğ¹, ÑÑ‡Ğ¸Ñ‚Ğ°ÑÑ‰Ğ¸Ğ¹ ÑĞºĞ¾Ñ€ $r_{i, t}$, Ğ±ÑƒĞ´ĞµÑ‚ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑÑ‚ÑŒÑÑ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾.\n",
        "\n",
        "Ğ§Ñ‚Ğ¾ Ğ¿Ğ¾Ğ´Ğ°Ñ‘Ñ‚ÑÑ Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸?\n",
        "\n",
        "Ğ’Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· `YambdaDataset` Ğ¸ `collate_fn` Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒÑÑ‚ÑÑ Ğ² flatten Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¸ Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ² padded Ğ±Ğ°Ñ‚Ñ‡Ğ¸. ĞĞ° Ğ²Ñ…Ğ¾Ğ´ `SASRecBackbone.forward` Ğ¿Ñ€Ğ¸Ñ…Ğ¾Ğ´Ğ¸Ñ‚ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ:\n",
        "\n",
        "- `inputs['item_id']` â€” Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€ Ğ¸Ğ½Ğ´ĞµĞºÑĞ¾Ğ² Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ², ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¹ ĞºĞ¾Ğ½ĞºĞ°Ñ‚ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸ÑĞ¼ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹, `shape: (total_elements,)`\n",
        "- `inputs['positions']` â€” Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ½Ğ´ĞµĞºÑĞ¾Ğ² Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ° $(0, 1, 2, \\dots)$, `shape: (total_elements,)`\n",
        "- `inputs['lengths']` â€” Ğ´Ğ»Ğ¸Ğ½Ñ‹ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¹ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ, `shape: (batch_size,)`\n",
        "\n",
        "Ğ­Ñ‚Ğ¸ Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€Ñ‹ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑĞ¼ $S^u$, ÑƒĞ¶Ğµ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ¸ Ğ¾Ğ±Ñ€ĞµĞ·Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ğ´Ğ¾ `max_seq_len`.\n",
        "\n",
        "Ğ§Ñ‚Ğ¾ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ?\n",
        "1) ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ `item_id` Ğ² ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ¸ `nn.Embedding`\n",
        "2) Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğº Ğ½Ğ¸Ğ¼ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ°Ğ»Ğ° Ğ¿Ğ¾Ñ€ÑĞ´Ğ¾Ğº ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹\n",
        "3) Ğ¡ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ `create_masked_tensor` Ğ¿Ñ€ĞµĞ²Ñ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ flatten Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ² padded Ğ±Ğ°Ñ‚Ñ‡\n",
        "4) ĞŸĞ¾ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ causal `mask`, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ğ°ĞµÑ‚ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ² Ğ±ÑƒĞ´ÑƒÑ‰ĞµĞµ\n",
        "5) ĞŸÑ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ±Ğ°Ñ‚Ñ‡ Ñ‡ĞµÑ€ĞµĞ· `nn.TransformerEncoder`\n",
        "6) Ğ’ĞµÑ€Ğ½ÑƒÑ‚ÑŒ Ğ² Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹ Ğ²ÑĞµÑ… Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹. Ğ˜Ğ¼ĞµĞ½Ğ½Ğ¾ ÑÑ‚Ğ¾Ñ‚ Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€ Ğ´Ğ°Ğ»ÑŒÑˆĞµ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ´Ğ»Ñ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ ÑĞºĞ¾Ñ€Ğ¾Ğ² $r_{i, t}$ Ğ¸ Ñ†ĞµĞ»ĞµĞ²Ñ‹Ñ… Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydP4vkiFfjjX"
      },
      "outputs": [],
      "source": [
        "class SASRecBackbone(nn.Module):\n",
        "    \"\"\"\n",
        "    Self-Attentive Sequential Recommendation (SASRec) backbone architecture.\n",
        "\n",
        "    Implements the core transformer-based model for sequential recommendation that captures\n",
        "    user preferences by attending to their historical interactions. The model uses self-attention\n",
        "    mechanisms with causal masking to ensure autoregressive generation: each position can only\n",
        "    attend to previous positions.\n",
        "\n",
        "    Architecture:\n",
        "    1. Embedding layer: converts item IDs to dense vectors\n",
        "    2. Positional encoding: adds position information to embeddings\n",
        "    3. Transformer encoder: multi-head self-attention with causal masking\n",
        "    4. Output: encoder representations for downstream tasks\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_items : int\n",
        "        Total number of unique items in the catalog. Used for embedding table size.\n",
        "    embedding_dim : int, optional\n",
        "        Dimension of item and position embeddings.\n",
        "    num_heads : int, optional\n",
        "        Number of attention heads in transformer.\n",
        "    max_seq_len : int, optional\n",
        "        Maximum sequence length for positional embeddings.\n",
        "    dropout_rate : float, optional\n",
        "        Dropout probability for regularization.\n",
        "    num_transformer_layers : int, optional\n",
        "        Number of transformer encoder layers.\n",
        "\n",
        "    Input Format\n",
        "    -----------\n",
        "    inputs : Dict[str, torch.Tensor]\n",
        "        Dictionary containing:\n",
        "        - 'item_id': Flattened item indices, shape (total_elements,)\n",
        "        - 'positions': Positional indices, shape (total_elements,)\n",
        "        - 'lengths': Actual sequence lengths for each sample, shape (batch_size,)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, torch.Tensor]\n",
        "        Dictionary containing:\n",
        "        - 'encoder_output': Transformer encoder output, shape (total_valid_elements, embedding_dim)\n",
        "            Contains only non-padded representations extracted using the mask.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> model = SASRecBackbone(num_items=10000, embedding_dim=64, num_heads=2)\n",
        "    >>> inputs = {\n",
        "    ...     'item_id': torch.tensor([1, 2, 3, 4, 5, 6]),\n",
        "    ...     'positions': torch.tensor([0, 1, 2, 0, 1, 2]),\n",
        "    ...     'lengths': torch.tensor([3, 3])\n",
        "    ... }\n",
        "    >>> output = model(inputs)\n",
        "    >>> output['encoder_output'].shape\n",
        "    torch.Size([6, 64])\n",
        "\n",
        "    Note\n",
        "    ----\n",
        "    - Uses causal masking to prevent looking into future\n",
        "    - Handles variable-length sequences via padding and masking\n",
        "    - Position embeddings are added additively to item embeddings\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_items: int,\n",
        "            embedding_dim: int = 64,\n",
        "            num_heads: int = 2,\n",
        "            max_seq_len: int = 512,\n",
        "            dropout_rate: float = 0.2,\n",
        "            num_transformer_layers: int = 2,\n",
        "        ) -> None:\n",
        "        super().__init__()\n",
        "        self.num_items = num_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.item_embeddings = ...  # TODO: your code here\n",
        "        self.position_embeddings = ...  # TODO: your code here\n",
        "\n",
        "        encoder_layer = ...  # TODO: your code here\n",
        "        self.transformer_encoder = ...  # TODO: your code here\n",
        "\n",
        "    def forward(self, inputs: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass through the SASRec model.\n",
        "\n",
        "        Processes flattened input sequences through embedding, padding, and transformer\n",
        "        encoder with causal masking to produce contextual representations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : Dict[str, torch.Tensor]\n",
        "            Input dictionary containing:\n",
        "            - 'item_id': Flattened item indices, shape (total_elements,)\n",
        "            - 'positions': Positional indices [0, 1, 2, ...], shape (total_elements,)\n",
        "            - 'lengths': Sequence lengths, shape (batch_size,)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict[str, torch.Tensor]\n",
        "            Output dictionary containing:\n",
        "            - 'encoder_output': Valid (non-padded) encoder representations,\n",
        "              shape (total_elements, embedding_dim)\n",
        "\n",
        "        Processing Steps\n",
        "        ----------------\n",
        "        1. Embed items and positions\n",
        "        2. Add position embeddings to item embeddings\n",
        "        3. Convert to padded format with mask\n",
        "        4. Create causal mask for autoregressive attention\n",
        "        5. Pass through transformer encoder with causal and padding masks\n",
        "        6. Extract only valid positions using mask\n",
        "        \"\"\"\n",
        "        lengths = inputs['lengths']\n",
        "\n",
        "        embeddings = ...  # TODO: your code here\n",
        "        position_embeddings = ...  # TODO: your code here\n",
        "        embeddings = embeddings + position_embeddings  # (batch_size, seq_len, embedding_dim)\n",
        "\n",
        "        embeddings, mask = create_masked_tensor(\n",
        "            data=embeddings, lengths=lengths\n",
        "        )  # (batch_size, seq_len, embedding_dim), (batch_size, seq_len)\n",
        "\n",
        "        encoder_output = ...  # TODO: your code here\n",
        "\n",
        "        return {\n",
        "            'encoder_output': encoder_output\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cf4ueb6WfjjX"
      },
      "outputs": [],
      "source": [
        "def test_sasrec_backbone():\n",
        "    model = SASRecBackbone(num_items=1000, embedding_dim=32, num_heads=2)\n",
        "    model.eval()\n",
        "\n",
        "    assert model.item_embeddings.num_embeddings == 1000, 'ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ item_embeddings'\n",
        "    assert model.item_embeddings.embedding_dim == 32, 'ĞĞµĞ²ĞµÑ€Ğ½Ğ°Ñ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²'\n",
        "\n",
        "    inputs = {\n",
        "        'item_id': torch.tensor([1, 2, 3, 4, 5]),\n",
        "        'positions': torch.tensor([0, 1, 2, 0, 1]),\n",
        "        'lengths': torch.tensor([3, 2])\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(inputs)\n",
        "\n",
        "    assert output['encoder_output'].shape == (5, 32), \\\n",
        "        f'ĞĞµĞ²ĞµÑ€Ğ½Ğ°Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°: {output['encoder_output'].shape}'\n",
        "    assert not torch.isnan(output['encoder_output']).any(), 'Ğ’Ñ‹Ñ…Ğ¾Ğ´ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ NaN'\n",
        "\n",
        "    print('âœ… test_sasrec_backbone: OK')\n",
        "\n",
        "\n",
        "test_sasrec_backbone()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv273oFrfjjX"
      },
      "source": [
        "5ï¸âƒ£ Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞ¹Ñ‚Ğµ ĞºĞ»Ğ°ÑÑ `SASRecModel`, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚ `backbone` Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ¾Ğ¹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞ¸.\n",
        "\n",
        "ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ² Ğ´Ğ²ÑƒÑ… Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°Ñ…:\n",
        "\n",
        "1) Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ (`self.training == True`):\n",
        "    - ĞŸÑ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· `backbone` ÑĞ½ĞºĞ¾Ğ´ĞµÑ€\n",
        "    - Ğ’Ñ‹Ğ·Ğ¾Ğ²Ğ¸Ñ‚Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´ `compute_loss` Ğ´Ğ»Ñ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ Ñ†ĞµĞ»ĞµĞ²Ğ¾Ğ¹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ (Ğ¼Ñ‹ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ ĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ·Ğ¶Ğµ)\n",
        "    - Ğ’ĞµÑ€Ğ½Ğ¸Ñ‚Ğµ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ñ ĞºĞ»ÑÑ‡Ğ¾Ğ¼ `'loss'`\n",
        "\n",
        "2) Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸/Ñ‚ĞµÑÑ‚Ğ° (`self.training == False`):\n",
        "- ĞŸÑ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· `backbone` ÑĞ½ĞºĞ¾Ğ´ĞµÑ€\n",
        "- Ğ¡ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ `get_last()` Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ¸Ñ‚Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ\n",
        "- Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸Ñ‚Ğµ Ñ†ĞµĞ»ĞµĞ²Ğ¾Ğ¹ (Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹) Ğ°Ğ¹Ñ‚ĞµĞ¼ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ\n",
        "- Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚Ğµ ÑĞºĞ¾Ñ€Ñ‹ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ² ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ°\n",
        "- Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚Ğµ ÑĞºĞ¾Ñ€ Ñ Ñ†ĞµĞ»ĞµĞ²Ñ‹Ğ¼ Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ¼ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾\n",
        "- Ğ’ĞµÑ€Ğ½Ğ¸Ñ‚Ğµ Ğ¾Ğ±Ğ° Ñ‚Ğ¸Ğ¿Ğ° ÑĞºĞ¾Ñ€Ğ¾Ğ² Ğ² ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ğµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sy3n8LNQfjjX"
      },
      "outputs": [],
      "source": [
        "class SASRecModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Complete SASRec recommendation model combining backbone encoder with training and inference logic.\n",
        "\n",
        "    This model wraps the SASRecBackbone encoder and implements two distinct forward passes:\n",
        "\n",
        "    - Training mode: processes user sequences through the backbone and computes a loss value\n",
        "      for parameter optimization.\n",
        "\n",
        "    - Evaluation mode (validation/test): uses the backbone to encode user histories,\n",
        "      then computes relevance scores for all items in the catalog. For each user,\n",
        "      the model produces scores r_i = <F^l, M_i> where F^l is the last encoder\n",
        "      output for that user and M_i is the embedding of item i.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : SASRecBackbone\n",
        "        The transformer encoder backbone that produces contextualized representations\n",
        "        from user interaction sequences.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            backbone: SASRecBackbone,\n",
        "        ) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.init_weights(0.02)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def init_weights(self, initializer_range: float) -> None:\n",
        "        \"\"\"\n",
        "        Initializes model weights using truncated normal distribution.\n",
        "\n",
        "        Strategy:\n",
        "        - Weight matrices: truncated normal with std=initializer_range\n",
        "        - LayerNorm weights: ones (identity)\n",
        "        - Biases: zeros\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        initializer_range : float\n",
        "            Standard deviation for truncated normal initialization.\n",
        "        \"\"\"\n",
        "        for key, value in self.named_parameters():\n",
        "            if 'weight' in key:\n",
        "                if 'norm' in key:\n",
        "                    nn.init.ones_(value.data)\n",
        "                else:\n",
        "                    nn.init.trunc_normal_(\n",
        "                        value.data, std=initializer_range, a=-2 * initializer_range, b=2 * initializer_range\n",
        "                    )\n",
        "            else:\n",
        "                assert 'bias' in key\n",
        "                nn.init.zeros_(value.data)\n",
        "\n",
        "    def compute_loss(self, inputs: Dict, backbone_output: Dict[str, torch.Tensor]) -> Dict:\n",
        "        # DO NOT CHANGE THIS FUNCTION HERE\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, inputs: Dict):\n",
        "        \"\"\"\n",
        "        Forward pass of the SASRec model with mode-dependent behavior.\n",
        "\n",
        "        During training: computes and returns loss.\n",
        "        During evaluation: computes and returns ranking scores for all items.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : Dict\n",
        "            Input batch dictionary with keys:\n",
        "            - 'history': encoded user sequence (processed by YambdaDataset)\n",
        "              containing 'item_id', 'positions', 'lengths'\n",
        "            - 'labels': ground truth next items\n",
        "              containing 'item_id', 'lengths'\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            - If training (self.training == True):\n",
        "              {'loss': scalar tensor}\n",
        "\n",
        "            - If evaluating (self.training == False):\n",
        "              {\n",
        "                'all_scores': (batch_size, num_items) relevance scores for all items,\n",
        "                'positive_scores': (batch_size,) scores for ground truth items\n",
        "              }\n",
        "        \"\"\"\n",
        "        backbone_outputs = self.backbone(inputs['history'])\n",
        "\n",
        "        if self.training:\n",
        "            # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ\n",
        "            return {\n",
        "                'loss': self.compute_loss(inputs, backbone_outputs)\n",
        "            }\n",
        "        else:\n",
        "            # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ\n",
        "            last_embeddings = ...  # TODO: your code here\n",
        "            last_labels = ...  # TODO: your code here\n",
        "\n",
        "            last_labels_embeddings = ... # TODO: your code here\n",
        "            all_item_embeddings = ... # TODO: your code here\n",
        "\n",
        "            all_scores = ... # TODO: your code here\n",
        "            positive_score = ... # TODO: your code here\n",
        "\n",
        "            return {\n",
        "                'all_scores': all_scores,\n",
        "                'positive_scores': positive_score,\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4uGUwKqfjjX"
      },
      "outputs": [],
      "source": [
        "def test_sasrec_model():\n",
        "    backbone = SASRecBackbone(num_items=100, embedding_dim=32, num_heads=2)\n",
        "    model = SASRecModel(backbone)\n",
        "\n",
        "    inputs = {\n",
        "        'history': {\n",
        "            'item_id': torch.tensor([1, 2, 3, 4, 5]),\n",
        "            'positions': torch.tensor([0, 1, 2, 0, 1]),\n",
        "            'lengths': torch.tensor([3, 2])\n",
        "        },\n",
        "        'labels': {'item_id': torch.tensor([2, 3, 4, 5, 6])}\n",
        "    }\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(inputs)\n",
        "\n",
        "    assert out['all_scores'].shape == (2, 100), f'ĞĞµĞ²ĞµÑ€Ğ½Ğ°Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ° all_scores: {out['all_scores'].shape}'\n",
        "    assert out['positive_scores'].shape == (2,), f'ĞĞµĞ²ĞµÑ€Ğ½Ğ°Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ° positive_scores: {out['positive_scores'].shape}'\n",
        "    assert not torch.isnan(out['all_scores']).any(), 'all_scores ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ NaN'\n",
        "\n",
        "    model.train()\n",
        "    try:\n",
        "        model(inputs)\n",
        "        assert False, 'compute_loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ²Ñ‹Ğ±Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ NotImplementedError'\n",
        "    except NotImplementedError:\n",
        "        pass\n",
        "\n",
        "    print('âœ… test_sasrec_model: OK')\n",
        "\n",
        "\n",
        "test_sasrec_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTeO4wZ9fjjX"
      },
      "source": [
        "# ğŸ’» Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ SASRec'Ğ°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCAyAtDBfjjX"
      },
      "source": [
        "## ğŸ¤“ Task 3. Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ SASRec Ğ¸Ğ· ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ (1 Ğ±Ğ°Ğ»Ğ»)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dBIuDwvfjjX"
      },
      "source": [
        "Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞ¹Ñ‚Ğµ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ `SASRec` Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ `BinaryCrossEntropy` Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_UnlxuNfjjX"
      },
      "source": [
        "Ğ’ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°Ğ»Ğ¾ÑÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ BCE (Binary Cross Entropy):\n",
        "\n",
        "$$\\Large{\\mathcal{L}_{Original} = - \\sum_{S^u \\in S} \\sum_{t \\in [1, 2, \\dots, |S^u| - 1]} \\Bigg[ \\log \\sigma \\left( r_{S^u_{t+1}, t} \\right)  + \\sum_{j \\notin S^u} \\log \\left( 1 - \\sigma \\left( r_{j,t} \\right)   \\right)} \\Bigg],$$\n",
        "\n",
        "Ğ³Ğ´Ğµ $\\sigma(r_{i,t})$ - Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¾Ğ³Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ°Ğ¹Ñ‚ĞµĞ¼ $i$ Ğ±ÑƒĞ´ĞµÑ‚ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¼ Ğ² Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ $t$, Ğ° $\\sigma$ - ÑĞ¸Ğ³Ğ¼Ğ¾Ğ¸Ğ´Ğ°.\n",
        "\n",
        "$\\color{red}{\\text{ĞĞ¾ Ğ½Ğ° ÑĞ°Ğ¼Ğ¾Ğ¼ Ğ´ĞµĞ»Ğµ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ĞµĞ¹ ÑÑƒĞ¼Ğ¼Ñ‹ Ğ½ĞµÑ‚, Ğ² ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ¾Ğ´Ğ¸Ğ½ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ² Ğ½Ğ° Ğ¾Ğ´Ğ¸Ğ½ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvJmVgHNfjjX"
      },
      "outputs": [],
      "source": [
        "class SASRecReal(SASRecModel):\n",
        "    \"\"\"\n",
        "    SASRec model trained with Binary Cross-Entropy loss (negative sampling).\n",
        "\n",
        "    For each position t in a user sequence, the model learns to distinguish between:\n",
        "    - Positive: the ground-truth next item S^u_t (label = 1)\n",
        "    - Negative: a randomly sampled item from the catalog (label = 0)\n",
        "\n",
        "    The loss is computed as:\n",
        "        L = BCE(scores, labels)\n",
        "    where scores are computed as dot products between query embeddings (from backbone)\n",
        "    and item embeddings (positive and negative).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : SASRecBackbone\n",
        "        The encoder backbone that produces contextualized user representations.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - Negative sampling is done uniformly at random from the entire item catalog.\n",
        "    \"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def compute_loss_inner(cls, user_embeddings: torch.Tensor, positive_embeddings: torch.Tensor, negative_embeddings: torch.Tensor) -> torch.Tensor:\n",
        "        # TODO: your code here\n",
        "        pass\n",
        "\n",
        "    def compute_loss(self, inputs: Dict, backbone_output: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        query_embeddings = backbone_output['encoder_output']\n",
        "        positive_embeddings = self.backbone.item_embeddings(inputs['labels']['item_id'])  # (total_batch_events, embedding_dim)\n",
        "\n",
        "        random_item_ids = torch.randint(\n",
        "            low=0,\n",
        "            high=self.backbone.num_items,\n",
        "            size=(positive_embeddings.shape[0],),\n",
        "            device=positive_embeddings.device\n",
        "        )\n",
        "\n",
        "        negative_embeddings = self.backbone.item_embeddings(random_item_ids)  # (total_batch_events, embedding_dim)\n",
        "\n",
        "        return self.compute_loss_inner(query_embeddings, positive_embeddings, negative_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM26K7VhE8r-"
      },
      "outputs": [],
      "source": [
        "def test_compute_loss_inner_real():\n",
        "    user_emb = torch.tensor([[1.0, 0.0], [0.0, 1.0]])\n",
        "    pos_emb = torch.tensor([[100.0, 0.0], [0.0, 100.0]])\n",
        "    neg_emb = torch.tensor([[-100.0, 0.0], [0.0, -100.0]])\n",
        "    loss = SASRecReal.compute_loss_inner(user_emb, pos_emb, neg_emb)\n",
        "    assert loss.item() < 1e-6, f'loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ñ€Ğ°Ğ²ĞµĞ½ 0, Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ¸: {loss.item():.4f}'\n",
        "\n",
        "    user_emb = torch.tensor([[1.0, 0.0], [0.0, 1.0]])\n",
        "    pos_emb = torch.tensor([[-100.0, 0.0], [0.0, -100.0]])\n",
        "    neg_emb = torch.tensor([[100.0, 0.0], [0.0, 100.0]])\n",
        "    loss = SASRecReal.compute_loss_inner(user_emb, pos_emb, neg_emb)\n",
        "    assert abs(loss.item() - 100) < 1e-3, f'loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ€Ğ°Ğ²ĞµĞ½ 100, Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ¸: {loss.item():.4f}'\n",
        "\n",
        "    user_emb = torch.randn(1000, 16) * 0.1\n",
        "    pos_emb = torch.randn(1000, 16) * 0.1\n",
        "    neg_emb = torch.randn(1000, 16) * 0.1\n",
        "\n",
        "    loss = SASRecReal.compute_loss_inner(user_emb, pos_emb, neg_emb)\n",
        "    expected_loss = np.log(2)\n",
        "\n",
        "    # Ğ¸Ğ·-Ğ·Ğ° Ñ€Ğ°Ğ½Ğ´Ğ¾Ğ¼Ğ° ÑÑ‚Ğ¾Ñ‚ Ñ‚ĞµÑÑ‚ Ğ¼Ğ¾Ğ¶ĞµÑ‚ ÑƒĞ¿Ğ°ÑÑ‚ÑŒ Ñ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ¼Ğ°Ğ»Ğ¾Ğ¹ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¿Ñ€Ğ¸ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾Ğ¼ ĞºĞ¾Ğ´Ğµ\n",
        "    assert abs(loss.item() - expected_loss) < 1e-2, \\\n",
        "        f'loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ€Ğ°Ğ²ĞµĞ½ {expected_loss:.3f}, Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ¸: {loss.item():.4f}'\n",
        "\n",
        "    user_emb = torch.zeros(10, 8)\n",
        "    pos_emb = torch.zeros(10, 8)\n",
        "    neg_emb = torch.zeros(10, 8)\n",
        "\n",
        "    loss = SASRecReal.compute_loss_inner(user_emb, pos_emb, neg_emb)\n",
        "    expected_loss = np.log(2)\n",
        "    assert abs(loss.item() - expected_loss) < 1e-2, \\\n",
        "        f'loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ€Ğ°Ğ²ĞµĞ½ {expected_loss:.3f}, Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ¸: {loss.item():.4f}'\n",
        "\n",
        "    print('âœ… test_compute_loss_inner_real: OK')\n",
        "\n",
        "test_compute_loss_inner_real()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ysm8Rd5fjjX"
      },
      "source": [
        "## ğŸ˜‡ Task 4. Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ SASRec Ñ‡ĞµÑ€ĞµĞ· Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ in-batch Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ¾Ğ² (1 Ğ±Ğ°Ğ»Ğ»)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKtZq_mQfjjY"
      },
      "source": [
        "Ğ’ÑĞµ Ğ¶Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ ÑĞ¾Ñ„Ñ‚Ğ¼Ğ°ĞºÑ Ğ½Ğµ Ğ²ÑĞµĞ³Ğ´Ğ° Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğ¼ Ğ¸ Ñ€Ğ°Ğ½Ğ´Ğ¾Ğ¼Ğ½Ğ¾ ÑĞµĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹ Ğ¸Ğ· Ğ²ÑĞµĞ³Ğ¾ ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ½ĞµÑ‚Ñ€Ğ¸Ğ²Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ñ€ĞµÑˆĞ¸Ñ‚ÑŒ ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ¼Ñ‹ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ.\n",
        "\n",
        "$$\\Large{\\mathcal{L}_{\\text{in batch}} = - \\sum_{S^u \\in S} \\sum_{t \\in [1, 2, \\dots, n]}  \\Bigg[  - \\log \\left( \\frac{e^{r_{S^u_{t+1}, t}}}{e^{r_{S^u_{t+1}, t}} + \\sum_{d \\in Sample(B, k)}{e^{r_{d, t}}}} \\right) \\Bigg]},$$\n",
        "\n",
        "Ğ³Ğ´Ğµ $k$ - ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ¾Ğ², Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑĞµĞ¼Ğ¿Ğ»Ğ°, $B$ - Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ¸Ğ· Ğ²ÑĞµÑ… Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ² Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVxgmMdlfjjY"
      },
      "source": [
        "Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞ¹Ñ‚Ğµ Ğ²ĞµÑ€ÑĞ¸Ñ `SASRec`, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ in-batch negative sampling Ğ²Ğ¼ĞµÑÑ‚Ğ¾ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğ³Ğ¾ ÑĞµĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ· ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ°. Ğ­Ñ‚Ğ° ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ±Ğ¾Ğ»ĞµĞµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°, Ñ‚Ğ°Ğº ĞºĞ°Ğº Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ, ÑƒĞ¶Ğµ Ğ½Ğ°Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸ĞµÑÑ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸, Ğ¸ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ñ‘Ñ‚ Ğ»ÑƒÑ‡ÑˆĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ñ€ĞµĞ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ°Ğ¼.\n",
        "\n",
        "Ğ˜Ğ´ĞµÑ:\n",
        "Ğ’Ğ¼ĞµÑÑ‚Ğ¾ Ñ‚Ğ¾Ğ³Ğ¾ Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾ Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ°Ğ¹Ñ‚ĞµĞ¼Ñ‹ Ğ¸Ğ· Ğ²ÑĞµĞ³Ğ¾ ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ°, Ğ¼Ñ‹ Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¸Ñ… Ğ¸Ğ· Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ², ÑƒĞ¶Ğµ Ğ¿Ñ€Ğ¸ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ² Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¼ Ğ±Ğ°Ñ‚Ñ‡Ğµ (Ñ‚Ğ¾ ĞµÑÑ‚ÑŒ Ğ¸Ğ· Ñ†ĞµĞ»ĞµĞ²Ñ‹Ñ… Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ² Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ). Ğ­Ñ‚Ğ¾ Ğ´Ğ°Ñ‘Ñ‚ Ğ½Ğ°Ğ¼ \"Ñ‚Ñ€ÑƒĞ´Ğ½ĞµĞµ\" Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ñ‹ â€” Ğ¾Ğ½Ğ¸ Ğ±Ğ¾Ğ»ĞµĞµ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸ Ğ½Ğ° Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ°Ğ¹Ñ‚ĞµĞ¼Ñ‹, Ñ‡ĞµĞ¼ ÑĞ¾Ğ²ÑĞµĞ¼ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyF-pPs6fjjY"
      },
      "outputs": [],
      "source": [
        "class SASRecInBatch(SASRecModel):\n",
        "    \"\"\"\n",
        "    SASRec model trained with using in-batch negative sampling.\n",
        "\n",
        "    For each position t in a user sequence, the model learns to distinguish:\n",
        "    - Positive: the ground-truth next item S^u_t\n",
        "    - Negatives: `num_negatives` random items sampled from the given batch of target items\n",
        "\n",
        "    This formulation is equivalent to multi-class classification where the model\n",
        "    finds one positive among (1 + num_negatives) candidates.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : SASRecBackbone\n",
        "        The encoder backbone that produces contextualized user representations.\n",
        "    num_negatives : int\n",
        "        Number of negative samples per positive example.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - In-batch negatives are sampled uniformly from batch target items.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            backbone: SASRecBackbone,\n",
        "            num_negatives: int\n",
        "        ) -> None:\n",
        "        super().__init__(backbone)\n",
        "        self.num_negatives = num_negatives\n",
        "\n",
        "    @classmethod\n",
        "    def compute_loss_inner(cls, user_embeddings: torch.Tensor, positive_embeddings: torch.Tensor, negative_embeddings: torch.Tensor) -> torch.Tensor:\n",
        "        # TODO: your code here\n",
        "        pass\n",
        "\n",
        "    def compute_loss(self, inputs: Dict[str, torch.Tensor], backbone_output: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        query_embeddings = backbone_output['encoder_output']  # (total_batch_events, embedding_dim)\n",
        "        positive_embeddings = self.backbone.item_embeddings(inputs['labels']['item_id'])  # (total_batch_events, embedding_dim)\n",
        "\n",
        "        inbatch_negative_ids = torch.randint(\n",
        "            low=0,\n",
        "            high=inputs['labels']['item_id'].shape[0],\n",
        "            size=(self.num_negatives * query_embeddings.shape[0],),\n",
        "            device=positive_embeddings.device\n",
        "        )\n",
        "        inbatch_item_ids = inputs['labels']['item_id'][inbatch_negative_ids]\n",
        "\n",
        "        inbatch_negative_embeddings = self.backbone.item_embeddings(inbatch_item_ids).reshape(\n",
        "            query_embeddings.shape[0],\n",
        "            self.num_negatives,\n",
        "            query_embeddings.shape[-1]\n",
        "        )  # (total_batch_events, num_negatives, embedding_dim)\n",
        "\n",
        "        return self.compute_loss_inner(query_embeddings, positive_embeddings, inbatch_negative_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoCOCCF6IBsS"
      },
      "outputs": [],
      "source": [
        "def test_compute_loss_inner_inbatch():\n",
        "    user_emb = torch.tensor([\n",
        "        [1.0, 0.0],\n",
        "        [0.0, 1.0]\n",
        "    ])\n",
        "    pos_emb = torch.tensor([\n",
        "        [100.0, 0.0],\n",
        "        [0.0, 100.0]\n",
        "    ])\n",
        "    neg_emb = torch.tensor([\n",
        "        [[-100.0, 0.0], [0.0, -100.0], [-50.0, -50.0]],\n",
        "        [[100.0, 0.0], [-100.0, 0.0], [-50.0, -50.0]]\n",
        "    ])\n",
        "\n",
        "    loss = SASRecInBatch.compute_loss_inner(user_emb, pos_emb, neg_emb)\n",
        "    expected_loss = 0\n",
        "    assert abs(loss.item() - expected_loss) < 1e-2, \\\n",
        "        f'loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ€Ğ°Ğ²ĞµĞ½ {expected_loss:.3f}, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾: {loss.item():.4f}'\n",
        "\n",
        "    user_emb = torch.tensor([[1.0, 0.0], [0.0, 1.0]])\n",
        "    pos_emb = torch.tensor([[-100.0, 0.0], [0.0, -100.0]])\n",
        "    neg_emb = torch.tensor([\n",
        "        [[100.0, 0.0], [50.0, 0.0], [10.0, 0.0]],\n",
        "        [[0.0, 100.0], [0.0, 50.0], [0.0, 10.0]]\n",
        "    ])\n",
        "    loss = SASRecInBatch.compute_loss_inner(user_emb, pos_emb, neg_emb)\n",
        "    expected_loss = 200\n",
        "    assert abs(loss.item() - expected_loss) < 1e-2, \\\n",
        "        f'loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ€Ğ°Ğ²ĞµĞ½ {expected_loss:.3f}, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾: {loss.item():.4f}'\n",
        "\n",
        "    batch_size = 10000\n",
        "    num_negatives = 5\n",
        "    embedding_dim = 16\n",
        "\n",
        "    user_emb = torch.randn(batch_size, embedding_dim) * 0.1\n",
        "    pos_emb = torch.randn(batch_size, embedding_dim) * 0.1\n",
        "    neg_emb = torch.randn(batch_size, num_negatives, embedding_dim) * 0.1\n",
        "\n",
        "    loss = SASRecInBatch.compute_loss_inner(user_emb, pos_emb, neg_emb)\n",
        "    expected_loss = np.log(num_negatives + 1)\n",
        "\n",
        "    # Ğ¸Ğ·-Ğ·Ğ° Ñ€Ğ°Ğ½Ğ´Ğ¾Ğ¼Ğ° ÑÑ‚Ğ¾Ñ‚ Ñ‚ĞµÑÑ‚ Ğ¼Ğ¾Ğ¶ĞµÑ‚ ÑƒĞ¿Ğ°ÑÑ‚ÑŒ Ñ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ¼Ğ°Ğ»Ğ¾Ğ¹ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¿Ñ€Ğ¸ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾Ğ¼ ĞºĞ¾Ğ´Ğµ\n",
        "    assert abs(loss.item() - expected_loss) < 1e-2, \\\n",
        "        f'loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ€Ğ°Ğ²ĞµĞ½ {expected_loss:.3f}, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾: {loss.item():.4f}'\n",
        "\n",
        "    print('âœ… test_compute_loss_inner_inbatch: OK')\n",
        "\n",
        "\n",
        "test_compute_loss_inner_inbatch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrb3dln_fjjY"
      },
      "source": [
        "## ğŸ¤© Task 5. Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ SASRec Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ log-q ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ğ¸ Ğ² in-batch Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ (2 Ğ±Ğ°Ğ»Ğ»Ğ°)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB5KZ_yrfjjY"
      },
      "source": [
        "ğŸ˜¢ ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ»Ñ…Ğ¾Ğ´Ğ°: Ğ¡Ğ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ In-Batch Negative Sampling\n",
        "\n",
        "ĞŸÑ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ in-batch negative sampling Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°ÑÑ‚ÑÑ Ğ¸Ğ· Ñ†ĞµĞ»ĞµĞ²Ñ‹Ñ… Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğ°. ĞĞ´Ğ½Ğ°ĞºĞ¾ ÑÑ‚Ğ¸ Ğ°Ğ¹Ñ‚ĞµĞ¼Ñ‹ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ñ‹ Ğ½ĞµÑ€Ğ°Ğ²Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾ â€” Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ñ‹Ğµ Ğ°Ğ¹Ñ‚ĞµĞ¼Ñ‹ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°ÑÑ‚ÑÑ Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ Ñ‡Ğ°Ñ‰Ğµ, Ñ‡ĞµĞ¼ Ñ€ĞµĞ´ĞºĞ¸Ğµ (long-tail distribution). Ğ­Ñ‚Ğ¾ Ğ²Ğ²Ğ¾Ğ´Ğ¸Ñ‚ ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ: Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ²Ğ¸Ğ´Ğ¸Ñ‚ Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ñ‹Ğµ Ğ°Ğ¹Ñ‚ĞµĞ¼Ñ‹ Ñ‡Ğ°Ñ‰Ğµ ĞºĞ°Ğº Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ñ‹, Ñ‡Ñ‚Ğ¾ Ğ²Ğ»Ğ¸ÑĞµÑ‚ Ğ½Ğ° Ğ¸Ñ… Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸.\n",
        "\n",
        "ĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, ĞµÑĞ»Ğ¸ Ğ°Ğ¹Ñ‚ĞµĞ¼ A Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€ĞµĞ½ (Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°ĞµÑ‚ÑÑ), Ğ¾Ğ½ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ¿Ğ¾Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚ Ğ² Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ \"ÑĞ¸Ğ»ÑŒĞ½ĞµĞµ Ğ¾Ñ‚Ñ‚Ğ°Ğ»ĞºĞ¸Ğ²Ğ°Ñ‚ÑŒ\" ĞµĞ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ, Ğ´Ğ°Ğ¶Ğµ ĞµÑĞ»Ğ¸ ÑÑ‚Ğ¾ Ğ½Ğµ Ğ²ÑĞµĞ³Ğ´Ğ° Ğ½ÑƒĞ¶Ğ½Ğ¾. Ğ­Ñ‚Ğ¾ Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğº Ğ½ĞµĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğ¼ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼ Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ñ‹Ñ… Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ²."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3jtlmPRfjjY"
      },
      "source": [
        "â­ Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ: LogQ Correction\n",
        "\n",
        "LogQ correction ĞºĞ¾Ğ¼Ğ¿ĞµĞ½ÑĞ¸Ñ€ÑƒĞµÑ‚ ÑÑ‚Ğ¾ ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ, Ğ²Ñ‹Ñ‡Ğ¸Ñ‚Ğ°Ñ Ğ¸Ğ· ÑĞºĞ¾Ñ€Ğ° Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ° Ğ»Ğ¾Ğ³Ğ°Ñ€Ğ¸Ñ„Ğ¼ ĞµĞ³Ğ¾ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹ Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ:\n",
        "\n",
        "$$r_{i, t}^{*} = r_{i, t} - \\log(Q(i)),$$\n",
        "\n",
        "Ğ³Ğ´Ğµ $\\large{Q(i) = \\frac{\\#i}{\\#all}}$ - Ğ´Ğ¾Ğ»Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ñ Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ¼ $i$.\n",
        "\n",
        "Ğ­Ñ‚Ğ¾ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğº Ğ½ĞµÑĞ¼ĞµÑ‰Ñ‘Ğ½Ğ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ¸ÑÑ‚Ğ¸Ğ½Ğ½Ğ¾Ğ¹ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ, Ğ½ĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ Ğ¾Ñ‚ Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ°.\n",
        "\n",
        "Ğ”Ğ»Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ log-q ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ğ¸ Ğ½Ğ°Ğ¼ Ğ½Ğ°Ğ´Ğ¾ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ğ´Ğ½Ñƒ Ğ²ĞµÑ‰ÑŒ: Ğ½Ğ°Ğ´Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ¾Ğ²\n",
        "\n",
        "Ğ•ÑĞ»Ğ¸ Ğ²Ğ°Ğ¼ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞµĞ½ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ», ÑĞ¾Ğ²ĞµÑ‚ÑƒÑ Ğ¿Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ ÑÑ‚Ğ¸ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸:\n",
        "\n",
        "1. [Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations](https://research.google/pubs/sampling-bias-corrected-neural-modeling-for-large-corpus-item-recommendations/)\n",
        "1. [Correcting the LogQ Correction: Revisiting Sampled Softmax for Large-Scale Retrieval](https://arxiv.org/abs/2507.09331)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qmdiuhBfjjY"
      },
      "source": [
        "Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞ¹Ñ‚Ğµ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ in-batch negative sampling Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¿Ğ¾Ñ…Ğ¾Ğ´Ğ° LogQ correction â€” Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¾Ğ¹ Ğ´Ğ»Ñ ĞºĞ¾Ğ¼Ğ¿ĞµĞ½ÑĞ°Ñ†Ğ¸Ğ¸ ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ñ, Ğ²Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾Ğ³Ğ¾ in-batch negative sampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vYvaV5rfjjY"
      },
      "outputs": [],
      "source": [
        "def compute_item_statistics(dataset: YambdaDataset):\n",
        "    item_counts = Counter()\n",
        "    all_cnt = 0\n",
        "    idx = 0\n",
        "    while True:\n",
        "        try:\n",
        "            sample = dataset[idx]\n",
        "            for item_id in sample['labels']['item_id']:\n",
        "                item_counts[item_id] += 1\n",
        "                all_cnt += 1\n",
        "            idx += 1\n",
        "        except:\n",
        "            break\n",
        "\n",
        "    return item_counts, all_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtE783pYfjjY"
      },
      "outputs": [],
      "source": [
        "class SASRecInBatchWithLogQ(SASRecModel):\n",
        "    \"\"\"\n",
        "    SASRec with in-batch negative sampling and LogQ bias correction.\n",
        "\n",
        "    When negative samples are drawn from a batch,\n",
        "    they follow the empirical distribution of the data (popular items\n",
        "    appear more frequently), which can bias the learned embeddings.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : SASRecBackbone\n",
        "        The encoder backbone that produces contextualized user representations.\n",
        "    num_negatives : int\n",
        "        Number of negative samples per positive example (sampled from batch).\n",
        "    item_freqs : torch.Tensor\n",
        "        1D tensor of shape (num_items,) containing frequency/probability of each\n",
        "        item in the training data. Used for LogQ correction.\n",
        "        Example: item_freqs[i] = (count of item i) / (total items in dataset)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            backbone: SASRecBackbone,\n",
        "            num_negatives: int,\n",
        "            item_freqs: torch.Tensor\n",
        "        ) -> None:\n",
        "        super().__init__(backbone=backbone)\n",
        "        self.num_negatives = num_negatives\n",
        "        self.register_buffer('item_freqs', item_freqs)\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_correction(scores: torch.Tensor, freqs: torch.Tensor) -> torch.Tensor:\n",
        "        return scores - torch.log(freqs + 1e-9)\n",
        "\n",
        "    @classmethod\n",
        "    def compute_loss_inner(\n",
        "          cls,\n",
        "          user_embeddings: torch.Tensor,\n",
        "          positive_embeddings: torch.Tensor,\n",
        "          negative_embeddings: torch.Tensor,\n",
        "          negative_item_ids: torch.Tensor,\n",
        "          num_negatives: int,\n",
        "          item_freqs: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        # TODO: your code here\n",
        "        pass\n",
        "\n",
        "    def compute_loss(self, inputs: Dict[str, torch.Tensor], backbone_output: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        query_embeddings = backbone_output['encoder_output']  # (total_batch_events, embedding_dim)\n",
        "        positive_embeddings = self.backbone.item_embeddings(inputs['labels']['item_id'])  # (total_batch_events, embedding_dim)\n",
        "\n",
        "        # Ğ¡ĞµĞ¼Ğ¿Ğ»Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ñ‹ Ğ¸Ğ· Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ±Ğ°Ñ‚Ñ‡Ğ°\n",
        "        inbatch_negative_ids = torch.randint(\n",
        "            low=0,\n",
        "            high=inputs['labels']['item_id'].shape[0],\n",
        "            size=(self.num_negatives * query_embeddings.shape[0],),\n",
        "            device=positive_embeddings.device\n",
        "        )\n",
        "        inbatch_item_ids = inputs['labels']['item_id'][inbatch_negative_ids]\n",
        "\n",
        "        inbatch_negative_embeddings = self.backbone.item_embeddings(inbatch_item_ids).reshape(\n",
        "            query_embeddings.shape[0],\n",
        "            self.num_negatives,\n",
        "            query_embeddings.shape[-1]\n",
        "        )  # (total_batch_events, num_negatives, embedding_dim)\n",
        "\n",
        "        return self.compute_loss_inner(\n",
        "            query_embeddings,\n",
        "            positive_embeddings,\n",
        "            inbatch_negative_embeddings,\n",
        "            inbatch_item_ids,\n",
        "            self.num_negatives,\n",
        "            self.item_freqs\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnCv6_5YOLiz"
      },
      "outputs": [],
      "source": [
        "def test_compute_loss_inner_inbatch_logq():\n",
        "    user_emb = torch.tensor([[1.0, 0.0], [0.0, 1.0]])\n",
        "    pos_emb = torch.tensor([[100.0, 0.0], [0.0, 100.0]])\n",
        "    neg_emb = torch.tensor([\n",
        "        [[-100.0, 0.0], [0.0, -100.0], [-50.0, -50.0]],\n",
        "        [[100.0, 0.0], [-100.0, 0.0], [-50.0, -50.0]]\n",
        "    ])\n",
        "\n",
        "    num_negatives = 3\n",
        "    num_items = 100\n",
        "    item_freqs = torch.ones(num_items) * 0.01\n",
        "    negative_item_ids = torch.tensor([5, 10, 15, 20, 25, 30])\n",
        "\n",
        "    loss = SASRecInBatchWithLogQ.compute_loss_inner(\n",
        "        user_emb, pos_emb, neg_emb, negative_item_ids, num_negatives, item_freqs\n",
        "    )\n",
        "    expected_loss = 0.\n",
        "    assert abs(loss.item() - expected_loss) < 1e-2, \\\n",
        "      f'loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ€Ğ°Ğ²ĞµĞ½ {expected_loss:.3f}, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾: {loss.item():.4f}'\n",
        "\n",
        "    user_emb = torch.tensor([[1.0, 0.0], [0.0, 1.0]])\n",
        "    pos_emb = torch.tensor([[-100.0, 0.0], [0.0, -100.0]])\n",
        "    neg_emb = torch.tensor([\n",
        "        [[100.0, 0.0], [50.0, 0.0], [10.0, 0.0]],\n",
        "        [[0.0, 100.0], [0.0, 50.0], [0.0, 10.0]]\n",
        "    ])\n",
        "\n",
        "    loss = SASRecInBatchWithLogQ.compute_loss_inner(\n",
        "        user_emb, pos_emb, neg_emb, negative_item_ids, num_negatives, item_freqs\n",
        "    )\n",
        "    expected_loss = 204.6052\n",
        "    assert abs(loss.item() - expected_loss) < 1e-2, \\\n",
        "      f'loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ€Ğ°Ğ²ĞµĞ½ {expected_loss:.3f}, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾: {loss.item():.4f}'\n",
        "\n",
        "    print('âœ… test_compute_loss_inner_inbatch_logq: OK')\n",
        "\n",
        "\n",
        "test_compute_loss_inner_inbatch_logq()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6n7z15PfjjY"
      },
      "source": [
        "## ğŸ¯ Task 6. Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (1 Ğ±Ğ°Ğ»Ğ»)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu-60hVBfjjY"
      },
      "source": [
        "Ğ”Ğ»Ñ Ñ‚Ğ¾Ğ³Ğ¾, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ Ğ½Ğ°ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ°ÑˆĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ½Ğ°Ğ¼ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒÑÑ Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¼Ñ‹ Ñ…Ğ¾Ñ‚Ğ¸Ğ¼ ÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ½Ğ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ñ‚ĞµÑÑ‚Ğµ. Ğ’ Ñ€Ğ°Ğ¼ĞºĞ°Ñ… Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ ÑĞµĞ¼Ğ¸Ğ½Ğ°Ñ€Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸:\n",
        "\n",
        "$$\\text{HitRate@k} = \\frac{1}{|S|} \\sum_{S^u \\in S}{ \\mathbb{I} [ \\text{positive} \\in \\text{recommended}[:\\text{k}]] },$$\n",
        "\n",
        "$$\\text{DCG@k} = \\frac{1}{|S|}\\sum_{S^u \\in S}{}{\\sum_{i = 1}^{k} \\frac{\\mathbb{I} [ \\text{recommended}^u_i = \\text{positive} ] }{\\log_2(i + 1)}},$$\n",
        "\n",
        "$$\\text{Coverage@k} = \\frac{ \\bigcup_{S^u \\in S}{ \\bigcup_{i=1}^{k}{ \\text{recommended}^u_i}} }{|\\mathcal{I}|},$$\n",
        "\n",
        "Ğ³Ğ´Ğµ $\\text{positive}$ - ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞµ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ, Ğ° $\\text{recommended}$ - ÑƒĞ¿Ğ¾Ñ€ÑĞ´Ğ¾Ñ‡ĞµĞ½Ğ½Ğ°Ñ Ğ²Ñ‹Ğ´Ğ°Ñ‡Ğ°, ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ°Ğ¹Ğ´Ğ¸ÑˆĞ½Ğ¸ĞºĞ¾Ğ² ÑƒĞ¿Ğ¾Ñ€ÑĞ´Ğ¾Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾ ÑƒĞ±Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ. $\\mathcal{I}$ - Ğ²ĞµÑÑŒ ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³ Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ².\n",
        "\n",
        "Ğ’Ğ°Ğ¶Ğ½Ğ¾ Ğ·Ğ°Ğ¼ĞµÑ‚Ğ¸Ñ‚ÑŒ, Ñ‡Ñ‚Ğ¾ Ñ‚Ğ°Ğº ĞºĞ°Ğº Ñƒ Ğ½Ğ°Ñ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ğ´Ğ¸Ğ½ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ², Ñ‚Ğ¾ Ğ´Ğ»Ñ Ğ½Ğ°ÑˆĞµĞ³Ğ¾ ÑĞ»ÑƒÑ‡Ğ°Ñ $\\text{HitRate@k} = \\text{Recall@k}$ Ğ¸ $\\text{DCG@k} = \\text{nDCG@k}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb7fEmVrfjjY"
      },
      "outputs": [],
      "source": [
        "def compute_hitrate(all_scores: torch.Tensor, positive_scores: torch.Tensor, k: int) -> List[float]:\n",
        "    \"\"\"\n",
        "    Computes Hit Rate@k for each sample in the batch.\n",
        "\n",
        "    Hit Rate measures whether the ground truth positive item appears in the top-k\n",
        "    ranked items. For each user, it's a binary metric: 1 if the positive item is\n",
        "    in top-k, 0 otherwise.\n",
        "\n",
        "    Hit Rate@k = 1 if rank(positive_item) < k, else 0\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    all_scores : torch.Tensor\n",
        "        Relevance scores for all items in the catalog, shape (batch_size, num_items).\n",
        "        Higher scores indicate higher relevance.\n",
        "    positive_scores : torch.Tensor\n",
        "        Relevance scores for the ground truth positive items (targets),\n",
        "        shape (batch_size,).\n",
        "    k : int\n",
        "        Cutoff for top-k evaluation. Typical values: 1, 5, 10, 20, 50, 100.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[float]\n",
        "        Hit Rate values for each sample in the batch, shape (batch_size,).\n",
        "        Each value is either 0.0 (miss) or 1.0 (hit).\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    pass\n",
        "\n",
        "\n",
        "def compute_dcg(all_scores: torch.Tensor, positive_scores: torch.Tensor, k: int) -> List[float]:\n",
        "    \"\"\"\n",
        "    Computes DCG@k for each sample in the batch.\n",
        "\n",
        "    DCG (Discounted Cumulative Gain) measures ranking quality with position discount.\n",
        "    For a single positive item at position p (0-indexed):\n",
        "        DCG@k = 1 / log2(p + 2) if p < k else 0\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    all_scores : torch.Tensor\n",
        "        Scores for all items, shape (batch_size, num_items).\n",
        "    positive_scores : torch.Tensor\n",
        "        Scores for the ground truth positive items, shape (batch_size,).\n",
        "    k : int\n",
        "        Cutoff for evaluation (top-k).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[float]\n",
        "        DCG@k values for each sample in the batch.\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    pass\n",
        "\n",
        "\n",
        "def compute_metrics(all_scores: torch.Tensor, positive_scores: torch.Tensor) -> Dict[str, float]:\n",
        "    return {\n",
        "        'dcg@10': compute_dcg(all_scores, positive_scores, k=10),\n",
        "        'dcg@100': compute_dcg(all_scores, positive_scores, k=100),\n",
        "        'dcg@1000': compute_dcg(all_scores, positive_scores, k=1000),\n",
        "\n",
        "        'hitrate@10': compute_hitrate(all_scores, positive_scores, k=10),\n",
        "        'hitrate@100': compute_hitrate(all_scores, positive_scores, k=100),\n",
        "        'hitrate@1000': compute_hitrate(all_scores, positive_scores, k=1000),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOdVHjr8fjjY"
      },
      "outputs": [],
      "source": [
        "def test_compute_hitrate():\n",
        "    assert compute_hitrate(torch.tensor([[0.9, 0.5]]), torch.tensor([0.9]), k=1) == [1.0]\n",
        "    assert compute_hitrate(torch.tensor([[0.9, 0.5]]), torch.tensor([0.5]), k=1) == [0.0]\n",
        "    assert compute_hitrate(torch.tensor([[0.9, 0.5]]), torch.tensor([0.5]), k=2) == [1.0]\n",
        "\n",
        "    all_scores = torch.tensor([[0.9, 0.5, 0.3], [0.9, 0.8, 0.7]])\n",
        "    positive = torch.tensor([0.9, 0.8])\n",
        "    assert compute_hitrate(all_scores, positive, k=2) == [1.0, 1.0]\n",
        "\n",
        "    print('âœ… test_compute_hitrate: OK')\n",
        "\n",
        "\n",
        "def test_compute_dcg():\n",
        "    import math\n",
        "\n",
        "    assert abs(compute_dcg(torch.tensor([[0.9, 0.5]]), torch.tensor([0.9]), k=2)[0] - 1.0) < 1e-5\n",
        "\n",
        "    expected = 1.0 / math.log2(3)\n",
        "    assert abs(compute_dcg(torch.tensor([[0.9, 0.5]]), torch.tensor([0.5]), k=2)[0] - expected) < 1e-5\n",
        "\n",
        "    assert abs(compute_dcg(torch.tensor([[0.9, 0.8, 0.5]]), torch.tensor([0.5]), k=3)[0] - 0.5) < 1e-5\n",
        "\n",
        "    assert compute_dcg(torch.tensor([[0.9, 0.8, 0.7, 0.5]]), torch.tensor([0.5]), k=2)[0] == 0.0\n",
        "\n",
        "    print('âœ… test_compute_dcg: OK')\n",
        "\n",
        "\n",
        "test_compute_hitrate()\n",
        "test_compute_dcg()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNy5CVEXfjjY"
      },
      "source": [
        "# ğŸ”¥ ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfKzTo1fjjY"
      },
      "source": [
        "## ğŸ° Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ / ÑĞ²Ğ°Ğ» Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3V_FSkPfjjY"
      },
      "outputs": [],
      "source": [
        "def evaluation(\n",
        "        dataloader: DataLoader,\n",
        "        model: SASRecModel,\n",
        "        device: str = 'cpu',\n",
        "        num_batches: Optional[int] = None\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    eval_metrics = defaultdict(list)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for idx, batch in tqdm(enumerate(dataloader)):\n",
        "        for key in batch:\n",
        "            if isinstance(batch[key], dict):\n",
        "                for sub_key in batch[key]:\n",
        "                    batch[key][sub_key] = batch[key][sub_key].to(device)\n",
        "            else:\n",
        "                assert isinstance(batch[key], torch.Tensor)\n",
        "                batch[key] = batch[key].to(device)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            model_output = model(batch)\n",
        "            batch_metrics = compute_metrics(model_output['all_scores'], model_output['positive_scores'])\n",
        "        for key, values in batch_metrics.items():\n",
        "            eval_metrics[key].extend(values)\n",
        "\n",
        "        if num_batches is not None and idx + 1 >= num_batches:\n",
        "            break\n",
        "\n",
        "    for key, values in eval_metrics.items():\n",
        "        eval_metrics[key] = np.mean(values)\n",
        "\n",
        "    return eval_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw--Hmi6fjjZ"
      },
      "source": [
        "## ğŸ” Ğ¦Ğ¸ĞºĞ» Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JMC0jMAfjjZ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(\n",
        "        train_dataloader: DataLoader,\n",
        "        valid_dataloader: DataLoader,\n",
        "        model: torch.nn.Module,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        num_epochs: int | None = None,\n",
        "        device: str = 'cpu',\n",
        "        num_valid_batches: Optional[int] = None\n",
        "    ) -> torch.nn.Module:\n",
        "    step_num = 0\n",
        "    epoch_num = 0\n",
        "\n",
        "    best_checkpoint = None\n",
        "    best_metric_name = 'dcg@1000'\n",
        "    best_metric_value = float('-inf')\n",
        "\n",
        "    while num_epochs is None or epoch_num < num_epochs:\n",
        "        print(f'Start epoch {epoch_num + 1}')\n",
        "        running_loss = []\n",
        "\n",
        "        for batch in tqdm(train_dataloader):\n",
        "            model.train()\n",
        "\n",
        "            for key in batch:\n",
        "                if isinstance(batch[key], dict):\n",
        "                    for sub_key in batch[key]:\n",
        "                        batch[key][sub_key] = batch[key][sub_key].to(device)\n",
        "                else:\n",
        "                    assert isinstance(batch[key], torch.Tensor)\n",
        "                    batch[key] = batch[key].to(device)\n",
        "\n",
        "            loss = model(batch)['loss']\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            step_num += 1\n",
        "\n",
        "            running_loss.append(loss.item())\n",
        "\n",
        "        valid_metrics = evaluation(valid_dataloader, model, device, num_valid_batches)\n",
        "\n",
        "        if best_metric_value is None or best_metric_value < valid_metrics[best_metric_name]:\n",
        "            best_metric_value = valid_metrics[best_metric_name]\n",
        "            best_checkpoint = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "        msgs = []\n",
        "        for metric_name, metrinc_value in valid_metrics.items():\n",
        "            msgs.append(f'{metric_name}: {round(metrinc_value, 5)}')\n",
        "        msg = ', '.join(msgs)\n",
        "        print(msg)\n",
        "\n",
        "        print(f'Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ»Ğ¾ÑÑ Ğ½Ğ° ÑĞ¿Ğ¾Ñ…Ğµ #{epoch_num + 1}: {round(np.mean(running_loss), 5)}')\n",
        "\n",
        "        epoch_num += 1\n",
        "\n",
        "    print('ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾!')\n",
        "\n",
        "    return best_checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn_BUqnQfjjZ"
      },
      "source": [
        "## ğŸ Ğ’ÑĞµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UanC70x9fjjZ"
      },
      "source": [
        "1ï¸âƒ£ Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-BbvO4DcAQs"
      },
      "outputs": [],
      "source": [
        "train_dataset = YambdaDataset(\n",
        "    dataframe=train_data,\n",
        "    max_seq_len=MAX_SEQ_LEN\n",
        ")\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=2,\n",
        "    prefetch_factor=4,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmmO725-cF9h"
      },
      "outputs": [],
      "source": [
        "valid_dataset = YambdaDataset(\n",
        "  dataframe=valid_data,\n",
        "  max_seq_len=MAX_SEQ_LEN\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=False,\n",
        "    num_workers=2,\n",
        "    prefetch_factor=4,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dl8ADMOfjjZ"
      },
      "outputs": [],
      "source": [
        "eval_dataset = YambdaDataset(\n",
        "    dataframe=eval_data,\n",
        "    max_seq_len=MAX_SEQ_LEN\n",
        "  )\n",
        "eval_dataloader = DataLoader(\n",
        "    dataset=eval_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=False,\n",
        "    num_workers=2,\n",
        "    prefetch_factor=4,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cupZrWKrfjjZ"
      },
      "source": [
        "2ï¸âƒ£ ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ `SASRecReal`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WZcnsmbfjjZ"
      },
      "outputs": [],
      "source": [
        "model_real = SASRecReal(\n",
        "    backbone=SASRecBackbone(\n",
        "        num_items=len(item_mapping),\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        num_heads=NUM_HEADS,\n",
        "        max_seq_len=MAX_SEQ_LEN,\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        num_transformer_layers=NUM_TRANSFORMER_LAYERS\n",
        "    )\n",
        ").to(DEVICE)\n",
        "optimizer_real = torch.optim.Adam(params=model_real.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "best_checkpoint_real = train(\n",
        "    train_dataloader=train_dataloader,\n",
        "    valid_dataloader=valid_dataloader,\n",
        "    model=model_real,\n",
        "    optimizer=optimizer_real,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2KBYEIBfjjZ"
      },
      "source": [
        "3ï¸âƒ£ ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ `SASRecInBatch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "burfluTefjjZ"
      },
      "outputs": [],
      "source": [
        "model_in_batch = SASRecInBatch(\n",
        "    backbone=SASRecBackbone(\n",
        "        num_items=len(item_mapping),\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        num_heads=NUM_HEADS,\n",
        "        max_seq_len=MAX_SEQ_LEN,\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        num_transformer_layers=NUM_TRANSFORMER_LAYERS\n",
        "    ),\n",
        "    num_negatives=TRAIN_BATCH_SIZE\n",
        ").to(DEVICE)\n",
        "optimizer_in_batch = torch.optim.Adam(params=model_in_batch.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "best_checkpoint_in_batch = train(\n",
        "    train_dataloader=train_dataloader,\n",
        "    valid_dataloader=valid_dataloader,\n",
        "    model=model_in_batch,\n",
        "    optimizer=optimizer_in_batch,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDsrrxt2fjjZ"
      },
      "source": [
        "4ï¸âƒ£ ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ `SASRecInBatchWithLogQ`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XECzSR7dfjjZ"
      },
      "outputs": [],
      "source": [
        "item_freqs = torch.zeros(len(item_mapping), dtype=torch.float32)\n",
        "\n",
        "item_statistics, num_labels = compute_item_statistics(train_dataset)\n",
        "for key, val in item_statistics.items():\n",
        "    item_freqs[key] = val / num_labels\n",
        "    assert 0 <= item_freqs[key] < 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCoWYEC9PQYM"
      },
      "outputs": [],
      "source": [
        "model_inbatch_logq = SASRecInBatchWithLogQ(\n",
        "    backbone=SASRecBackbone(\n",
        "        num_items=len(item_mapping),\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        num_heads=NUM_HEADS,\n",
        "        max_seq_len=MAX_SEQ_LEN,\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        num_transformer_layers=NUM_TRANSFORMER_LAYERS\n",
        "    ),\n",
        "    num_negatives=TRAIN_BATCH_SIZE,\n",
        "    item_freqs=item_freqs\n",
        ").to(DEVICE)\n",
        "optimizer_inbatch_logq = torch.optim.Adam(params=model_inbatch_logq.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "best_checkpoint_inbatch_logq = train(\n",
        "    train_dataloader=train_dataloader,\n",
        "    valid_dataloader=valid_dataloader,\n",
        "    model=model_inbatch_logq,\n",
        "    optimizer=optimizer_inbatch_logq,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOhXysIYfjjZ"
      },
      "source": [
        "# Task 7. ĞŸĞ¾Ğ±Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ñ€Ğ¾Ğ³Ğ¸ Ğ½Ğ° Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞµ (1 Ğ±Ğ°Ğ»Ğ»)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmJaplVefjjZ"
      },
      "source": [
        "1ï¸âƒ£ Ğ˜Ğ·Ğ¼ĞµÑ€ÑĞµĞ¼ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ° Ñ‚ĞµÑÑ‚Ğµ Ğ´Ğ»Ñ `SASRecReal`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcmJplYwfjjZ"
      },
      "outputs": [],
      "source": [
        "def test_model_real_quality():\n",
        "    model_real.load_state_dict(best_checkpoint_real)\n",
        "    eval_metrics = evaluation(valid_dataloader, model_real, device=DEVICE)\n",
        "    print(eval_metrics)\n",
        "\n",
        "    thresholds = {\n",
        "        'dcg@10': 0.0016,\n",
        "        'dcg@100': 0.006,\n",
        "        'dcg@1000': 0.021,\n",
        "        'hitrate@10': 0.0035,\n",
        "        'hitrate@100': 0.027,\n",
        "        'hitrate@1000': 0.15\n",
        "    }\n",
        "\n",
        "    for metric_name, threshold in thresholds.items():\n",
        "        actual = eval_metrics[metric_name]\n",
        "        assert actual >= threshold, \\\n",
        "            f'âŒ {metric_name}: {actual} < {threshold}'\n",
        "        print(f'âœ… {metric_name}: {actual} >= {threshold}')\n",
        "\n",
        "    print('\\nâœ… test_model_real_quality: OK')\n",
        "test_model_real_quality()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1k2dZMJfjjZ"
      },
      "source": [
        "2ï¸âƒ£ Ğ˜Ğ·Ğ¼ĞµÑ€ÑĞµĞ¼ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ° Ñ‚ĞµÑÑ‚Ğµ Ğ´Ğ»Ñ `SASRecInBatch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sdr6ZgV7fjjZ"
      },
      "outputs": [],
      "source": [
        "def test_model_in_batch_quality():\n",
        "    model_in_batch.load_state_dict(best_checkpoint_in_batch)\n",
        "    eval_metrics = evaluation(valid_dataloader, model_in_batch, device=DEVICE)\n",
        "    print(eval_metrics)\n",
        "\n",
        "    thresholds = {\n",
        "        'dcg@10': 0.007,\n",
        "        'dcg@100': 0.015,\n",
        "        'dcg@1000': 0.034,\n",
        "        'hitrate@10': 0.012,\n",
        "        'hitrate@100': 0.059,\n",
        "        'hitrate@1000': 0.23\n",
        "    }\n",
        "\n",
        "    for metric_name, threshold in thresholds.items():\n",
        "        actual = eval_metrics[metric_name]\n",
        "        assert actual >= threshold, \\\n",
        "            f'âŒ {metric_name}: {actual} < {threshold}'\n",
        "        print(f'âœ… {metric_name}: {actual} >= {threshold}')\n",
        "\n",
        "    print('\\nâœ… test_model_in_batch_quality: OK')\n",
        "\n",
        "test_model_in_batch_quality()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BivKLlo8fjjZ"
      },
      "source": [
        "3ï¸âƒ£ Ğ˜Ğ·Ğ¼ĞµÑ€ÑĞµĞ¼ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ° Ñ‚ĞµÑÑ‚Ğµ Ğ´Ğ»Ñ `SASRecInBatchWithLogq`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8fXEIydfjjZ"
      },
      "outputs": [],
      "source": [
        "def test_model_in_batch_logq_quality():\n",
        "    model_inbatch_logq.load_state_dict(best_checkpoint_inbatch_logq)\n",
        "    eval_metrics = evaluation(valid_dataloader, model_inbatch_logq, device=DEVICE)\n",
        "    print(eval_metrics)\n",
        "\n",
        "    thresholds = {\n",
        "        'dcg@10': 0.007,\n",
        "        'dcg@100': 0.015,\n",
        "        'dcg@1000': 0.035,\n",
        "        'hitrate@10': 0.013,\n",
        "        'hitrate@100': 0.059,\n",
        "        'hitrate@1000': 0.23\n",
        "    }\n",
        "\n",
        "    for metric_name, threshold in thresholds.items():\n",
        "        actual = eval_metrics[metric_name]\n",
        "        assert actual >= threshold, \\\n",
        "            f'âŒ {metric_name}: {actual} < {threshold}'\n",
        "        print(f'âœ… {metric_name}: {actual} >= {threshold}')\n",
        "\n",
        "    print('\\nâœ… test_model_in_batch_logq_quality: OK')\n",
        "\n",
        "test_model_in_batch_logq_quality()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtILpQlHfjjZ"
      },
      "source": [
        "# ğŸ§  ĞĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ñ‹\n",
        "\n",
        "Ğ¡Ñ‚Ğ°Ñ‚ÑŒĞ¸ Ğ¸Ğ· Ğ¸Ğ½Ğ´ÑƒÑÑ‚Ñ€Ğ¸Ğ¸:\n",
        "1. [PinnerFormer: Sequence Modeling for User Representation at Pinterest](https://arxiv.org/pdf/2205.04507)\n",
        "1. [Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations](https://arxiv.org/pdf/2402.17152v1)\n",
        "1. [Better Generalization with Semantic IDs: A Case Study in Ranking for Recommendations](https://arxiv.org/pdf/2306.08121)\n",
        "1. [Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations](https://research.google/pubs/sampling-bias-corrected-neural-modeling-for-large-corpus-item-recommendations/)\n",
        "1. [Correcting the LogQ Correction: Revisiting Sampled Softmax for Large-Scale Retrieval](https://arxiv.org/abs/2507.09331)\n",
        "\n",
        "\n",
        "ĞŸÑ€Ğ¾ Ñ‚Ğ¾, ĞºĞ°Ğº Ğ½Ğ°Ğ´Ğ¾ Ğ¸ Ğ½Ğµ Ğ½Ğ°Ğ´Ğ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ:\n",
        "1. [A Critical Study on Data Leakage in Recommender System Offline Evaluation](https://dl.acm.org/doi/full/10.1145/3569930)\n",
        "1. [Exploring Data Splitting Strategies for the Evaluation of Recommendation Models](https://arxiv.org/pdf/2007.13237)\n",
        "\n",
        "\n",
        "Ğ¡Ñ‚Ğ°Ñ‚ÑŒĞ¸ Ğ¸Ğ· Ğ°ĞºĞ°Ğ´ĞµĞ¼Ğ¸Ğ¸:\n",
        "1. [SASRec: Self-Attentive Sequential Recommendation](https://arxiv.org/abs/1808.09781)\n",
        "1. [BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer](https://arxiv.org/abs/1904.06690)\n",
        "1. [A Systematic Review and Replicability Study of BERT4Rec for Sequential Recommendation](https://dl.acm.org/doi/10.1145/3523227.3548487)\n",
        "1. [CL4SRec Contrastive Learning for Sequential Recommendation](https://arxiv.org/abs/2010.14395)\n",
        "1. [DuoRec: Contrastive Learning for Representation Degeneration Problem in Sequential Recommendation](https://arxiv.org/abs/2110.05730)\n",
        "\n",
        "\n",
        "ĞŸÑ€Ğ¾ Ğ¸Ğ½Ñ„Ñ€Ñƒ:\n",
        "1. [Semantic Product Search](https://dl.acm.org/doi/10.1145/3292500.3330759)\n",
        "1. [Monolith: Real Time Recommendation System With Collisionless Embedding Table](https://arxiv.org/pdf/2209.07663)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y0Fg-OPIFA2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a19f38e77ca343d8891603ba1371c27d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7998c1d3b9314cf195a3b75aa04f8f65",
              "IPY_MODEL_1241b01b94e1464695f519e5a399b4c1",
              "IPY_MODEL_d24ddbda0a154d579652b340394c3f18"
            ],
            "layout": "IPY_MODEL_b0e63cf89b66449f811dd2b91a0bea0a"
          }
        },
        "7998c1d3b9314cf195a3b75aa04f8f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f12cc45275234b10a03e0ed04839dfbf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c9a7e02e565f4bc486cc818f49b01906",
            "value": "README.md:â€‡"
          }
        },
        "1241b01b94e1464695f519e5a399b4c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e626216099c740f6b0316eda58639e60",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f271932ca6604856bd6e01ae44384bc1",
            "value": 1
          }
        },
        "d24ddbda0a154d579652b340394c3f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b59a67ece2d34349a58bbd7b59cb1723",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9e0dc61a030b4f8e95ab05a581e45ece",
            "value": "â€‡11.8k/?â€‡[00:00&lt;00:00,â€‡802kB/s]"
          }
        },
        "b0e63cf89b66449f811dd2b91a0bea0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f12cc45275234b10a03e0ed04839dfbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a7e02e565f4bc486cc818f49b01906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e626216099c740f6b0316eda58639e60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f271932ca6604856bd6e01ae44384bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b59a67ece2d34349a58bbd7b59cb1723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e0dc61a030b4f8e95ab05a581e45ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "741b63b59b4e45bfb97ea85050cbbd51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee4bbb16e4a74c81ad93db2322cab9da",
              "IPY_MODEL_2334192d66484be083cce210808553df",
              "IPY_MODEL_3a5c4f4a9242445392f49c09adfa1efe"
            ],
            "layout": "IPY_MODEL_3f03450e18b24d5b9757cc069aaa3240"
          }
        },
        "ee4bbb16e4a74c81ad93db2322cab9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f96f92842744c8cb891180fbfc4140c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0ef6463ec67440e39fd1268b87cd5807",
            "value": "sequential/50m/listens.parquet:â€‡100%"
          }
        },
        "2334192d66484be083cce210808553df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89a4e953129646c79e44c68b21cb649c",
            "max": 426248769,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faf91d36d9c647d0a376951b849bf7a1",
            "value": 426248769
          }
        },
        "3a5c4f4a9242445392f49c09adfa1efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7001ce47bbe04751b12d9ff05019bf99",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_97778bf609df4aee87efd361cc3cd3d0",
            "value": "â€‡426M/426Mâ€‡[00:03&lt;00:00,â€‡223MB/s]"
          }
        },
        "3f03450e18b24d5b9757cc069aaa3240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f96f92842744c8cb891180fbfc4140c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ef6463ec67440e39fd1268b87cd5807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89a4e953129646c79e44c68b21cb649c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf91d36d9c647d0a376951b849bf7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7001ce47bbe04751b12d9ff05019bf99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97778bf609df4aee87efd361cc3cd3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b835109422f14b868bb52affb65e7cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f166891335d42c7b4d842dcaae0f730",
              "IPY_MODEL_22f48b12a5c94d4f9daf6918d308434d",
              "IPY_MODEL_46056633d40b4565b71c29acf779254e"
            ],
            "layout": "IPY_MODEL_a6c5bccfa5a7407eb46b125f7fd932b7"
          }
        },
        "3f166891335d42c7b4d842dcaae0f730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c3b91d0190f423ebcdab728b8ee8868",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ad9b1ed288e64a41a88c57993a623fd8",
            "value": "Generatingâ€‡trainâ€‡split:â€‡"
          }
        },
        "22f48b12a5c94d4f9daf6918d308434d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ccde9ffa234c57bc0b0e755851b42d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d28149e272474d04aa91138ba04659af",
            "value": 1
          }
        },
        "46056633d40b4565b71c29acf779254e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d83a163030dc40e9a471356a618afe5a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_483b199c92fe4c23828f70dedae7112b",
            "value": "â€‡9238/0â€‡[00:16&lt;00:00,â€‡547.33â€‡examples/s]"
          }
        },
        "a6c5bccfa5a7407eb46b125f7fd932b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c3b91d0190f423ebcdab728b8ee8868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad9b1ed288e64a41a88c57993a623fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76ccde9ffa234c57bc0b0e755851b42d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d28149e272474d04aa91138ba04659af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d83a163030dc40e9a471356a618afe5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "483b199c92fe4c23828f70dedae7112b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}