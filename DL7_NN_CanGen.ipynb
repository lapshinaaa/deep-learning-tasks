{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lapshinaaa/deep-learning-tasks/blob/main/DL7_NN_CanGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWCQnbMRfjjQ"
      },
      "source": [
        "<h1><center>NN Approaches to CanGen in RecSys</center></h1>\n",
        "\n",
        "Author of the tasks: Vladimir Baikalov (Telegram: @noname_untitled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfXKc8fbfjjR"
      },
      "source": [
        "In this assignment, you will implement and study neural network models for the candidate generation task in recommender systems. Using the Yandex Music logs dataset [\"Yambda\"](https://huggingface.co/datasets/yandex/yambda), you will:\n",
        "\n",
        "1) Prepare data for training neural recommendation models  \n",
        "2) Implement SASRec â€” one of the most effective architectures for modeling user sequences  \n",
        "3) Experiment with different loss functions and analyze their impact on model quality and performance  \n",
        "4) Evaluate the results and draw conclusions about how the choice of loss function affects the final model quality  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olc1prCGfjjR"
      },
      "source": [
        "In this assignment, you are expected to independently implement the key stages of the training pipeline for candidate generation on sequential user data â€” from raw data preparation to metric computation on validation and test sets.\n",
        "\n",
        "In all code cells marked with `# TODO: your code here`, you need to write your own code implementing the corresponding stage of processing, filtering, mapping, dataset construction, or model components. This may include functions, filters, pipeline structures, class implementations, and methods.\n",
        "\n",
        "At the end of each subtask, you will encounter sanity checks â€” lightweight tests that provide basic validation of your solutions but are NOT exhaustive. Passing these checks does not guarantee full correctness, but they help quickly catch common mistakes and typos at early stages.\n",
        "\n",
        "Your task is to complete the entire pipeline â€” from raw data to trained models and final quality metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1F06lkjfjjR"
      },
      "source": [
        "# ğŸ”§ Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BHw4JjTfjjR"
      },
      "source": [
        "## ğŸ“¦ Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtyobnaKfjjR",
        "outputId": "8caa68c3-92da-4796-d59b-044a40ab10a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==4.4.1\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (2.0.2)\n",
            "Collecting pyarrow>=21.0.0 (from datasets==4.4.1)\n",
            "  Downloading pyarrow-23.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (3.13.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets==4.4.1) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets==4.4.1) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets==4.4.1) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets==4.4.1) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets==4.4.1) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets==4.4.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets==4.4.1) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==4.4.1) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==4.4.1) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.4.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.4.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.4.1) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==4.4.1) (1.17.0)\n",
            "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-23.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed datasets-4.4.1 pyarrow-23.0.0\n",
            "Collecting polars==1.33.1\n",
            "  Downloading polars-1.33.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Downloading polars-1.33.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: polars\n",
            "  Attempting uninstall: polars\n",
            "    Found existing installation: polars 1.31.0\n",
            "    Uninstalling polars-1.31.0:\n",
            "      Successfully uninstalled polars-1.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-polars-cu12 25.10.0 requires polars<1.33,>=1.28, but you have polars 1.33.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed polars-1.33.1\n"
          ]
        }
      ],
      "source": [
        "# keep the versions\n",
        "!pip install datasets==4.4.1 -i https://pypi.org/simple\n",
        "!pip install polars==1.33.1 -i https://pypi.org/simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j0dQ5KafjjS"
      },
      "source": [
        "## ğŸ“š Library Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SbkKok0dfjjS"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import polars as pl\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAKFAslVfjjS"
      },
      "source": [
        "## âš™ï¸ Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VBLvaJ4byhXk"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(1337)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MXXnSQUzfjjS"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "HOUR_SECONDS = 60 * 60\n",
        "DAY_SECONDS = 24 * HOUR_SECONDS\n",
        "\n",
        "VAL_SIZE = 1 * DAY_SECONDS\n",
        "TEST_SIZE = 1 * DAY_SECONDS\n",
        "\n",
        "LAST_TIMESTAMP = 26000000\n",
        "TEST_TIMESTAMP = LAST_TIMESTAMP - TEST_SIZE\n",
        "\n",
        "# Model\n",
        "HASH_DIM = 64\n",
        "LEARNING_RATE = 1e-3\n",
        "TRAIN_BATCH_SIZE = 256\n",
        "VALID_BATCH_SIZE = 1024\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "EMBEDDING_DIM = 64\n",
        "NUM_HEADS = 2\n",
        "MAX_SEQ_LEN = 200\n",
        "MIN_SEQ_LEN = 2\n",
        "DROPOUT_RATE = 0.1\n",
        "NUM_TRANSFORMER_LAYERS = 2\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZlHMLqRfjjS"
      },
      "source": [
        "# ğŸ—‚ï¸ Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik2EZ_EkfjjS"
      },
      "source": [
        "## ğŸµ Dataset: Yandex Music Behavior (Yambda)\n",
        "\n",
        "The Yandex Music user behavior dataset contains real listening histories from a music streaming service, including detailed information about userâ€“track interactions. Each record represents a sequence of events for a user, capturing timestamps, track metadata, and engagement metrics.\n",
        "\n",
        "Data structure:\n",
        "- uid: unique user identifier  \n",
        "- item_id: sequence of track identifiers listened to by the user  \n",
        "- timestamp: event time in seconds since the Unix epoch  \n",
        "- played_ratio_pct: percentage of the track that was listened to (0â€“100%)  \n",
        "- is_organic: organic interaction flag (1 = user actively chose the track, 0 = recommendation)  \n",
        "- track_length_seconds: track duration in seconds  \n",
        "\n",
        "The dataset is well suited for evaluating sequential recommendation models due to its scale, chronological structure, and rich signals of real user behavior.\n",
        "\n",
        "---\n",
        "\n",
        "### Yambda dataset variants\n",
        "\n",
        "Yambda is available in multiple formats and sizes.\n",
        "\n",
        "Formats:\n",
        "- flat: raw event logs without grouping (each event is a separate row)  \n",
        "- sequence: pre-grouped user interaction sequences (ready-to-use histories)\n",
        "\n",
        "Sizes:\n",
        "- 50m: 50 million events (compact version for local experimentation)  \n",
        "- 500m: 500 million events (medium scale)  \n",
        "- 5b: 5 billion events (full dataset)\n",
        "\n",
        "In this work, we use the sequence format with size 50m for speed and resource accessibility. However, it is worth noting that on larger variants (500m and 5b), the advantages of neural approaches over classical methods become much more pronounced. Interested readers can explore this further in the [Yandex research paper](https://arxiv.org/abs/2505.22238)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TZN_kALfjjT"
      },
      "source": [
        "#### Func for sequential split into train/val/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9n-mLfydfjjT"
      },
      "outputs": [],
      "source": [
        "# Source: https://huggingface.co/datasets/yandex/yambda\n",
        "\n",
        "def sequential_split_train_val_test(\n",
        "    df: pl.LazyFrame,\n",
        "    test_timestamp: int,\n",
        "    val_size: int = 0,\n",
        "    gap_size: int = 0,\n",
        "    drop_non_train_items: bool = False,\n",
        "    engine: str = 'streaming',\n",
        ") -> tuple[pl.LazyFrame, pl.LazyFrame | None, pl.LazyFrame]:\n",
        "    \"\"\"\n",
        "    Splits the dataset into training, validation, and test segments based on the provided timestamps.\n",
        "\n",
        "    The segments are defined as follows:\n",
        "    - Training set: [0, test_timestamp - gap_size - val_size - gap_size) if val_size != 0,\n",
        "                    otherwise [0, test_timestamp - gap_size)\n",
        "    - Validation set: [test_timestamp - val_size - gap_size, test_timestamp - gap_size), if val_size != 0\n",
        "    - Test set: [test_timestamp, +inf)\n",
        "\n",
        "    It retains only those users and items in the validation and test sets that exist in the training set.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    df : LazyFrame\n",
        "        The dataset in Polars' LazyFrame format.\n",
        "    test_timestamp : int | None\n",
        "        The timestamp marking the start of the test set;\n",
        "    val_size : int | None\n",
        "        The size of validation. If 0, no validation set is created.\n",
        "    gap_size : int\n",
        "        The duration of gap between training and validation/test sets.\n",
        "    drop_non_train_items : bool\n",
        "        Whether to drop items that are not in the training set.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    tuple[LazyFrame, LazyFrame | None, LazyFrame]\n",
        "        A tuple containing LazyFrames for the training, validation (if applicable), and test sets.\n",
        "    \"\"\"\n",
        "\n",
        "    def drop(df: pl.LazyFrame, unique_train_item_ids) -> pl.LazyFrame:\n",
        "        if not drop_non_train_items:\n",
        "            return df\n",
        "\n",
        "        return df.select(\n",
        "            'uid',\n",
        "            pl.all()\n",
        "            .exclude('uid')\n",
        "            .list.gather(\n",
        "                pl.col('item_id').list.eval(\n",
        "                    pl.arg_where(pl.element().is_in(unique_train_item_ids.get_column('item_id').implode()))\n",
        "                )\n",
        "            ),\n",
        "        ).filter(pl.col('item_id').list.len() > 0)\n",
        "\n",
        "    train_timestamp = test_timestamp - gap_size - val_size - (gap_size if val_size != 0 else 0)\n",
        "\n",
        "    assert gap_size >= 0\n",
        "    assert val_size >= 0\n",
        "    assert train_timestamp > 0\n",
        "\n",
        "    df_lazy = df.lazy()\n",
        "\n",
        "    train = df_lazy.select(\n",
        "        'uid',\n",
        "        pl.all()\n",
        "        .exclude('uid')\n",
        "        .list.gather(pl.col('timestamp').list.eval(pl.arg_where(pl.element() < train_timestamp))),\n",
        "    ).filter(pl.col('item_id').list.len() > 0)\n",
        "\n",
        "    unique_train_uids = train.select('uid').unique().collect(engine=engine)\n",
        "    unique_train_item_ids = train.explode('item_id').select('item_id').unique().collect(engine=engine)\n",
        "\n",
        "    validation = None\n",
        "    if val_size != 0:\n",
        "        validation = (\n",
        "            df_lazy.select(\n",
        "                'uid',\n",
        "                pl.all()\n",
        "                .exclude('uid')\n",
        "                .list.gather(\n",
        "                    pl.col('timestamp').list.eval(\n",
        "                        pl.arg_where(\n",
        "                            (pl.element() >= test_timestamp - val_size - gap_size)\n",
        "                            & (pl.element() < test_timestamp - gap_size)\n",
        "                        )\n",
        "                    )\n",
        "                ),\n",
        "            )\n",
        "            .with_columns(\n",
        "                pl.col('uid').is_in(unique_train_uids.get_column('uid').implode()).alias('uid_in_train')\n",
        "            )  # to prevent filter reordering\n",
        "            .filter('uid_in_train')\n",
        "            .drop('uid_in_train')\n",
        "        )\n",
        "\n",
        "        validation = drop(validation, unique_train_item_ids).filter(pl.col('item_id').list.len() > 0)\n",
        "\n",
        "    test = (\n",
        "        df_lazy.select(\n",
        "            'uid',\n",
        "            pl.all()\n",
        "            .exclude('uid')\n",
        "            .list.gather(pl.col('timestamp').list.eval(pl.arg_where(pl.element() >= test_timestamp))),\n",
        "        )\n",
        "        #\n",
        "        .with_columns(\n",
        "            pl.col('uid').is_in(unique_train_uids.get_column('uid').implode()).alias('uid_in_train')\n",
        "        )  # to prevent filter reordering\n",
        "        .filter('uid_in_train')\n",
        "        .drop('uid_in_train')\n",
        "    )\n",
        "\n",
        "    test = drop(test, unique_train_item_ids).filter(pl.col('item_id').list.len() > 0)\n",
        "\n",
        "    return train, validation, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2osV0__OfjjT"
      },
      "source": [
        "## ğŸ” About data preprocessing for model training\n",
        "\n",
        "In modern recommender system research, a standardized data preprocessing pipeline is commonly used to ensure reproducibility of results. Many papers on recommender systems follow a well-established dataset preprocessing scheme:\n",
        " 1. Filtering rare entities\n",
        "\n",
        "Users and items (products / movies / etc.) with fewer interactions than a predefined threshold are removed. This reduces the sparsity of the interaction matrix and minimizes noise.\n",
        "For Amazon datasets, which are very popular in academia, a special notation such as â€œ5-coreâ€ is often used. However, for Yambda, we skip this step, since similar filtering has already been applied during dataset construction.\n",
        "\n",
        " 2. Data splitting strategies\n",
        "\n",
        "A common approach in the literature is leave-one-out (LOO) splitting (the last item is used for testing, the second-to-last for validation, and the rest for training).\n",
        "In this work, we instead use a time-based split, because LOO introduces data leakage â€” the model should not observe future events during training. Moreover, LOO poorly correlates with real-world production scenarios.\n",
        "\n",
        " 3. Training and evaluation process\n",
        "\n",
        "    â€¢ The training set is used to learn the model parameters.\n",
        "\n",
        "    â€¢ The validation set is used for hyperparameter tuning and early stopping.\n",
        "\n",
        "    â€¢ The test set is used to compute the final evaluation metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwwdsnwBfjjT"
      },
      "source": [
        "## ğŸ› ï¸ Task 1. Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQtfWFWIfjjT"
      },
      "source": [
        "1ï¸âƒ£ Download a dataset of user-track interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "896906065c584429a30b87fa8ecece77",
            "a5167e8aba3041db8b3640d4ccc7bfd5",
            "736da6a3af7947e98e6fdbddb7f65b17",
            "5eee93bc201f449f925145b1bdcf7d7c",
            "a5afb48f05f24900a4583449761a2a53",
            "af2aab6be0914eb1b44d0a09bf0d7872",
            "3229bd8ddc2e4e7cb0e7b600a81bf3cc",
            "244ddee70bc54ffd931684f5476895d8",
            "33ea386224ca4cb4b8c2054c35045fa9",
            "5bf35498384c49389384882d0424c375",
            "1391e50346664bd38751e34c0b3cdfcd",
            "45b9161d378e4bfeaa63abc5789d3619",
            "577f69a4d2224d88a165f8b7fdb8a457",
            "13920066e6894dcfba5829bade837b4d",
            "6621b53cd77c42dca7eddd84a246d41e",
            "084eb831d4ff44518041a30e30c6ea72",
            "bb8df16bf5ce46ba87effb97a015e952",
            "d851d59547b941c4b8dddb953092778c",
            "4593be00b2824d7e92e0d027e39eee2b",
            "a16c66a5e2bf424ca1a626daad50b61c",
            "cea4579b08c94e9db5ae075d3c57f2c6",
            "9723066ecd0a48eb96649402c01d5f8c",
            "ebcbfa4c89a1443e83a2e61198f79fde",
            "b42b38942e444b1d976b9ad765624aed",
            "e49cc2b11b5a4e26b5a4c742303e9185",
            "8d0c16081f194dd4bac266720c40ba9c",
            "fd53aa388bff4a8dbbc1d45367174510",
            "b728c6caa51a45c2be731b2ea4cb2653",
            "9a2bcfac6818463babf6d1d32be88133",
            "d321e2e9651f4fa6950ee2156b4a8baf",
            "615272daed2547449b2d64130dc6d887",
            "361d40ae0a564700bf96e68ac827d117",
            "bea2ef05e89f4a68830f7f6fde20f07a"
          ]
        },
        "id": "viKiSaEKfjjT",
        "outputId": "cb2e60ea-5b11-4696-9cc0-59a571f6ad65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "896906065c584429a30b87fa8ecece77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sequential/50m/listens.parquet:   0%|          | 0.00/426M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45b9161d378e4bfeaa63abc5789d3619"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebcbfa4c89a1443e83a2e61198f79fde"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "format = 'sequential'\n",
        "size = '50m'\n",
        "events = 'listens'\n",
        "\n",
        "# Load data from Hugging Face Hub\n",
        "listens_data = load_dataset('yandex/yambda', data_dir=f'{format}/{size}', data_files=f'{events}.parquet')\n",
        "\n",
        "# Convert into Polars DataFrame for further processing\n",
        "yambda_df = pl.from_arrow(listens_data['train'].data.table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNanksDRfjjT",
        "outputId": "09bd65f3-1336-44a0-ab0f-eb7bcf1d6a53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_yambda_data_loading: OK\n"
          ]
        }
      ],
      "source": [
        "def test_yambda_data_loading():\n",
        "    assert isinstance(yambda_df, pl.DataFrame), 'yambda_df must be Polars DataFrame'\n",
        "    assert yambda_df.shape == (9238, 6), f'Wrong shape: {yambda_df.shape}'\n",
        "\n",
        "    expected_cols = {'uid', 'timestamp', 'item_id', 'is_organic', 'played_ratio_pct', 'track_length_seconds'}\n",
        "    assert set(yambda_df.columns) == expected_cols, f'Wrong columns: {yambda_df.columns}'\n",
        "\n",
        "    assert yambda_df['item_id'].dtype == pl.List(pl.UInt32), 'item_id must be List[UInt32]'\n",
        "    assert yambda_df['timestamp'].dtype == pl.List(pl.UInt32), 'timestamp must be List[UInt32]'\n",
        "\n",
        "    assert yambda_df['item_id'].list.len().min() > 0, 'Contains empty histories'\n",
        "\n",
        "    print('âœ… test_yambda_data_loading: OK')\n",
        "\n",
        "test_yambda_data_loading()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMbeUvWHfjjT"
      },
      "source": [
        "2ï¸âƒ£ Filter the dataset by applying the following conditions:\n",
        "\n",
        " â€¢ Keep only users whose user_id is divisible by 200.\n",
        "\n",
        " â€¢ Keep only events that were organically generated (i.e., explicitly chosen by the user, not recommended).\n",
        "\n",
        " â€¢ Keep only events where the track was listened to for more than 50% of its duration.\n",
        "\n",
        " â€¢ Remove user histories that become empty after filtering.\n",
        "\n",
        "This filtering step allows the model to train on higher-quality and more representative data, reducing noise from weak or accidental interactions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#yambda_df.head(5)"
      ],
      "metadata": {
        "id": "On4EQH1Gnt5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # TODO: your code here\n",
        "list_cols = [\"timestamp\", \"item_id\", \"is_organic\", \"played_ratio_pct\", \"track_length_seconds\"]\n",
        "\n",
        "yambda_df = (\n",
        "    yambda_df\n",
        "    # keep only users divisible by 200\n",
        "    .filter((pl.col(\"uid\") % 200) == 0)\n",
        "\n",
        "    # explode lists into per-event rows (alignment is preserved across these columns)\n",
        "    .explode(list_cols)\n",
        "\n",
        "    # keep only organic events + listened > 50%\n",
        "    .filter(\n",
        "        (pl.col(\"is_organic\") == 0) &\n",
        "        (pl.col(\"played_ratio_pct\") >= 50)\n",
        "    )\n",
        "\n",
        "    # group events back into user sequences (lists)\n",
        "    .group_by(\"uid\", maintain_order=True)\n",
        "    .agg([\n",
        "        pl.col(\"timestamp\").alias(\"timestamp\"),\n",
        "        pl.col(\"item_id\").alias(\"item_id\"),\n",
        "        pl.col(\"is_organic\").alias(\"is_organic\"),\n",
        "        pl.col(\"played_ratio_pct\").alias(\"played_ratio_pct\"),\n",
        "        pl.col(\"track_length_seconds\").alias(\"track_length_seconds\"),\n",
        "    ])\n",
        "\n",
        "    # drop users with empty histories (after filtering)\n",
        "    .filter(pl.col(\"item_id\").list.len() > 0)\n",
        "    .select([\"uid\", \"timestamp\", \"item_id\"])\n",
        ")"
      ],
      "metadata": {
        "id": "-PawLib2oaP9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#yambda_df = yambda_df.select([\"uid\", \"timestamp\", \"item_id\"])"
      ],
      "metadata": {
        "id": "CTPRUgV3wh9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_lengths = yambda_df['item_id'].list.len()"
      ],
      "metadata": {
        "id": "pEEvkkNytuhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_lengths.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XG2APS5tvb9",
        "outputId": "bfcc8f46-bff0-4f2a-8d0a-cb474278f82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7587469"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HTturbHfjjU",
        "outputId": "b03200b7-4ae2-413e-f103-4aa2e198389b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_yambda_filtering: OK\n"
          ]
        }
      ],
      "source": [
        "def test_yambda_filtering():\n",
        "    assert yambda_df.shape[0] == 4289, \\\n",
        "        f'Wrong number of users: {yambda_df.shape[0]}'\n",
        "\n",
        "    expected_columns = {'uid', 'timestamp', 'item_id'}\n",
        "    actual_columns = set(yambda_df.columns)\n",
        "    assert actual_columns == expected_columns, \\\n",
        "        f'Wrong columns. Expected: {expected_columns}, got: {actual_columns}'\n",
        "\n",
        "    assert yambda_df['timestamp'].dtype == pl.List(pl.UInt32), \\\n",
        "        f\"timestamp mist be List[UInt32], received: {yambda_df['timestamp'].dtype}\"\n",
        "    assert yambda_df['item_id'].dtype == pl.List(pl.UInt32), \\\n",
        "        f\"item_id muste be List[UInt32], received: {yambda_df['item_id'].dtype}\"\n",
        "\n",
        "    seq_lengths = yambda_df['item_id'].list.len()\n",
        "    assert seq_lengths.min() >= 1, \\\n",
        "        f'Minimum length of sequence must be >= 1, got: {seq_lengths.min()}'\n",
        "    assert seq_lengths.sum() == 7587469, \\\n",
        "        f'Overall number of events is wrong. Expected: 7587469, got: {seq_lengths.sum()}'\n",
        "\n",
        "    unique_items = yambda_df.select('item_id').explode('item_id').unique().shape[0]\n",
        "    assert unique_items == 304787, \\\n",
        "        f'The number of unique items is wrong. Expected: 304787, got: {unique_items}'\n",
        "\n",
        "    print('âœ… test_yambda_filtering: OK')\n",
        "\n",
        "test_yambda_filtering()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKFs6KQRfjjU"
      },
      "source": [
        "3ï¸âƒ£ Task: Remap Track IDs to a Dense Range\n",
        "\n",
        "Extract all unique track IDs from the dataset and create a mapping  \n",
        "old_id â†’ new_id, where new_id âˆˆ `{0, â€¦, Nâˆ’1}`.\n",
        "\n",
        "Deep learning models require categorical features (such as item / track IDs)\n",
        "to be represented as contiguous integer indices starting from 0.\n",
        "This is especially important for embedding layers, which assume indices\n",
        "in the range` [0, num_embeddings - 1]`.\n",
        "\n",
        "The Yambda dataset contains original track IDs that are sparse and non-contiguous\n",
        "(e.g. `[7, 100, 5000, 12000, â€¦]`), which is inefficient and incompatible with\n",
        "embedding tables.\n",
        "\n",
        "Therefore, we:\n",
        "1. Collect all unique track IDs from the dataset\n",
        "2. Build a mapping from original IDs to new compact IDs\n",
        "3. Replace original IDs in user sequences using this mapping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items = (\n",
        "    yambda_df\n",
        "    .select(\"item_id\")\n",
        "    .explode(\"item_id\")\n",
        "    .get_column(\"item_id\")\n",
        "    .unique()\n",
        "    .sort()\n",
        ")"
      ],
      "metadata": {
        "id": "AwLNuuRtMczO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#items.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "DBEmCl9WNDzD",
        "outputId": "62b6fd0e-f6b6-4a30-e549-4b8aea6dca2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (2,)\n",
              "Series: 'item_id' [u32]\n",
              "[\n",
              "\t50\n",
              "\t175\n",
              "]"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (2,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>item_id</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>50</td></tr><tr><td>175</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unique_items as a dataframe with shape (N, 2) to pass assert statements below\n",
        "unique_items = pl.DataFrame({\n",
        "    \"new_item_id\": pl.arange(0, len(items), eager=True, dtype=pl.UInt32),\n",
        "    \"item_id\": items,\n",
        "})"
      ],
      "metadata": {
        "id": "gR8H_5t5NIjq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_items.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "lSZ8kHW9Kjy8",
        "outputId": "cb41f737-73eb-44c9-8c85-a1b107b50680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (3, 2)\n",
              "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
              "â”‚ new_item_id â”† item_id â”‚\n",
              "â”‚ ---         â”† ---     â”‚\n",
              "â”‚ u32         â”† u32     â”‚\n",
              "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•¡\n",
              "â”‚ 0           â”† 50      â”‚\n",
              "â”‚ 1           â”† 175     â”‚\n",
              "â”‚ 2           â”† 195     â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>new_item_id</th><th>item_id</th></tr><tr><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>50</td></tr><tr><td>1</td><td>175</td></tr><tr><td>2</td><td>195</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# item_mapping: dict old_id -> new_id\n",
        "item_mapping = dict(zip(unique_items[\"item_id\"].to_list(),\n",
        "                        unique_items[\"new_item_id\"].to_list()))"
      ],
      "metadata": {
        "id": "DYFBGRg6Kf57"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yambda_df = yambda_df.with_columns([\n",
        "    pl.col('item_id')\n",
        "        .map_elements(\n",
        "            lambda items: [item_mapping[item] for item in items],\n",
        "            return_dtype=pl.List(pl.UInt32)\n",
        "        )\n",
        "        .alias('item_id')\n",
        "])"
      ],
      "metadata": {
        "id": "7omNNNoZIVdo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_mapping[50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuqDJOTbLDqu",
        "outputId": "69170510-78bc-4d83-bcf6-f491d5c9a232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MltQKQ8cfjjU",
        "outputId": "1e592679-0beb-4d57-ef2d-bcb6e1fb80b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_item_mapping: OK\n"
          ]
        }
      ],
      "source": [
        "def test_item_mapping():\n",
        "    assert unique_items.shape == (304787, 2), f'Wrong size of unique_items: {unique_items.shape}'\n",
        "    assert set(unique_items.columns) == {'new_item_id', 'item_id'}, 'Wrong columns unique_items'\n",
        "\n",
        "    assert len(item_mapping) == 304787, f'Wrong size of item_mapping: {len(item_mapping)}'\n",
        "    assert item_mapping[50] == 0 and item_mapping[175] == 1 and item_mapping[195] == 2, \\\n",
        "        'Wrong first mappings'\n",
        "\n",
        "    new_ids = unique_items['new_item_id']\n",
        "    assert new_ids.min() == 0 and new_ids.max() == 304786, 'new_item_id must be in range [0, 304786]'\n",
        "\n",
        "    all_ids = yambda_df.select('item_id').explode('item_id')['item_id']\n",
        "    assert all_ids.min() == 0 and all_ids.max() == 304786, 'item_id in yambda_df not updated'\n",
        "    assert all_ids.n_unique() == 304787, 'Unique number of item_id has changed'\n",
        "\n",
        "    print('âœ… test_item_mapping: OK')\n",
        "\n",
        "test_item_mapping()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHnmCq7XfjjU"
      },
      "source": [
        "4ï¸âƒ£ Sequential Train / Validation / Test Split (Time-based)\n",
        "\n",
        "Split each userâ€™s listening history into three non-overlapping time periods:\n",
        "\n",
        "- Validation and test must each contain exactly one day of events.\n",
        "- Training must contain all earlier events (everything before validation and test).\n",
        "- There must be no gaps between the periods â€” the time windows must be adjacent (go â€œback-to-backâ€).\n",
        "\n",
        "This split is time-based to avoid data leakage: the model should not train on events that occur in the future relative to validation/test."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_ts = (\n",
        "    yambda_df\n",
        "    .select(pl.col(\"timestamp\").explode().max().alias(\"max_ts\"))\n",
        "    .item()\n",
        ")  # calculating the max timestamp in seconds"
      ],
      "metadata": {
        "id": "k5DDbkLKPnsW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#max_ts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iUGCTF2QNjV",
        "outputId": "56809cb6-4f5e-413d-d4a9-e4ce4cc2a4a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25999985"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_timestamp = max_ts - DAY_SECONDS\n",
        "val_size = DAY_SECONDS - 1"
      ],
      "metadata": {
        "id": "4r4duoimPtZB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BDS06D6vfjjU"
      },
      "outputs": [],
      "source": [
        "train_events_df, valid_events_df, eval_events_df = sequential_split_train_val_test(df=yambda_df, test_timestamp=test_timestamp, val_size=val_size)  # TODO: your code here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert into DF because it doesnt pass asserts otherwise\n",
        "train_events_df = train_events_df.collect()\n",
        "valid_events_df = valid_events_df.collect()\n",
        "eval_events_df  = eval_events_df.collect()"
      ],
      "metadata": {
        "id": "WqEiU1p-QxvT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_events_df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DPsLS3ZRD0U",
        "outputId": "8617f45b-375b-4e55-f5ec-5ed845fc56ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4284"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_events_df.select(pl.col('item_id').list.len()).sum().item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK1Slt2ARe9c",
        "outputId": "85d842d6-9cd0-4696-9a71-2f1afe664faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35933"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13X5uop0fjjU",
        "outputId": "110e6893-892f-453d-fe94-2a2f72e71fe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_yambda_train_val_test_split: OK\n"
          ]
        }
      ],
      "source": [
        "def test_yambda_train_val_test_split():\n",
        "    assert train_events_df.shape[0] == (4284), \\\n",
        "        f'Wrong number of users: {train_events_df.shape[0]}'\n",
        "    assert valid_events_df.shape[0] == (1356), \\\n",
        "        f'Wrong number of users: {valid_events_df.shape[0]}'\n",
        "    assert eval_events_df.shape[0] == (1407), \\\n",
        "        f'Wrong number of users: {eval_events_df.shape[0]}'\n",
        "\n",
        "    assert isinstance(train_events_df, pl.DataFrame), 'Incorrect type'\n",
        "    assert isinstance(valid_events_df, pl.DataFrame), 'Incorrect type'\n",
        "    assert isinstance(eval_events_df, pl.DataFrame), 'Incorrect type'\n",
        "\n",
        "    assert train_events_df.select(pl.col('item_id').list.len()).sum().item() == 7510554, \\\n",
        "        'Wrong number of events in train'\n",
        "    assert valid_events_df.select(pl.col('item_id').list.len()).sum().item() == 35933, \\\n",
        "        'Wrong number of events in val'\n",
        "    assert eval_events_df.select(pl.col('item_id').list.len()).sum().item() == 40961, \\\n",
        "        'Wrong number of events in test'\n",
        "\n",
        "    print('âœ… test_yambda_train_val_test_split: OK')\n",
        "\n",
        "test_yambda_train_val_test_split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGwbwJmvfjjU"
      },
      "source": [
        "5ï¸âƒ£ Merge train/val/test splits by user\n",
        "\n",
        "Combine the three split datasets (`train / val / test`) into a single table by users (`uid`).\n",
        "\n",
        "The resulting table should contain, for each user, their listening history from all three stages:\n",
        "- training history\n",
        "- validation history\n",
        "- test history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#max(list(map(len, joined_events_df['item_id'].to_list())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChVuCIpnanp4",
        "outputId": "c3ac4b96-ae29-4407-dc04-fe2673f91a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26010"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_events_df = (\n",
        "    train_events_df\n",
        "    .join(valid_events_df, on=\"uid\", how=\"left\", suffix=\"_val\")\n",
        "    .join(eval_events_df,  on=\"uid\", how=\"left\", suffix=\"_test\")\n",
        "    .select([\n",
        "        \"uid\",\n",
        "        \"item_id\", \"timestamp\",                      # train\n",
        "        pl.col(\"item_id_val\"), pl.col(\"timestamp_val\"),  # val\n",
        "        pl.col(\"item_id_test\"), pl.col(\"timestamp_test\") # test\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "ixp3cNGcbuSQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joined_events_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "wPVl-zUlciUG",
        "outputId": "40f55683-9e3a-489f-df24-f5f71c46ffb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (2, 7)\n",
              "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
              "â”‚ uid â”† item_id   â”† timestamp  â”† item_id_val â”† timestamp_val   â”† item_id_test    â”† timestamp_test  â”‚\n",
              "â”‚ --- â”† ---       â”† ---        â”† ---         â”† ---             â”† ---             â”† ---             â”‚\n",
              "â”‚ u32 â”† list[u32] â”† list[u32]  â”† list[u32]   â”† list[u32]       â”† list[u32]       â”† list[u32]       â”‚\n",
              "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
              "â”‚ 600 â”† [262291,  â”† [1329190,  â”† [257175,    â”† [25852420,      â”† [14322, 194515, â”† [25939985,      â”‚\n",
              "â”‚     â”† 60566, â€¦  â”† 1329405, â€¦ â”† 195370, â€¦   â”† 25852635, â€¦     â”† â€¦ 210156]       â”† 25940245, â€¦     â”‚\n",
              "â”‚     â”† 215130]   â”† 25819590]  â”† 285767]     â”† 2590215â€¦        â”†                 â”† 2599754â€¦        â”‚\n",
              "â”‚ 800 â”† [21707,   â”† [121100,   â”† null        â”† null            â”† [112823, 28553, â”† [25975185,      â”‚\n",
              "â”‚     â”† 206290, â€¦ â”† 121290, â€¦  â”†             â”†                 â”† â€¦ 62936]        â”† 25975410, â€¦     â”‚\n",
              "â”‚     â”† 192318]   â”† 25805770]  â”†             â”†                 â”†                 â”† 2597731â€¦        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>uid</th><th>item_id</th><th>timestamp</th><th>item_id_val</th><th>timestamp_val</th><th>item_id_test</th><th>timestamp_test</th></tr><tr><td>u32</td><td>list[u32]</td><td>list[u32]</td><td>list[u32]</td><td>list[u32]</td><td>list[u32]</td><td>list[u32]</td></tr></thead><tbody><tr><td>600</td><td>[262291, 60566, â€¦ 215130]</td><td>[1329190, 1329405, â€¦ 25819590]</td><td>[257175, 195370, â€¦ 285767]</td><td>[25852420, 25852635, â€¦ 25902150]</td><td>[14322, 194515, â€¦ 210156]</td><td>[25939985, 25940245, â€¦ 25997540]</td></tr><tr><td>800</td><td>[21707, 206290, â€¦ 192318]</td><td>[121100, 121290, â€¦ 25805770]</td><td>null</td><td>null</td><td>[112823, 28553, â€¦ 62936]</td><td>[25975185, 25975410, â€¦ 25977310]</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaQgBvssfjjU",
        "outputId": "968ce765-2e4c-485e-da25-c32e7ab5018d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_yambda_all_join: OK\n"
          ]
        }
      ],
      "source": [
        "def test_yambda_all_join():\n",
        "    assert joined_events_df.shape[0] == 4284, \\\n",
        "        f'Wrong number of users: {joined_events_df.shape[0]}'\n",
        "\n",
        "    assert min(list(map(len, joined_events_df['item_id'].to_list()))) == 1\n",
        "    assert max(list(map(len, joined_events_df['item_id'].to_list()))) == 25643\n",
        "\n",
        "    print('âœ… test_yambda_all_join: OK')\n",
        "\n",
        "test_yambda_all_join()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_events_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWqjUDk7VgBj",
        "outputId": "8933f741-6cc5-47da-fb4f-f2c2ad2e1da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['uid',\n",
              " 'item_id',\n",
              " 'timestamp',\n",
              " 'item_id_val',\n",
              " 'timestamp_val',\n",
              " 'item_id_test',\n",
              " 'timestamp_test']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHBKhHb6fjjU"
      },
      "source": [
        "6ï¸âƒ£ **Building Train, Validation, and Test Datasets**\n",
        "\n",
        "Construct training, validation, and test datasets for sequential recommendation.\n",
        "\n",
        "Training set\n",
        "- Keep only users whose interaction histories contain at least `MIN_SEQ_LEN` events.\n",
        "- These sequences will be used to train the model.\n",
        "\n",
        "Validation set\n",
        "- Create *incremental sequences* for each user from the validation period.\n",
        "- For every user, generate multiple samples where:\n",
        "  - The history consists of all training events for the user\n",
        "  - Plus progressively more validation events:\n",
        "    - train + vâ‚\n",
        "    - train + vâ‚, vâ‚‚\n",
        "    - train + vâ‚, vâ‚‚, vâ‚ƒ\n",
        "    - ...\n",
        "- This setup evaluates how well the model predicts the *next item* as user history grows.\n",
        "\n",
        "Test set\n",
        "- Construct incremental sequences similarly to validation, but:\n",
        "  - Start with full train + full validation history\n",
        "  - Incrementally add test events:\n",
        "    - train + valid + tâ‚\n",
        "    - train + valid + tâ‚, tâ‚‚\n",
        "    - ...\n",
        "- This reflects the real production scenario: predicting future user actions given all past behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VkiHBdKdfjjU"
      },
      "outputs": [],
      "source": [
        "train_data = (\n",
        "    joined_events_df\n",
        "    .select([\"uid\", \"timestamp\", \"item_id\"])\n",
        "    .filter(pl.col(\"item_id\").list.len() >= MIN_SEQ_LEN)\n",
        ") # TODO: your code here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLvo72H9XDhz",
        "outputId": "f5d99e4a-46bb-4ece-fe5b-991a2d7bbb7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['uid', 'timestamp', 'item_id']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSppjCNkfjjU",
        "outputId": "b0a97ade-be79-4c5b-c5e5-3c82578d3159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_train_data: OK\n"
          ]
        }
      ],
      "source": [
        "def test_train_data():\n",
        "    assert train_data.shape == (4228, 3), f'Wrong shape: {train_data.shape}'\n",
        "    assert train_data.columns == ['uid', 'timestamp', 'item_id'], 'Wrong columns'\n",
        "\n",
        "    assert train_data['item_id'].list.len().min() >= MIN_SEQ_LEN, \\\n",
        "        'Sequences shorter than MIN_SEQ_LEN are present'\n",
        "\n",
        "    assert train_data['item_id'].list.len().sum() == 7510498, 'Wrong number of events'\n",
        "\n",
        "    assert train_data['uid'].head(5).to_list() == [600, 800, 1000, 1400, 1600], 'Wrong first uid'\n",
        "\n",
        "    print('âœ… test_train_data: OK')\n",
        "\n",
        "test_train_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#valid_events_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gVYbRvAalXA",
        "outputId": "58b85a73-e716-4c10-9ef2-8eaf0078556c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1356, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "z1pZSBDofjjU"
      },
      "outputs": [],
      "source": [
        "valid_data = (\n",
        "    train_data\n",
        "    .join(\n",
        "        valid_events_df.select([\"uid\", \"item_id\", \"timestamp\"]).rename({\n",
        "            \"item_id\": \"item_id_val\",\n",
        "            \"timestamp\": \"timestamp_val\",\n",
        "        }),\n",
        "        on=\"uid\",\n",
        "        how=\"inner\"\n",
        "    )\n",
        "    .with_columns(\n",
        "        pl.col(\"item_id_val\").list.len().alias(\"val_len\")\n",
        "    )\n",
        "    .with_columns(\n",
        "        pl.int_ranges(1, pl.col(\"val_len\") + 1).alias(\"prefix_len\")\n",
        "    )\n",
        "    .explode(\"prefix_len\")\n",
        "    .with_columns([\n",
        "        pl.concat_list([\n",
        "            pl.col(\"item_id\"),\n",
        "            pl.col(\"item_id_val\").list.slice(0, pl.col(\"prefix_len\"))\n",
        "        ]).alias(\"item_id\"),\n",
        "        pl.concat_list([\n",
        "            pl.col(\"timestamp\"),\n",
        "            pl.col(\"timestamp_val\").list.slice(0, pl.col(\"prefix_len\"))\n",
        "        ]).alias(\"timestamp\"),\n",
        "    ])\n",
        "    .select([\"uid\", \"timestamp\", \"item_id\"])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_ujdnNGfjjV",
        "outputId": "8c762edf-5a73-413d-d563-fdc7d5906f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_valid_data: OK\n"
          ]
        }
      ],
      "source": [
        "def test_valid_data():\n",
        "    assert valid_data.shape == (35933, 3), f'Wrong shape: {valid_data.shape}'\n",
        "    assert valid_data.columns == ['uid', 'timestamp', 'item_id'], 'Wrong columns'\n",
        "\n",
        "    assert valid_data['item_id'].list.len().min() >= MIN_SEQ_LEN, \\\n",
        "        'Sequences shorter than MIN_SEQ_LEN are present'\n",
        "\n",
        "    assert valid_data['item_id'].list.len().sum() == 195225055, 'Wrong number of events'\n",
        "    assert valid_data['uid'].head(5).to_list() == [600, 600, 600, 600, 600], 'Wrong first uid'\n",
        "\n",
        "    first_user_lens = valid_data.filter(pl.col('uid') == 100)['item_id'].list.len().to_list()[:5]\n",
        "    assert first_user_lens == sorted(first_user_lens), 'Lengths must be increasing incrementally'\n",
        "\n",
        "    print('âœ… test_valid_data: OK')\n",
        "\n",
        "test_valid_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TZtGyiqcfjjV"
      },
      "outputs": [],
      "source": [
        "base_train = joined_events_df.select([\"uid\", \"timestamp\", \"item_id\"])  # NO MIN_SEQ_LEN filter here\n",
        "\n",
        "eval_data = (\n",
        "    base_train\n",
        "    .join(\n",
        "        valid_events_df.select([\"uid\", \"item_id\", \"timestamp\"]).rename({\n",
        "            \"item_id\": \"item_id_val\",\n",
        "            \"timestamp\": \"timestamp_val\",\n",
        "        }),\n",
        "        on=\"uid\",\n",
        "        how=\"left\"\n",
        "    )\n",
        "    .with_columns([\n",
        "        pl.col(\"item_id_val\").fill_null(pl.lit([], dtype=pl.List(pl.UInt32))),\n",
        "        pl.col(\"timestamp_val\").fill_null(pl.lit([], dtype=pl.List(pl.UInt32))),\n",
        "    ])\n",
        "    .join(\n",
        "        eval_events_df.select([\"uid\", \"item_id\", \"timestamp\"]).rename({\n",
        "            \"item_id\": \"item_id_test\",\n",
        "            \"timestamp\": \"timestamp_test\",\n",
        "        }),\n",
        "        on=\"uid\",\n",
        "        how=\"inner\"\n",
        "    )\n",
        "    .with_columns(pl.col(\"item_id_test\").list.len().alias(\"test_len\"))\n",
        "    .with_columns(pl.int_ranges(1, pl.col(\"test_len\") + 1).alias(\"prefix_len\"))\n",
        "    .explode(\"prefix_len\")\n",
        "    .with_columns([\n",
        "        pl.concat_list([\n",
        "            pl.col(\"item_id\"),\n",
        "            pl.col(\"item_id_val\"),\n",
        "            pl.col(\"item_id_test\").list.slice(0, pl.col(\"prefix_len\")),\n",
        "        ]).alias(\"item_id\"),\n",
        "        pl.concat_list([\n",
        "            pl.col(\"timestamp\"),\n",
        "            pl.col(\"timestamp_val\"),\n",
        "            pl.col(\"timestamp_test\").list.slice(0, pl.col(\"prefix_len\")),\n",
        "        ]).alias(\"timestamp\"),\n",
        "    ])\n",
        "    .select([\"uid\", \"timestamp\", \"item_id\"])\n",
        "    # NOW enforcing MIN_SEQ_LEN\n",
        "    .filter(pl.col(\"item_id\").list.len() >= MIN_SEQ_LEN)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eCGOhRBfjjV",
        "outputId": "688d6f69-e873-4984-e1f2-2dbe32aacefa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_eval_data: OK\n"
          ]
        }
      ],
      "source": [
        "def test_eval_data():\n",
        "    assert eval_data.shape == (40961, 3), f'Wrong shape: {eval_data.shape}'\n",
        "    assert eval_data.columns == ['uid', 'timestamp', 'item_id'], 'Wrong columns'\n",
        "\n",
        "    assert eval_data['item_id'].list.len().min() >= MIN_SEQ_LEN, \\\n",
        "        'Sequences shorter than MIN_SEQ_LEN are present'\n",
        "\n",
        "    assert eval_data['item_id'].list.len().sum() == 212124968, 'Long number of events'\n",
        "    assert eval_data['uid'].head(5).to_list() == [600, 600, 600, 600, 600], 'Wrong first uid'\n",
        "\n",
        "    first_user_lens = eval_data.filter(pl.col('uid') == 100)['item_id'].list.len().head(5).to_list()\n",
        "    assert first_user_lens == sorted(first_user_lens), 'Lengths must be increasing incrementally'\n",
        "\n",
        "    assert eval_data['item_id'].list.len().sum() > valid_data['item_id'].list.len().sum(), \\\n",
        "        'eval_data must be bigger than valid_data'\n",
        "\n",
        "    print('âœ… test_eval_data: OK')\n",
        "\n",
        "test_eval_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8oyiPe0fjjV"
      },
      "source": [
        "Samples that we will be passing to a model have the following structure:\n",
        "\n",
        "- `history`\n",
        "    - `item_id` (user's interactions from their history)\n",
        "    - `lengths` (number of interactions in user's history)\n",
        "    - `positions` (numbers of positions in reverse order)\n",
        "- `labels`\n",
        "    - `item_id` (positives that the model must predict, a.k.a. next interaction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kfhnDEDfjjV"
      },
      "source": [
        "7ï¸âƒ£ Implement the `YambdaDataset` class, which transforms prepared user interaction histories into a format suitable for training neural network models.\n",
        "\n",
        "Requirements:\n",
        "\n",
        " â€¢ In the `__len__` method: return the number of samples in the dataset.\n",
        "\n",
        " â€¢ In the `__getitem__` method: given an index, retrieve a sample and return a dictionary with two keys:\n",
        "\n",
        " â€¢ `history` â€” a dictionary representing the context (what the model sees):\n",
        "\n",
        " â€¢ `item_id` â€” a sequence of track IDs excluding the last event from the original history\n",
        "\n",
        " â€¢ `lengths` â€” the length of this sequence\n",
        "\n",
        " â€¢ `positions` â€” ordinal indices of events (from 0 to length - 1)\n",
        "\n",
        " â€¢ `labels` â€” a dictionary representing the targets (what the model should predict):\n",
        "\n",
        " â€¢ `item_id` â€” a sequence of target track IDs excluding the first event from the original history\n",
        "\n",
        " â€¢ Truncate both` history['item_id']` and `labels['item_id'] `to max_seq_len, keeping the most recent events, since they best reflect the userâ€™s current interests.\n",
        "\n",
        "The shift between history/item_id and labels/item_id creates (context â†’ target) pairs required for autoregressive training.\n",
        "Each event in the history corresponds to a target (the next item), enabling the model to learn how to predict the next track based on previous interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "r0wQcZmkfjjV"
      },
      "outputs": [],
      "source": [
        "class YambdaDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset for sequential user interaction histories.\n",
        "\n",
        "    Transforms user listening sequences into format suitable for training autoregressive\n",
        "    recommendation models. Creates (history, target) pairs where the target is shifted\n",
        "    by one event forward relative to the history.\n",
        "\n",
        "    For each user:\n",
        "    - history: events [0:-1] (all except last)\n",
        "    - labels: events [1:] (all except first)\n",
        "\n",
        "    This enables the model to learn predicting the next track based on previous events\n",
        "    in the user's history.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe : pl.DataFrame\n",
        "        DataFrame with columns 'uid', 'timestamp', 'item_id', where item_id\n",
        "        contains sequences (lists) of user interaction events.\n",
        "    max_seq_len : int\n",
        "        Maximum sequence length. Histories are truncated keeping the last\n",
        "        (most recent) events.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, Dict[str, Any]]\n",
        "        Dictionary with keys 'history' and 'labels':\n",
        "        - history['item_id']: list of track IDs\n",
        "        - history['lengths']: sequence length\n",
        "        - history['positions']: ordinal numbers [0, 1, ..., len-1]\n",
        "        - labels['item_id']: list of target IDs (targets)\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> dataset = YambdaDataset(train_data, max_seq_len=200)\n",
        "    >>> sample = dataset[0]\n",
        "    >>> sample['history']['item_id']  # [track_id_1, track_id_2, track_id_3, ...]\n",
        "    >>> sample['labels']['item_id']   # [track_id_2, track_id_3, track_id_4, ...]\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            dataframe: pl.DataFrame,\n",
        "            max_seq_len: int,\n",
        "        ) -> None:\n",
        "        super().__init__()\n",
        "        # TODO: your code here\n",
        "        self.dataframe = dataframe\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns the number of samples in the dataset.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        int\n",
        "            Number of rows in the DataFrame.\n",
        "        \"\"\"\n",
        "        # TODO: your code here\n",
        "        return self.dataframe.height\n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict[str, List[int]]:\n",
        "        \"\"\"\n",
        "        Retrieves a sample by index and transforms it into format for training.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        index : int\n",
        "            Index of the sample in the dataset.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict[str, Dict[str, Any]]\n",
        "            Dictionary with 'history' (context) and 'labels' (targets).\n",
        "            History is truncated to max_seq_len, keeping last events.\n",
        "        \"\"\"\n",
        "        # TODO: your code here\n",
        "        row = self.dataframe.row(index, named=True)  # grabbing one user's sequence\n",
        "        items: List[int] = row[\"item_id\"]\n",
        "\n",
        "        hist_items = items[:-1]\n",
        "        labels = items[1:] # items and corresponding labels (next listened tracks)\n",
        "\n",
        "        # truncating\n",
        "        if len(hist_items) > self.max_seq_len:\n",
        "          hist_items = hist_items[-self.max_seq_len:]\n",
        "          labels = labels[-self.max_seq_len:]\n",
        "\n",
        "        length = len(hist_items)\n",
        "        positions = list(range(length))\n",
        "\n",
        "        # returning dict of dicts\n",
        "        return {\n",
        "            \"history\": {\n",
        "                \"item_id\": hist_items,\n",
        "                \"lengths\": length,\n",
        "                \"positions\": positions,\n",
        "            },\n",
        "            \"labels\": {\n",
        "                \"item_id\": labels,\n",
        "            },\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZWn6SDFfjjV",
        "outputId": "1fec41d5-31d5-4a22-fea4-c1b17a86c31d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_yambda_dataset: OK\n"
          ]
        }
      ],
      "source": [
        "def test_yambda_dataset():\n",
        "    max_seq_len = 20\n",
        "    dataset = YambdaDataset(train_data, max_seq_len=max_seq_len)\n",
        "\n",
        "    assert len(dataset) == train_data.shape[0], \\\n",
        "        f'Wrong length of dataset. Expected: {train_data.shape[0]}, received: {len(dataset)}'\n",
        "\n",
        "    sample = dataset[0]\n",
        "    assert isinstance(sample, dict), 'Sample must be a dictionary'\n",
        "    assert 'history' in sample and 'labels' in sample, \"Keys 'history' and 'labels' are required\"\n",
        "\n",
        "    hist = sample['history']\n",
        "    assert 'item_id' in hist and 'lengths' in hist and 'positions' in hist, \"Missing keys in 'history'\"\n",
        "    assert isinstance(hist['item_id'], list), \"'history/item_id' must be of list type\"\n",
        "    assert isinstance(hist['positions'], list), \"'history/positions' must be of list type\"\n",
        "    assert isinstance(hist['lengths'], int), \"'history/lengths' must be int\"\n",
        "    assert len(hist['positions']) == hist['lengths'] == len(hist['item_id']), 'Length of positions sand histories dont match'\n",
        "    assert hist['lengths'] <= max_seq_len, 'Length of history exceeds max_seq_len'\n",
        "\n",
        "    labels = sample['labels']\n",
        "    assert 'item_id' in labels, \"'labels' must contain'item_id'\"\n",
        "    assert isinstance(labels['item_id'], list), \"'labels/item_id' must be of list type\"\n",
        "    assert len(labels['item_id']) == hist['lengths'], 'Len of history Ğ¸ labels do not match'\n",
        "\n",
        "    row_item_id = train_data['item_id'][0]\n",
        "    if len(row_item_id) > max_seq_len:\n",
        "        row_item_id = row_item_id[-(max_seq_len+1):]\n",
        "    expected_history = row_item_id[:-1]\n",
        "    expected_labels = row_item_id[1:]\n",
        "    assert tuple(hist['item_id']) == tuple(expected_history), f\"Wrong history! {hist['item_id']} vs {expected_history}\"\n",
        "    assert tuple(labels['item_id']) == tuple(expected_labels), f\"Wrong targets! {labels['item_id']} vs {expected_labels}\"\n",
        "\n",
        "    print('âœ… test_yambda_dataset: OK')\n",
        "\n",
        "test_yambda_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8mF58JTfjjV"
      },
      "source": [
        "8ï¸âƒ£ Implement func `collate_fn`, which will be used for converting batches into a format that is suitable for the model.\n",
        "\n",
        "The function must:\n",
        "- Take a list of dicts (batch of samples from `YambdaDataset`)\n",
        "- Convert all lists of elements into a single PyTorch tensor\n",
        "- Convert all scalars into tensors\n",
        "- Return a single dictionary, where all values are of type `torch.Tensor`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9dgA4KZlfjjV"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Collates a batch of samples into a single batched tensor representation.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    batch : List[Dict[str, Any]]\n",
        "        A list of samples returned by __getitem__, where each sample is a dictionary.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, Any]\n",
        "        A dictionary with the same structure as input samples, but where all leaf values\n",
        "        are PyTorch tensors of dtype torch.long. Nested dictionaries are preserved,\n",
        "        with tensors at the leaf level.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> batch = [\n",
        "    ...     {\n",
        "    ...         'history': {'item_id': [1, 2, 3], 'lengths': 3, 'positions': [0, 1, 2]},\n",
        "    ...         'labels': {'item_id': [2, 3, 4]}\n",
        "    ...     },\n",
        "    ...     {\n",
        "    ...         'history': {'item_id': [5, 6], 'lengths': 2, 'positions': [0, 1]},\n",
        "    ...         'labels': {'item_id': [6, 7]}\n",
        "    ...     }\n",
        "    ... ]\n",
        "    >>> result = collate_fn(batch)\n",
        "    >>> result['history']['item_id']\n",
        "    tensor([[1, 2, 3, 5, 6]], dtype=torch.long)\n",
        "    >>> result['history']['lengths']\n",
        "    tensor([3, 2], dtype=torch.long)\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    out = {}\n",
        "\n",
        "    for section in batch[0].keys():\n",
        "      out[section] = {}\n",
        "\n",
        "      # iterate over second level\n",
        "      for key in batch[0][section].keys():\n",
        "        values = [sample[section][key] for sample in batch]\n",
        "\n",
        "        if isinstance(values[0], list):\n",
        "          flat=[]\n",
        "          for v in values:\n",
        "            flat.extend(v)\n",
        "          out[section][key] = torch.tensor(flat, dtype=torch.long)\n",
        "\n",
        "        else:\n",
        "          out[section][key] = torch.tensor(values, dtype=torch.long)\n",
        "\n",
        "\n",
        "    return out # a single dict according to TT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy24_uSOfjjV",
        "outputId": "b38aa502-9961-454d-ec52-ffc78c546a22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_collate_fn: OK\n"
          ]
        }
      ],
      "source": [
        "def test_collate_fn():\n",
        "    \"\"\"Tests the correctness of batching by collate_fn.\"\"\"\n",
        "\n",
        "    batch = [\n",
        "        {'history': {'item_id': [1, 2, 3], 'lengths': 3, 'positions': [0, 1, 2]}, 'labels': {'item_id': [2, 3, 4]}},\n",
        "        {'history': {'item_id': [5, 6], 'lengths': 2, 'positions': [0, 1]}, 'labels': {'item_id': [6, 7]}},\n",
        "    ]\n",
        "\n",
        "    result = collate_fn(batch)\n",
        "\n",
        "    assert isinstance(result['history']['item_id'], torch.Tensor), 'item_id must be tensor'\n",
        "    assert result['history']['item_id'].dtype == torch.long, 'dtype must be long'\n",
        "\n",
        "    assert result['history']['item_id'].tolist() == [1, 2, 3, 5, 6], 'Wrong concat item_id'\n",
        "    assert result['history']['positions'].tolist() == [0, 1, 2, 0, 1], 'Wrong concat positions'\n",
        "\n",
        "    assert result['history']['lengths'].tolist() == [3, 2], 'Wrong lengths'\n",
        "\n",
        "    assert result['labels']['item_id'].tolist() == [2, 3, 4, 6, 7], 'Wrong labels'\n",
        "\n",
        "    assert result['history']['lengths'].sum().item() == len(result['history']['item_id']), \\\n",
        "        'Sum of lengths != len item_id'\n",
        "\n",
        "    print('âœ… test_collate_fn: OK')\n",
        "\n",
        "test_collate_fn()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_gC5wKZfjjW"
      },
      "source": [
        "# About SASRec model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KxkgUKXfjjW"
      },
      "source": [
        "## ğŸ“– A little bit of theory about SASRec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd7Hnmo_fjjW"
      },
      "source": [
        "### ğŸ§ What is SASRec?\n",
        "\n",
        "SASRec (Self-Attentive Sequential Recommendation) is a neural network model for sequential recommendation based on the Transformer architecture and the self-attention mechanism. The model was proposed in 2018 (Wang-Cheng Kang, Julian McAuley). Its goal is to effectively capture both short-term and long-term dependencies in a user's interaction sequence in order to predict future interests.\n",
        "\n",
        "SASRec adapts self-attention ideas from NLP to the recommendation setting, which makes it interpretable, scalable, and faster compared to RNN- and CNN-based approaches.  \n",
        "The original paper describing the method can be found here:  \n",
        "http://arxiv.org/abs/1808.09781\n",
        "\n",
        "\n",
        "### ğŸ‘€ Main components of the model:\n",
        "\n",
        "- Embedding Layer: each item is mapped to a trainable embedding of fixed dimensionality $d$. Positional embeddings are also added to account for the order of events.\n",
        "- Transformer Encoder: a sequential stack of $l$ Transformer encoder blocks with a causal mask. Each block consists of a self-attention layer and a position-wise feed-forward layer, along with residual connections and layer normalization.\n",
        "- Prediction Layer: for each position $t$, the encoder output $\\mathbf{F}^{(b)}_t$ is multiplied (dot product) with the embedding of each item in the catalog $\\mathbf{M}_i$ to obtain a relevance score $r_{i, t}$ for every item.\n",
        "\n",
        "\n",
        "### ğŸ¤” What is given as input?\n",
        "\n",
        "SASRec takes as input a sequence of the most recent $|S^u|$ user interactions:\n",
        "\n",
        "$$\n",
        "\\Large{S^u = \\left( S^u_1, S^u_2, \\dots, S^u_{|S^u|} \\right)},\n",
        "$$\n",
        "\n",
        "where $S^u_t$ is the identifier of the item (e.g., a movie or a product) that user $u$ interacted with at time step $t$.\n",
        "\n",
        "\n",
        "### ğŸ¤·â€â™€ï¸ What do we predict?\n",
        "\n",
        "The model is trained to predict the next item in a userâ€™s interaction sequence. Formally, for each time step $t$, the model receives $(S^u_1, ..., S^u_{t-1})$ as input and must predict $S^u_t$.\n",
        "\n",
        "For every item $i$ in the catalog, a relevance score $r_{i, t}$ is computed, which reflects how suitable this item is to be the next one at time $t$:\n",
        "\n",
        "$$\n",
        "\\Large{r_{i, t} = \\langle F_t^{l}, M_i \\rangle},\n",
        "$$\n",
        "\n",
        "where $\\mathbf{F}_t^{l}$ is the output of the $l$-th encoder layer at position $t$, and $\\mathbf{M}_i$ is the embedding of item $i$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teZUPalhfjjW"
      },
      "source": [
        "## ğŸš€ Task 2. Implementation of SASRecBackbone and SASRecModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZUbLAOcfjjW"
      },
      "source": [
        "### ğŸ”§ Implementation of util functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nERZSUxZfjjW"
      },
      "source": [
        "1ï¸âƒ£ Write a func which creates a boolean mask for variable-length sequences. This mask must be a boolean tensor of shape `(batch_size, max_seq_len)`, where `True` stands for valid elements, and `False` â€” padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "eMfcgNCdfjjW"
      },
      "outputs": [],
      "source": [
        "def get_mask(lengths: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Creates a boolean mask for variable-length sequences.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lengths : torch.Tensor\n",
        "        1D tensor of shape (batch_size,) containing the actual length of each sequence\n",
        "        in the batch.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        Boolean mask of shape (batch_size, max_seq_len) where True indicates a valid\n",
        "        element and False indicates padding. Can be used directly in attention masks\n",
        "        or for selective loss computation.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> lengths = torch.tensor([3, 5, 2])\n",
        "    >>> mask = get_mask(lengths)\n",
        "    >>> mask\n",
        "    tensor([[ True,  True,  True, False, False],\n",
        "            [ True,  True,  True,  True,  True],\n",
        "            [ True,  True, False, False, False]])\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    batch_size = lengths.size(0)\n",
        "    max_seq_len = lengths.max().item()\n",
        "\n",
        "    positions = torch.arange(max_seq_len, device=lengths.device)\n",
        "    mask = positions.unsqueeze(0) < lengths.unsqueeze(1)\n",
        "\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybJ8TwvrfjjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5dab1a3-4736-4a2e-bf00-0ae7fac5de8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_get_mask: OK\n"
          ]
        }
      ],
      "source": [
        "def test_get_mask():\n",
        "    lengths = torch.tensor([3, 5, 2])\n",
        "    mask = get_mask(lengths)\n",
        "\n",
        "    assert mask.shape == (3, 5), f'Wrong shape: {mask.shape}'\n",
        "    assert mask.dtype == torch.bool, f'Must be of type bool: {mask.dtype}'\n",
        "\n",
        "    assert (mask.sum(dim=1) == lengths).all(), 'Number of True != lengths'\n",
        "\n",
        "    expected = torch.tensor([\n",
        "        [True, True, True, False, False],\n",
        "        [True, True, True, True, True],\n",
        "        [True, True, False, False, False]\n",
        "    ])\n",
        "    assert torch.equal(mask, expected), f'Wrong mask:\\n{mask}'\n",
        "\n",
        "    print('âœ… test_get_mask: OK')\n",
        "\n",
        "test_get_mask()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoUfilCVfjjW"
      },
      "source": [
        "2ï¸âƒ£ Implement a func, which extracts the last valid element from each seq in `flatten` batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZRNReP0SfjjW"
      },
      "outputs": [],
      "source": [
        "def get_last(data: torch.Tensor, lengths: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Extracts the last valid element from each sequence in a flattened batch.\n",
        "\n",
        "    Given a flattened tensor of concatenated sequences and their lengths, extracts\n",
        "    the final element of each sequence. Useful for obtaining the last hidden state\n",
        "    or final prediction from variable-length sequences without padding overhead.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : torch.Tensor\n",
        "        Tensor of shape (total_elements, ...) containing flattened sequences concatenated\n",
        "        sequentially. For example: [seq1_embedding1, seq1_embedding2, seq2_embedding1, seq2_embedding2, seq2_embedding3, ...]\n",
        "    lengths : torch.Tensor\n",
        "        1D tensor of shape (batch_size,) containing the length of each sequence.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        Tensor of shape (batch_size, ...) containing the last elements of each sequence.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> data = torch.tensor([1, 2, 3, 4, 5, 6])  # 3 sequences: [1,2], [3,4,5], [6]\n",
        "    >>> lengths = torch.tensor([2, 3, 1])\n",
        "    >>> get_last(data, lengths)\n",
        "    tensor([2, 5, 6])\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: your code here\n",
        "\n",
        "    end_indices = torch.cumsum(lengths, dim=0) - 1\n",
        "    return data[end_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "JYzftd_ufjjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "947aacb5-42a4-4ef0-a13c-33af9b3c4b63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_get_last: OK\n"
          ]
        }
      ],
      "source": [
        "def test_get_last():\n",
        "    data = torch.tensor([1, 2, 3, 4, 5, 6])  # [1,2], [3,4,5], [6]\n",
        "    lengths = torch.tensor([2, 3, 1])\n",
        "    result = get_last(data, lengths)\n",
        "    assert torch.equal(result, torch.tensor([2, 5, 6])), f'Wrong result: {result}'\n",
        "\n",
        "    data_2d = torch.tensor([[1., 2.], [3., 4.], [5., 6.], [7., 8.], [9., 10.]])\n",
        "    lengths_2d = torch.tensor([2, 3])\n",
        "    result_2d = get_last(data_2d, lengths_2d)\n",
        "    expected_2d = torch.tensor([[3., 4.], [9., 10.]])\n",
        "    assert torch.equal(result_2d, expected_2d), f'Wrong result for 2D: {result_2d}'\n",
        "\n",
        "    data_ones = torch.tensor([10, 20, 30])\n",
        "    lengths_ones = torch.tensor([1, 1, 1])\n",
        "    assert torch.equal(get_last(data_ones, lengths_ones), torch.tensor([10, 20, 30])), \\\n",
        "        'Wrong result for lengths ones'\n",
        "\n",
        "    print('âœ… test_get_last: OK')\n",
        "\n",
        "test_get_last()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4EkjjahfjjW"
      },
      "source": [
        "3ï¸âƒ£ Implement a func that converta a flattened batch into a padded tensor of corresponding masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Zw5Cd49AfjjW"
      },
      "outputs": [],
      "source": [
        "def create_masked_tensor(data: torch.Tensor, lengths: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Converts a batch of variable-length sequences into a padded tensor and corresponding mask.\n",
        "\n",
        "    Transforms a flattened concatenation of sequences into a padded 2D (or 3D for embeddings)\n",
        "    tensor with right-padding zeros, along with a boolean mask indicating valid positions.\n",
        "    This function is the inverse of the collate operation and prepares data for models\n",
        "    that require fixed-size inputs.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : torch.Tensor\n",
        "        Input tensor containing flattened sequences:\n",
        "        - For indices: shape (total_elements,) of dtype long\n",
        "        - For embeddings: shape (total_elements, embedding_dim)\n",
        "    lengths : torch.Tensor\n",
        "        1D tensor of sequence lengths, shape (batch_size,). Specifies the actual length\n",
        "        of each sequence before padding.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Tuple[torch.Tensor, torch.Tensor]\n",
        "        - padded_tensor: Padded tensor of shape:\n",
        "            - (batch_size, max_seq_len) for indices\n",
        "            - (batch_size, max_seq_len, embedding_dim) for embeddings\n",
        "            Shorter sequences are right-padded with zeros.\n",
        "        - mask: Boolean mask of shape (batch_size, max_seq_len) where True indicates\n",
        "            valid elements and False indicates padding. Can be used in attention or loss computation.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> data = torch.tensor([1, 2, 3, 4, 5, 6])  # sequences: [1,2], [3,4,5], [6]\n",
        "    >>> lengths = torch.tensor([2, 3, 1])\n",
        "    >>> padded, mask = create_masked_tensor(data, lengths)\n",
        "    >>> padded\n",
        "    tensor([[1, 2, 0],\n",
        "            [3, 4, 5],\n",
        "            [6, 0, 0]])\n",
        "    >>> mask\n",
        "    tensor([[ True,  True, False],\n",
        "            [ True,  True,  True],\n",
        "            [ True, False, False]])\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    mask = get_mask(lengths)\n",
        "    batch = lengths.shape[0]\n",
        "    elem_max = int(lengths.max().item()) # determine the shape of our padded tensor\n",
        "\n",
        "    if data.dim() == 1:\n",
        "        padded = torch.zeros((batch, elem_max), dtype=data.dtype, device=data.device)\n",
        "    else:\n",
        "        D = data.shape[1:]\n",
        "        padded = torch.zeros((batch, elem_max, *D), dtype=data.dtype, device=data.device)\n",
        "\n",
        "    start = 0\n",
        "    for i, L in enumerate(lengths.tolist()):\n",
        "        end = start + L\n",
        "        padded[i, :L] = data[start:end]\n",
        "        start = end\n",
        "\n",
        "\n",
        "    return padded, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QQOdDbN2fjjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a296d0-2f82-45bd-d48e-2759dcaf466e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_create_masked_tensor: OK\n"
          ]
        }
      ],
      "source": [
        "def test_create_masked_tensor():\n",
        "    data = torch.tensor([1, 2, 3, 4, 5, 6])\n",
        "    lengths = torch.tensor([2, 3, 1])\n",
        "    padded, mask = create_masked_tensor(data, lengths)\n",
        "\n",
        "    expected_padded = torch.tensor([[1, 2, 0], [3, 4, 5], [6, 0, 0]])\n",
        "    expected_mask = torch.tensor([[True, True, False], [True, True, True], [True, False, False]])\n",
        "\n",
        "    assert torch.equal(padded, expected_padded), f'Wrong padded:\\n{padded}'\n",
        "    assert torch.equal(mask, expected_mask), f'Wrong mask:\\n{mask}'\n",
        "    assert (padded[~mask] == 0).all(), 'Padding must be zeroes'\n",
        "    assert (mask.sum(dim=1) == lengths).all(), 'Sum of True != lengths'\n",
        "\n",
        "    data_2d = torch.randn(5, 4)  # 5 elements, dim=4\n",
        "    lengths_2d = torch.tensor([2, 3])\n",
        "    padded_2d, mask_2d = create_masked_tensor(data_2d, lengths_2d)\n",
        "\n",
        "    assert padded_2d.shape == (2, 3, 4), f'Wrong shape 2D: {padded_2d.shape}'\n",
        "    assert (padded_2d[~mask_2d] == 0).all(), 'Padding 2D must be zeroes'\n",
        "\n",
        "    print('âœ… test_create_masked_tensor: OK')\n",
        "\n",
        "test_create_masked_tensor()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i0d_HVMfjjW"
      },
      "source": [
        "### ğŸ—ï¸ Implementing a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iREI-H4-fjjW"
      },
      "source": [
        "## 4ï¸âƒ£ Implement the SASRecBackbone Class\n",
        "\n",
        "In this task, you need to implement the SASRec backbone, which represents the core component of the model architecture.\n",
        "\n",
        "In this assignment, you implement only the SASRec backbone â€” the part of the model that, given an input sequence, returns a sequence of hidden representations $F_t^l$ for all positions.  \n",
        "The classifier / prediction layer that computes the relevance score $r_{i, t}$ will be added separately.\n",
        "\n",
        "---\n",
        "\n",
        "## What is fed into the model?\n",
        "\n",
        "During training, data from YambdaDataset and collate_fn is first converted into a flatten format, and then into padded batches.\n",
        "\n",
        "The input to SASRecBackbone.forward is a dictionary with the following keys:\n",
        "\n",
        "- `inputs['item_id']` â€” a tensor of item indices corresponding to concatenated user histories,  \n",
        "  shape: (total_elements,)\n",
        "- `inputs['positions']` â€” a tensor of positional indices for each element $(0, 1, 2, \\dots)$,  \n",
        "  shape: (total_elements,)\n",
        "- `inputs['lengths']` â€” lengths of user histories in the batch,  \n",
        "  shape: (batch_size,)\n",
        "\n",
        "These tensors correspond to the sequences $S^u$, already prepared and truncated to max_seq_len.\n",
        "\n",
        "---\n",
        "\n",
        "## What should the model do?\n",
        "\n",
        "The model must perform the following steps:\n",
        "\n",
        "1. Convert item_id into item embeddings using nn.Embedding\n",
        "2. Add positional embeddings so the model can distinguish the order of events\n",
        "3. Use the function create_masked_tensor to convert flattened sequences into a padded batch\n",
        "4. Build a causal mask that prevents each position from attending to future positions\n",
        "5. Pass the batch through an nn.TransformerEncoder\n",
        "6. Return only valid hidden representations for all positions of all users  \n",
        "\n",
        "The output tensor will later be used to compute relevance scores $r_{i, t}$ and training objectives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ydP4vkiFfjjX"
      },
      "outputs": [],
      "source": [
        "class SASRecBackbone(nn.Module):\n",
        "    \"\"\"\n",
        "    Self-Attentive Sequential Recommendation (SASRec) backbone architecture.\n",
        "\n",
        "    Implements the core transformer-based model for sequential recommendation that captures\n",
        "    user preferences by attending to their historical interactions. The model uses self-attention\n",
        "    mechanisms with causal masking to ensure autoregressive generation: each position can only\n",
        "    attend to previous positions.\n",
        "\n",
        "    Architecture:\n",
        "    1. Embedding layer: converts item IDs to dense vectors\n",
        "    2. Positional encoding: adds position information to embeddings\n",
        "    3. Transformer encoder: multi-head self-attention with causal masking\n",
        "    4. Output: encoder representations for downstream tasks\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_items : int\n",
        "        Total number of unique items in the catalog. Used for embedding table size.\n",
        "    embedding_dim : int, optional\n",
        "        Dimension of item and position embeddings.\n",
        "    num_heads : int, optional\n",
        "        Number of attention heads in transformer.\n",
        "    max_seq_len : int, optional\n",
        "        Maximum sequence length for positional embeddings.\n",
        "    dropout_rate : float, optional\n",
        "        Dropout probability for regularization.\n",
        "    num_transformer_layers : int, optional\n",
        "        Number of transformer encoder layers.\n",
        "\n",
        "    Input Format\n",
        "    -----------\n",
        "    inputs : Dict[str, torch.Tensor]\n",
        "        Dictionary containing:\n",
        "        - 'item_id': Flattened item indices, shape (total_elements,)\n",
        "        - 'positions': Positional indices, shape (total_elements,)\n",
        "        - 'lengths': Actual sequence lengths for each sample, shape (batch_size,)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, torch.Tensor]\n",
        "        Dictionary containing:\n",
        "        - 'encoder_output': Transformer encoder output, shape (total_valid_elements, embedding_dim)\n",
        "            Contains only non-padded representations extracted using the mask.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> model = SASRecBackbone(num_items=10000, embedding_dim=64, num_heads=2)\n",
        "    >>> inputs = {\n",
        "    ...     'item_id': torch.tensor([1, 2, 3, 4, 5, 6]),\n",
        "    ...     'positions': torch.tensor([0, 1, 2, 0, 1, 2]),\n",
        "    ...     'lengths': torch.tensor([3, 3])\n",
        "    ... }\n",
        "    >>> output = model(inputs)\n",
        "    >>> output['encoder_output'].shape\n",
        "    torch.Size([6, 64])\n",
        "\n",
        "    Note\n",
        "    ----\n",
        "    - Uses causal masking to prevent looking into future\n",
        "    - Handles variable-length sequences via padding and masking\n",
        "    - Position embeddings are added additively to item embeddings\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_items: int,\n",
        "            embedding_dim: int = 64,\n",
        "            num_heads: int = 2,\n",
        "            max_seq_len: int = 512,\n",
        "            dropout_rate: float = 0.2,\n",
        "            num_transformer_layers: int = 2,\n",
        "        ) -> None:\n",
        "        super().__init__()\n",
        "        self.num_items = num_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.item_embeddings = nn.Embedding(\n",
        "            num_embeddings=num_items,\n",
        "            embedding_dim=embedding_dim\n",
        "\n",
        "        ) # TODO: your code here\n",
        "        self.position_embeddings = nn.Embedding(\n",
        "            num_embeddings=max_seq_len,\n",
        "            embedding_dim=embedding_dim\n",
        "        )  # TODO: your code here\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embedding_dim,\n",
        "            nhead=num_heads,\n",
        "            dropout=dropout_rate,\n",
        "            batch_first=True,\n",
        "            activation=\"gelu\",\n",
        "            norm_first=True\n",
        "        )  # TODO: your code here\n",
        "\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=num_transformer_layers\n",
        "        )  # TODO: your code here\n",
        "\n",
        "    def forward(self, inputs: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass through the SASRec model.\n",
        "\n",
        "        Processes flattened input sequences through embedding, padding, and transformer\n",
        "        encoder with causal masking to produce contextual representations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : Dict[str, torch.Tensor]\n",
        "            Input dictionary containing:\n",
        "            - 'item_id': Flattened item indices, shape (total_elements,)\n",
        "            - 'positions': Positional indices [0, 1, 2, ...], shape (total_elements,)\n",
        "            - 'lengths': Sequence lengths, shape (batch_size,)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict[str, torch.Tensor]\n",
        "            Output dictionary containing:\n",
        "            - 'encoder_output': Valid (non-padded) encoder representations,\n",
        "              shape (total_elements, embedding_dim)\n",
        "\n",
        "        Processing Steps\n",
        "        ----------------\n",
        "        1. Embed items and positions\n",
        "        2. Add position embeddings to item embeddings\n",
        "        3. Convert to padded format with mask\n",
        "        4. Create causal mask for autoregressive attention\n",
        "        5. Pass through transformer encoder with causal and padding masks\n",
        "        6. Extract only valid positions using mask\n",
        "        \"\"\"\n",
        "        lengths = inputs['lengths'] # (B, )\n",
        "        item_id = inputs[\"item_id\"].long()   # all histories glued together\n",
        "        pos_id  = inputs[\"positions\"].long() # (total_elements,)\n",
        "\n",
        "        embeddings = self.item_embeddings(item_id)  # TODO: your code here\n",
        "        position_embeddings = self.position_embeddings(pos_id)  # TODO: your code here\n",
        "        embeddings = embeddings + position_embeddings  # (batch_size, seq_len, embedding_dim) step 2\n",
        "\n",
        "        embeddings, mask = create_masked_tensor(\n",
        "            data=embeddings, lengths=lengths\n",
        "        )  # (batch_size, seq_len, embedding_dim), (batch_size, seq_len)\n",
        "\n",
        "        B, L, D = embeddings.shape\n",
        "        device = embeddings.device\n",
        "\n",
        "        # step 4  causal mask\n",
        "        causal_mask = torch.triu(torch.ones(L, L, device=device, dtype=torch.bool), diagonal=1)\n",
        "\n",
        "        # step 5 padding mask\n",
        "        key_padding_mask = ~mask\n",
        "\n",
        "        out = self.transformer_encoder(\n",
        "            embeddings,\n",
        "            mask=causal_mask,\n",
        "            src_key_padding_mask=key_padding_mask\n",
        "        )\n",
        "\n",
        "        encoder_output = out[mask]  # (sum(lengths), D)\n",
        "\n",
        "        return {\n",
        "            'encoder_output': encoder_output\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Cf4ueb6WfjjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d63aa1f5-587a-412d-de08-4e2fdc808f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_sasrec_backbone: OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def test_sasrec_backbone():\n",
        "    model = SASRecBackbone(num_items=1000, embedding_dim=32, num_heads=2)\n",
        "    model.eval()\n",
        "\n",
        "    assert model.item_embeddings.num_embeddings == 1000, 'Wrong shape item_embeddings'\n",
        "    assert model.item_embeddings.embedding_dim == 32, 'Wrong shape of embeddings'\n",
        "\n",
        "    inputs = {\n",
        "        'item_id': torch.tensor([1, 2, 3, 4, 5]),\n",
        "        'positions': torch.tensor([0, 1, 2, 0, 1]),\n",
        "        'lengths': torch.tensor([3, 2])\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(inputs)\n",
        "\n",
        "    assert output['encoder_output'].shape == (5, 32), \\\n",
        "        f'Wrong shape: {output['encoder_output'].shape}'\n",
        "    assert not torch.isnan(output['encoder_output']).any(), 'Output contains NaN'\n",
        "\n",
        "    print('âœ… test_sasrec_backbone: OK')\n",
        "\n",
        "\n",
        "test_sasrec_backbone()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv273oFrfjjX"
      },
      "source": [
        "5ï¸âƒ£ Implement the SASRecModel class, which combines the backbone with training and evaluation logic.\n",
        "\n",
        "The model must support two modes:\n",
        "\n",
        "1) Training mode (`self.training == True`):\n",
        "   - Pass user histories through the backbone encoder\n",
        "   - Call compute_loss to compute the objective (weâ€™ll implement it later)\n",
        "   - Return a dictionary with key 'loss'\n",
        "\n",
        "2) Validation/Test mode (`self.training == False`):\n",
        "   - Pass user histories through the backbone encoder\n",
        "   - Use get_last() to extract the last representation for each user\n",
        "   - Extract the target (positive) item for each user\n",
        "   - Compute relevance scores for all catalog items\n",
        "   - Compute the score for the target item separately\n",
        "   - Return both types of scores in a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "sy3n8LNQfjjX"
      },
      "outputs": [],
      "source": [
        "class SASRecModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Complete SASRec recommendation model combining backbone encoder with training and inference logic.\n",
        "\n",
        "    This model wraps the SASRecBackbone encoder and implements two distinct forward passes:\n",
        "\n",
        "    - Training mode: processes user sequences through the backbone and computes a loss value\n",
        "      for parameter optimization.\n",
        "\n",
        "    - Evaluation mode (validation/test): uses the backbone to encode user histories,\n",
        "      then computes relevance scores for all items in the catalog. For each user,\n",
        "      the model produces scores r_i = <F^l, M_i> where F^l is the last encoder\n",
        "      output for that user and M_i is the embedding of item i.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : SASRecBackbone\n",
        "        The transformer encoder backbone that produces contextualized representations\n",
        "        from user interaction sequences.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            backbone: SASRecBackbone,\n",
        "        ) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.init_weights(0.02)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def init_weights(self, initializer_range: float) -> None:\n",
        "        \"\"\"\n",
        "        Initializes model weights using truncated normal distribution.\n",
        "\n",
        "        Strategy:\n",
        "        - Weight matrices: truncated normal with std=initializer_range\n",
        "        - LayerNorm weights: ones (identity)\n",
        "        - Biases: zeros\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        initializer_range : float\n",
        "            Standard deviation for truncated normal initialization.\n",
        "        \"\"\"\n",
        "        for key, value in self.named_parameters():\n",
        "            if 'weight' in key:\n",
        "                if 'norm' in key:\n",
        "                    nn.init.ones_(value.data)\n",
        "                else:\n",
        "                    nn.init.trunc_normal_(\n",
        "                        value.data, std=initializer_range, a=-2 * initializer_range, b=2 * initializer_range\n",
        "                    )\n",
        "            else:\n",
        "                assert 'bias' in key\n",
        "                nn.init.zeros_(value.data)\n",
        "\n",
        "    def compute_loss(self, inputs: Dict, backbone_output: Dict[str, torch.Tensor]) -> Dict:\n",
        "        # DO NOT CHANGE THIS FUNCTION HERE\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, inputs: Dict):\n",
        "        \"\"\"\n",
        "        Forward pass of the SASRec model with mode-dependent behavior.\n",
        "\n",
        "        During training: computes and returns loss.\n",
        "        During evaluation: computes and returns ranking scores for all items.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : Dict\n",
        "            Input batch dictionary with keys:\n",
        "            - 'history': encoded user sequence (processed by YambdaDataset)\n",
        "              containing 'item_id', 'positions', 'lengths'\n",
        "            - 'labels': ground truth next items\n",
        "              containing 'item_id', 'lengths'\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            - If training (self.training == True):\n",
        "              {'loss': scalar tensor}\n",
        "\n",
        "            - If evaluating (self.training == False):\n",
        "              {\n",
        "                'all_scores': (batch_size, num_items) relevance scores for all items,\n",
        "                'positive_scores': (batch_size,) scores for ground truth items\n",
        "              }\n",
        "        \"\"\"\n",
        "        backbone_outputs = self.backbone(inputs['history'])\n",
        "\n",
        "\n",
        "        if self.training:\n",
        "            # Training\n",
        "            return {\n",
        "                'loss': self.compute_loss(inputs, backbone_outputs)\n",
        "            }\n",
        "        else:\n",
        "            # Validation\n",
        "            last_embeddings = get_last(backbone_outputs['encoder_output'], inputs['history']['lengths'])  # TODO: your code here\n",
        "            last_labels = get_last(inputs['labels']['item_id'], inputs['history']['lengths'])  # TODO: your code here\n",
        "\n",
        "            last_labels_embeddings = self.backbone.item_embeddings(last_labels.long()) # TODO: your code here\n",
        "            all_item_embeddings = self.backbone.item_embeddings.weight # TODO: your code here\n",
        "\n",
        "            all_scores = last_embeddings @ all_item_embeddings.T # TODO: your code here\n",
        "            positive_score = (last_embeddings * last_labels_embeddings).sum(dim=1) # TODO: your code here\n",
        "\n",
        "            return {\n",
        "                'all_scores': all_scores,\n",
        "                'positive_scores': positive_score,\n",
        "            }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, essentially, last_embeddings are compressed representations of each user's entire history (what this user is currently interested in given everything they listened to before). And then we take dot products between these summaries and all item embeddings to rank which items best match each user."
      ],
      "metadata": {
        "id": "B1WjsBoYX9b_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "-4uGUwKqfjjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed129a2-8f0f-4488-a793-39fc1d046f0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… test_sasrec_model: OK\n"
          ]
        }
      ],
      "source": [
        "def test_sasrec_model():\n",
        "    backbone = SASRecBackbone(num_items=100, embedding_dim=32, num_heads=2)\n",
        "    model = SASRecModel(backbone)\n",
        "\n",
        "    inputs = {\n",
        "        'history': {\n",
        "            'item_id': torch.tensor([1, 2, 3, 4, 5]),\n",
        "            'positions': torch.tensor([0, 1, 2, 0, 1]),\n",
        "            'lengths': torch.tensor([3, 2])\n",
        "        },\n",
        "        'labels': {'item_id': torch.tensor([2, 3, 4, 5, 6])}\n",
        "    }\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(inputs)\n",
        "\n",
        "    assert out['all_scores'].shape == (2, 100), f'Wrong shape all_scores: {out['all_scores'].shape}'\n",
        "    assert out['positive_scores'].shape == (2,), f'Wrong shape positive_scores: {out['positive_scores'].shape}'\n",
        "    assert not torch.isnan(out['all_scores']).any(), 'all_scores contains NaN'\n",
        "\n",
        "    model.train()\n",
        "    try:\n",
        "        model(inputs)\n",
        "        assert False, 'compute_loss must throw NotImplementedError'\n",
        "    except NotImplementedError:\n",
        "        pass\n",
        "\n",
        "    print('âœ… test_sasrec_model: OK')\n",
        "\n",
        "\n",
        "test_sasrec_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTeO4wZ9fjjX"
      },
      "source": [
        "# ğŸ’» Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ SASRec'Ğ°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCAyAtDBfjjX"
      },
      "source": [
        "## ğŸ¤“ Task 3. Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ SASRec Ğ¸Ğ· ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ (1 Ğ±Ğ°Ğ»Ğ»)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dBIuDwvfjjX"
      },
      "source": [
        "Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞ¹Ñ‚Ğµ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ `SASRec` Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ `BinaryCrossEntropy` Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_UnlxuNfjjX"
      },
      "source": [
        "Ğ’ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°Ğ»Ğ¾ÑÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ BCE (Binary Cross Entropy):\n",
        "\n",
        "$$\\Large{\\mathcal{L}_{Original} = - \\sum_{S^u \\in S} \\sum_{t \\in [1, 2, \\dots, |S^u| - 1]} \\Bigg[ \\log \\sigma \\left( r_{S^u_{t+1}, t} \\right)  + \\sum_{j \\notin S^u} \\log \\left( 1 - \\sigma \\left( r_{j,t} \\right)   \\right)} \\Bigg],$$\n",
        "\n",
        "Ğ³Ğ´Ğµ $\\sigma(r_{i,t})$ - Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¾Ğ³Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ°Ğ¹Ñ‚ĞµĞ¼ $i$ Ğ±ÑƒĞ´ĞµÑ‚ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¼ Ğ² Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ $t$, Ğ° $\\sigma$ - ÑĞ¸Ğ³Ğ¼Ğ¾Ğ¸Ğ´Ğ°.\n",
        "\n",
        "$\\color{red}{\\text{ĞĞ¾ Ğ½Ğ° ÑĞ°Ğ¼Ğ¾Ğ¼ Ğ´ĞµĞ»Ğµ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ĞµĞ¹ ÑÑƒĞ¼Ğ¼Ñ‹ Ğ½ĞµÑ‚, Ğ² ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ¾Ğ´Ğ¸Ğ½ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ² Ğ½Ğ° Ğ¾Ğ´Ğ¸Ğ½ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvJmVgHNfjjX"
      },
      "outputs": [],
      "source": [
        "class SASRecReal(SASRecModel):\n",
        "    \"\"\"\n",
        "    SASRec model trained with Binary Cross-Entropy loss (negative sampling).\n",
        "\n",
        "    For each position t in a user sequence, the model learns to distinguish between:\n",
        "    - Positive: the ground-truth next item S^u_t (label = 1)\n",
        "    - Negative: a randomly sampled item from the catalog (label = 0)\n",
        "\n",
        "    The loss is computed as:\n",
        "        L = BCE(scores, labels)\n",
        "    where scores are computed as dot products between query embeddings (from backbone)\n",
        "    and item embeddings (positive and negative).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : SASRecBackbone\n",
        "        The encoder backbone that produces contextualized user representations.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - Negative sampling is done uniformly at random from the entire item catalog.\n",
        "    \"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def compute_loss_inner(cls, user_embeddings: torch.Tensor, positive_embeddings: torch.Tensor, negative_embeddings: torch.Tensor) -> torch.Tensor:\n",
        "        # TODO: your code here\n",
        "        pass\n",
        "\n",
        "    def compute_loss(self, inputs: Dict, backbone_output: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        query_embeddings = backbone_output['encoder_output']\n",
        "        positive_embeddings = self.backbone.item_embeddings(inputs['labels']['item_id'])  # (total_batch_events, embedding_dim)\n",
        "\n",
        "        random_item_ids = torch.randint(\n",
        "            low=0,\n",
        "            high=self.backbone.num_items,\n",
        "            size=(positive_embeddings.shape[0],),\n",
        "            device=positive_embeddings.device\n",
        "        )\n",
        "\n",
        "        negative_embeddings = self.backbone.item_embeddings(random_item_ids)  # (total_batch_events, embedding_dim)\n",
        "\n",
        "        return self.compute_loss_inner(query_embeddings, positive_embeddings, negative_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM26K7VhE8r-"
      },
      "outputs": [],
      "source": [
        "def test_compute_loss_inner_real():\n",
        "    user_emb = torch.tensor([[1.0, 0.0], [0.0, 1.0]])\n",
        "    pos_emb = torch.tensor([[100.0, 0.0], [0.0, 100.0]])\n",
        "    neg_emb = torch.tensor([[-100.0, 0.0], [0.0, -100.0]])\n",
        "    loss = SASRecReal.compute_loss_inner(user_emb, pos_emb, neg_emb)\n",
        "    assert loss.item() < 1e-6, f'loss must be 0, got: {loss.item():.4f}'\n",
        "\n",
        "    user_emb = torch.tensor([[1.0, 0.0], [0.0, 1.0]])\n",
        "    pos_emb = torch.tensor([[-100.0, 0.0], [0.0, -100.0]])\n",
        "    neg_emb = torch.tensor([[100.0, 0.0], [0.0, 100.0]])\n",
        "    loss = SASRecReal.compute_loss_inner(user_emb, pos_emb, neg_emb)\n",
        "    assert abs(loss.item() - 100) < 1e-3, f'loss must be roughly 100, but got: {loss.item():.4f}'\n",
        "\n",
        "    user_emb = torch.randn(1000, 16) * 0.1\n",
        "    pos_emb = torch.randn(1000, 16) * 0.1\n",
        "    neg_emb = torch.randn(1000, 16) * 0.1\n",
        "\n",
        "    loss = SASRecReal.compute_loss_inner(user_emb, pos_emb, neg_emb)\n",
        "    expected_loss = np.log(2)\n",
        "\n",
        "    # because of rand this test might crash (with a very low prob given the code is correct)\n",
        "    assert abs(loss.item() - expected_loss) < 1e-2, \\\n",
        "        f'loss must be equal to roughly {expected_loss:.3f}, but got: {loss.item():.4f}'\n",
        "\n",
        "    user_emb = torch.zeros(10, 8)\n",
        "    pos_emb = torch.zeros(10, 8)\n",
        "    neg_emb = torch.zeros(10, 8)\n",
        "\n",
        "    loss = SASRecReal.compute_loss_inner(user_emb, pos_emb, neg_emb)\n",
        "    expected_loss = np.log(2)\n",
        "    assert abs(loss.item() - expected_loss) < 1e-2, \\\n",
        "        f'loss must be equal to roughly {expected_loss:.3f}, but got: {loss.item():.4f}'\n",
        "\n",
        "    print('âœ… test_compute_loss_inner_real: OK')\n",
        "\n",
        "test_compute_loss_inner_real()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ysm8Rd5fjjX"
      },
      "source": [
        "## ğŸ˜‡ Task 4. Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ SASRec Ñ‡ĞµÑ€ĞµĞ· Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ in-batch Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ¾Ğ² (1 Ğ±Ğ°Ğ»Ğ»)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKtZq_mQfjjY"
      },
      "source": [
        "Ğ’ÑĞµ Ğ¶Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ ÑĞ¾Ñ„Ñ‚Ğ¼Ğ°ĞºÑ Ğ½Ğµ Ğ²ÑĞµĞ³Ğ´Ğ° Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğ¼ Ğ¸ Ñ€Ğ°Ğ½Ğ´Ğ¾Ğ¼Ğ½Ğ¾ ÑĞµĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹ Ğ¸Ğ· Ğ²ÑĞµĞ³Ğ¾ ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ½ĞµÑ‚Ñ€Ğ¸Ğ²Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ñ€ĞµÑˆĞ¸Ñ‚ÑŒ ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ¼Ñ‹ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ.\n",
        "\n",
        "$$\\Large{\\mathcal{L}_{\\text{in batch}} = - \\sum_{S^u \\in S} \\sum_{t \\in [1, 2, \\dots, n]}  \\Bigg[  - \\log \\left( \\frac{e^{r_{S^u_{t+1}, t}}}{e^{r_{S^u_{t+1}, t}} + \\sum_{d \\in Sample(B, k)}{e^{r_{d, t}}}} \\right) \\Bigg]},$$\n",
        "\n",
        "Ğ³Ğ´Ğµ $k$ - ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ¾Ğ², Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑĞµĞ¼Ğ¿Ğ»Ğ°, $B$ - Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ¸Ğ· Ğ²ÑĞµÑ… Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ² Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVxgmMdlfjjY"
      },
      "source": [
        "Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞ¹Ñ‚Ğµ Ğ²ĞµÑ€ÑĞ¸Ñ `SASRec`, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ in-batch negative sampling Ğ²Ğ¼ĞµÑÑ‚Ğ¾ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğ³Ğ¾ ÑĞµĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ· ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ°. Ğ­Ñ‚Ğ° ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ±Ğ¾Ğ»ĞµĞµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°, Ñ‚Ğ°Ğº ĞºĞ°Ğº Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ, ÑƒĞ¶Ğµ Ğ½Ğ°Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸ĞµÑÑ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸, Ğ¸ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ñ‘Ñ‚ Ğ»ÑƒÑ‡ÑˆĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ñ€ĞµĞ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ°Ğ¼.\n",
        "\n",
        "Ğ˜Ğ´ĞµÑ:\n",
        "Ğ’Ğ¼ĞµÑÑ‚Ğ¾ Ñ‚Ğ¾Ğ³Ğ¾ Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾ Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ°Ğ¹Ñ‚ĞµĞ¼Ñ‹ Ğ¸Ğ· Ğ²ÑĞµĞ³Ğ¾ ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ°, Ğ¼Ñ‹ Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¸Ñ… Ğ¸Ğ· Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ², ÑƒĞ¶Ğµ Ğ¿Ñ€Ğ¸ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ² Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¼ Ğ±Ğ°Ñ‚Ñ‡Ğµ (Ñ‚Ğ¾ ĞµÑÑ‚ÑŒ Ğ¸Ğ· Ñ†ĞµĞ»ĞµĞ²Ñ‹Ñ… Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ² Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ). Ğ­Ñ‚Ğ¾ Ğ´Ğ°Ñ‘Ñ‚ Ğ½Ğ°Ğ¼ \"Ñ‚Ñ€ÑƒĞ´Ğ½ĞµĞµ\" Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ñ‹ â€” Ğ¾Ğ½Ğ¸ Ğ±Ğ¾Ğ»ĞµĞµ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸ Ğ½Ğ° Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ°Ğ¹Ñ‚ĞµĞ¼Ñ‹, Ñ‡ĞµĞ¼ ÑĞ¾Ğ²ÑĞµĞ¼ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyF-pPs6fjjY"
      },
      "outputs": [],
      "source": [
        "class SASRecInBatch(SASRecModel):\n",
        "    \"\"\"\n",
        "    SASRec model trained with using in-batch negative sampling.\n",
        "\n",
        "    For each position t in a user sequence, the model learns to distinguish:\n",
        "    - Positive: the ground-truth next item S^u_t\n",
        "    - Negatives: `num_negatives` random items sampled from the given batch of target items\n",
        "\n",
        "    This formulation is equivalent to multi-class classification where the model\n",
        "    finds one positive among (1 + num_negatives) candidates.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : SASRecBackbone\n",
        "        The encoder backbone that produces contextualized user representations.\n",
        "    num_negatives : int\n",
        "        Number of negative samples per positive example.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - In-batch negatives are sampled uniformly from batch target items.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            backbone: SASRecBackbone,\n",
        "            num_negatives: int\n",
        "        ) -> None:\n",
        "        super().__init__(backbone)\n",
        "        self.num_negatives = num_negatives\n",
        "\n",
        "    @classmethod\n",
        "    def compute_loss_inner(cls, user_embeddings: torch.Tensor, positive_embeddings: torch.Tensor, negative_embeddings: torch.Tensor) -> torch.Tensor:\n",
        "        # TODO: your code here\n",
        "        pass\n",
        "\n",
        "    def compute_loss(self, inputs: Dict[str, torch.Tensor], backbone_output: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        query_embeddings = backbone_output['encoder_output']  # (total_batch_events, embedding_dim)\n",
        "        positive_embeddings = self.backbone.item_embeddings(inputs['labels']['item_id'])  # (total_batch_events, embedding_dim)\n",
        "\n",
        "        inbatch_negative_ids = torch.randint(\n",
        "            low=0,\n",
        "            high=inputs['labels']['item_id'].shape[0],\n",
        "            size=(self.num_negatives * query_embeddings.shape[0],),\n",
        "            device=positive_embeddings.device\n",
        "        )\n",
        "        inbatch_item_ids = inputs['labels']['item_id'][inbatch_negative_ids]\n",
        "\n",
        "        inbatch_negative_embeddings = self.backbone.item_embeddings(inbatch_item_ids).reshape(\n",
        "            query_embeddings.shape[0],\n",
        "            self.num_negatives,\n",
        "            query_embeddings.shape[-1]\n",
        "        )  # (total_batch_events, num_negatives, embedding_dim)\n",
        "\n",
        "        return self.compute_loss_inner(query_embeddings, positive_embeddings, inbatch_negative_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoCOCCF6IBsS"
      },
      "outputs": [],
      "source": [
        "def test_compute_loss_inner_inbatch():\n",
        "    user_emb = torch.tensor([\n",
        "        [1.0, 0.0],\n",
        "        [0.0, 1.0]\n",
        "    ])\n",
        "    pos_emb = torch.tensor([\n",
        "        [100.0, 0.0],\n",
        "        [0.0, 100.0]\n",
        "    ])\n",
        "    neg_emb = torch.tensor([\n",
        "        [[-100.0, 0.0], [0.0, -100.0], [-50.0, -50.0]],\n",
        "        [[100.0, 0.0], [-100.0, 0.0], [-50.0, -50.0]]\n",
        "    ])\n",
        "\n",
        "    loss = SASRecInBatch.compute_loss_inner(user_emb, pos_emb, neg_emb)\n",
        "    expected_loss = 0\n",
        "    assert abs(loss.item() - expected_loss) < 1e-2, \\\n",
        "        f'loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ€Ğ°Ğ²ĞµĞ½ {expected_loss:.3f}, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾: {loss.item():.4f}'\n",
        "\n",
        "    user_emb = torch.tensor([[1.0, 0.0], [0.0, 1.0]])\n",
        "    pos_emb = torch.tensor([[-100.0, 0.0], [0.0, -100.0]])\n",
        "    neg_emb = torch.tensor([\n",
        "        [[100.0, 0.0], [50.0, 0.0], [10.0, 0.0]],\n",
        "        [[0.0, 100.0], [0.0, 50.0], [0.0, 10.0]]\n",
        "    ])\n",
        "    loss = SASRecInBatch.compute_loss_inner(user_emb, pos_emb, neg_emb)\n",
        "    expected_loss = 200\n",
        "    assert abs(loss.item() - expected_loss) < 1e-2, \\\n",
        "        f'loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ€Ğ°Ğ²ĞµĞ½ {expected_loss:.3f}, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾: {loss.item():.4f}'\n",
        "\n",
        "    batch_size = 10000\n",
        "    num_negatives = 5\n",
        "    embedding_dim = 16\n",
        "\n",
        "    user_emb = torch.randn(batch_size, embedding_dim) * 0.1\n",
        "    pos_emb = torch.randn(batch_size, embedding_dim) * 0.1\n",
        "    neg_emb = torch.randn(batch_size, num_negatives, embedding_dim) * 0.1\n",
        "\n",
        "    loss = SASRecInBatch.compute_loss_inner(user_emb, pos_emb, neg_emb)\n",
        "    expected_loss = np.log(num_negatives + 1)\n",
        "\n",
        "    # Ğ¸Ğ·-Ğ·Ğ° Ñ€Ğ°Ğ½Ğ´Ğ¾Ğ¼Ğ° ÑÑ‚Ğ¾Ñ‚ Ñ‚ĞµÑÑ‚ Ğ¼Ğ¾Ğ¶ĞµÑ‚ ÑƒĞ¿Ğ°ÑÑ‚ÑŒ Ñ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ¼Ğ°Ğ»Ğ¾Ğ¹ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¿Ñ€Ğ¸ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾Ğ¼ ĞºĞ¾Ğ´Ğµ\n",
        "    assert abs(loss.item() - expected_loss) < 1e-2, \\\n",
        "        f'loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ€Ğ°Ğ²ĞµĞ½ {expected_loss:.3f}, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾: {loss.item():.4f}'\n",
        "\n",
        "    print('âœ… test_compute_loss_inner_inbatch: OK')\n",
        "\n",
        "\n",
        "test_compute_loss_inner_inbatch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrb3dln_fjjY"
      },
      "source": [
        "## ğŸ¤© Task 5. Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ SASRec Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ log-q ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ğ¸ Ğ² in-batch Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ (2 Ğ±Ğ°Ğ»Ğ»Ğ°)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB5KZ_yrfjjY"
      },
      "source": [
        "ğŸ˜¢ ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ»Ñ…Ğ¾Ğ´Ğ°: Ğ¡Ğ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ In-Batch Negative Sampling\n",
        "\n",
        "ĞŸÑ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ in-batch negative sampling Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°ÑÑ‚ÑÑ Ğ¸Ğ· Ñ†ĞµĞ»ĞµĞ²Ñ‹Ñ… Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğ°. ĞĞ´Ğ½Ğ°ĞºĞ¾ ÑÑ‚Ğ¸ Ğ°Ğ¹Ñ‚ĞµĞ¼Ñ‹ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ñ‹ Ğ½ĞµÑ€Ğ°Ğ²Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾ â€” Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ñ‹Ğµ Ğ°Ğ¹Ñ‚ĞµĞ¼Ñ‹ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°ÑÑ‚ÑÑ Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ Ñ‡Ğ°Ñ‰Ğµ, Ñ‡ĞµĞ¼ Ñ€ĞµĞ´ĞºĞ¸Ğµ (long-tail distribution). Ğ­Ñ‚Ğ¾ Ğ²Ğ²Ğ¾Ğ´Ğ¸Ñ‚ ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ: Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ²Ğ¸Ğ´Ğ¸Ñ‚ Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ñ‹Ğµ Ğ°Ğ¹Ñ‚ĞµĞ¼Ñ‹ Ñ‡Ğ°Ñ‰Ğµ ĞºĞ°Ğº Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ñ‹, Ñ‡Ñ‚Ğ¾ Ğ²Ğ»Ğ¸ÑĞµÑ‚ Ğ½Ğ° Ğ¸Ñ… Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸.\n",
        "\n",
        "ĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, ĞµÑĞ»Ğ¸ Ğ°Ğ¹Ñ‚ĞµĞ¼ A Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€ĞµĞ½ (Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°ĞµÑ‚ÑÑ), Ğ¾Ğ½ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ¿Ğ¾Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚ Ğ² Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ \"ÑĞ¸Ğ»ÑŒĞ½ĞµĞµ Ğ¾Ñ‚Ñ‚Ğ°Ğ»ĞºĞ¸Ğ²Ğ°Ñ‚ÑŒ\" ĞµĞ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ, Ğ´Ğ°Ğ¶Ğµ ĞµÑĞ»Ğ¸ ÑÑ‚Ğ¾ Ğ½Ğµ Ğ²ÑĞµĞ³Ğ´Ğ° Ğ½ÑƒĞ¶Ğ½Ğ¾. Ğ­Ñ‚Ğ¾ Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğº Ğ½ĞµĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğ¼ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼ Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ñ‹Ñ… Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ²."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3jtlmPRfjjY"
      },
      "source": [
        "â­ Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ: LogQ Correction\n",
        "\n",
        "LogQ correction ĞºĞ¾Ğ¼Ğ¿ĞµĞ½ÑĞ¸Ñ€ÑƒĞµÑ‚ ÑÑ‚Ğ¾ ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ, Ğ²Ñ‹Ñ‡Ğ¸Ñ‚Ğ°Ñ Ğ¸Ğ· ÑĞºĞ¾Ñ€Ğ° Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ° Ğ»Ğ¾Ğ³Ğ°Ñ€Ğ¸Ñ„Ğ¼ ĞµĞ³Ğ¾ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹ Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ:\n",
        "\n",
        "$$r_{i, t}^{*} = r_{i, t} - \\log(Q(i)),$$\n",
        "\n",
        "Ğ³Ğ´Ğµ $\\large{Q(i) = \\frac{\\#i}{\\#all}}$ - Ğ´Ğ¾Ğ»Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ñ Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ¼ $i$.\n",
        "\n",
        "Ğ­Ñ‚Ğ¾ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğº Ğ½ĞµÑĞ¼ĞµÑ‰Ñ‘Ğ½Ğ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ¸ÑÑ‚Ğ¸Ğ½Ğ½Ğ¾Ğ¹ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ, Ğ½ĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ Ğ¾Ñ‚ Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ°.\n",
        "\n",
        "Ğ”Ğ»Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ log-q ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ğ¸ Ğ½Ğ°Ğ¼ Ğ½Ğ°Ğ´Ğ¾ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ğ´Ğ½Ñƒ Ğ²ĞµÑ‰ÑŒ: Ğ½Ğ°Ğ´Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ¾Ğ²\n",
        "\n",
        "Ğ•ÑĞ»Ğ¸ Ğ²Ğ°Ğ¼ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞµĞ½ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ», ÑĞ¾Ğ²ĞµÑ‚ÑƒÑ Ğ¿Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ ÑÑ‚Ğ¸ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸:\n",
        "\n",
        "1. [Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations](https://research.google/pubs/sampling-bias-corrected-neural-modeling-for-large-corpus-item-recommendations/)\n",
        "1. [Correcting the LogQ Correction: Revisiting Sampled Softmax for Large-Scale Retrieval](https://arxiv.org/abs/2507.09331)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qmdiuhBfjjY"
      },
      "source": [
        "Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞ¹Ñ‚Ğµ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ in-batch negative sampling Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¿Ğ¾Ñ…Ğ¾Ğ´Ğ° LogQ correction â€” Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¾Ğ¹ Ğ´Ğ»Ñ ĞºĞ¾Ğ¼Ğ¿ĞµĞ½ÑĞ°Ñ†Ğ¸Ğ¸ ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ñ, Ğ²Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾Ğ³Ğ¾ in-batch negative sampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vYvaV5rfjjY"
      },
      "outputs": [],
      "source": [
        "def compute_item_statistics(dataset: YambdaDataset):\n",
        "    item_counts = Counter()\n",
        "    all_cnt = 0\n",
        "    idx = 0\n",
        "    while True:\n",
        "        try:\n",
        "            sample = dataset[idx]\n",
        "            for item_id in sample['labels']['item_id']:\n",
        "                item_counts[item_id] += 1\n",
        "                all_cnt += 1\n",
        "            idx += 1\n",
        "        except:\n",
        "            break\n",
        "\n",
        "    return item_counts, all_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtE783pYfjjY"
      },
      "outputs": [],
      "source": [
        "class SASRecInBatchWithLogQ(SASRecModel):\n",
        "    \"\"\"\n",
        "    SASRec with in-batch negative sampling and LogQ bias correction.\n",
        "\n",
        "    When negative samples are drawn from a batch,\n",
        "    they follow the empirical distribution of the data (popular items\n",
        "    appear more frequently), which can bias the learned embeddings.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : SASRecBackbone\n",
        "        The encoder backbone that produces contextualized user representations.\n",
        "    num_negatives : int\n",
        "        Number of negative samples per positive example (sampled from batch).\n",
        "    item_freqs : torch.Tensor\n",
        "        1D tensor of shape (num_items,) containing frequency/probability of each\n",
        "        item in the training data. Used for LogQ correction.\n",
        "        Example: item_freqs[i] = (count of item i) / (total items in dataset)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            backbone: SASRecBackbone,\n",
        "            num_negatives: int,\n",
        "            item_freqs: torch.Tensor\n",
        "        ) -> None:\n",
        "        super().__init__(backbone=backbone)\n",
        "        self.num_negatives = num_negatives\n",
        "        self.register_buffer('item_freqs', item_freqs)\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_correction(scores: torch.Tensor, freqs: torch.Tensor) -> torch.Tensor:\n",
        "        return scores - torch.log(freqs + 1e-9)\n",
        "\n",
        "    @classmethod\n",
        "    def compute_loss_inner(\n",
        "          cls,\n",
        "          user_embeddings: torch.Tensor,\n",
        "          positive_embeddings: torch.Tensor,\n",
        "          negative_embeddings: torch.Tensor,\n",
        "          negative_item_ids: torch.Tensor,\n",
        "          num_negatives: int,\n",
        "          item_freqs: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        # TODO: your code here\n",
        "        pass\n",
        "\n",
        "    def compute_loss(self, inputs: Dict[str, torch.Tensor], backbone_output: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        query_embeddings = backbone_output['encoder_output']  # (total_batch_events, embedding_dim)\n",
        "        positive_embeddings = self.backbone.item_embeddings(inputs['labels']['item_id'])  # (total_batch_events, embedding_dim)\n",
        "\n",
        "        # Ğ¡ĞµĞ¼Ğ¿Ğ»Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ñ‹ Ğ¸Ğ· Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ±Ğ°Ñ‚Ñ‡Ğ°\n",
        "        inbatch_negative_ids = torch.randint(\n",
        "            low=0,\n",
        "            high=inputs['labels']['item_id'].shape[0],\n",
        "            size=(self.num_negatives * query_embeddings.shape[0],),\n",
        "            device=positive_embeddings.device\n",
        "        )\n",
        "        inbatch_item_ids = inputs['labels']['item_id'][inbatch_negative_ids]\n",
        "\n",
        "        inbatch_negative_embeddings = self.backbone.item_embeddings(inbatch_item_ids).reshape(\n",
        "            query_embeddings.shape[0],\n",
        "            self.num_negatives,\n",
        "            query_embeddings.shape[-1]\n",
        "        )  # (total_batch_events, num_negatives, embedding_dim)\n",
        "\n",
        "        return self.compute_loss_inner(\n",
        "            query_embeddings,\n",
        "            positive_embeddings,\n",
        "            inbatch_negative_embeddings,\n",
        "            inbatch_item_ids,\n",
        "            self.num_negatives,\n",
        "            self.item_freqs\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnCv6_5YOLiz"
      },
      "outputs": [],
      "source": [
        "def test_compute_loss_inner_inbatch_logq():\n",
        "    user_emb = torch.tensor([[1.0, 0.0], [0.0, 1.0]])\n",
        "    pos_emb = torch.tensor([[100.0, 0.0], [0.0, 100.0]])\n",
        "    neg_emb = torch.tensor([\n",
        "        [[-100.0, 0.0], [0.0, -100.0], [-50.0, -50.0]],\n",
        "        [[100.0, 0.0], [-100.0, 0.0], [-50.0, -50.0]]\n",
        "    ])\n",
        "\n",
        "    num_negatives = 3\n",
        "    num_items = 100\n",
        "    item_freqs = torch.ones(num_items) * 0.01\n",
        "    negative_item_ids = torch.tensor([5, 10, 15, 20, 25, 30])\n",
        "\n",
        "    loss = SASRecInBatchWithLogQ.compute_loss_inner(\n",
        "        user_emb, pos_emb, neg_emb, negative_item_ids, num_negatives, item_freqs\n",
        "    )\n",
        "    expected_loss = 0.\n",
        "    assert abs(loss.item() - expected_loss) < 1e-2, \\\n",
        "      f'loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ€Ğ°Ğ²ĞµĞ½ {expected_loss:.3f}, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾: {loss.item():.4f}'\n",
        "\n",
        "    user_emb = torch.tensor([[1.0, 0.0], [0.0, 1.0]])\n",
        "    pos_emb = torch.tensor([[-100.0, 0.0], [0.0, -100.0]])\n",
        "    neg_emb = torch.tensor([\n",
        "        [[100.0, 0.0], [50.0, 0.0], [10.0, 0.0]],\n",
        "        [[0.0, 100.0], [0.0, 50.0], [0.0, 10.0]]\n",
        "    ])\n",
        "\n",
        "    loss = SASRecInBatchWithLogQ.compute_loss_inner(\n",
        "        user_emb, pos_emb, neg_emb, negative_item_ids, num_negatives, item_freqs\n",
        "    )\n",
        "    expected_loss = 204.6052\n",
        "    assert abs(loss.item() - expected_loss) < 1e-2, \\\n",
        "      f'loss Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ€Ğ°Ğ²ĞµĞ½ {expected_loss:.3f}, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾: {loss.item():.4f}'\n",
        "\n",
        "    print('âœ… test_compute_loss_inner_inbatch_logq: OK')\n",
        "\n",
        "\n",
        "test_compute_loss_inner_inbatch_logq()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6n7z15PfjjY"
      },
      "source": [
        "## ğŸ¯ Task 6. Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (1 Ğ±Ğ°Ğ»Ğ»)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu-60hVBfjjY"
      },
      "source": [
        "Ğ”Ğ»Ñ Ñ‚Ğ¾Ğ³Ğ¾, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ Ğ½Ğ°ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ°ÑˆĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ½Ğ°Ğ¼ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒÑÑ Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¼Ñ‹ Ñ…Ğ¾Ñ‚Ğ¸Ğ¼ ÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ½Ğ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ñ‚ĞµÑÑ‚Ğµ. Ğ’ Ñ€Ğ°Ğ¼ĞºĞ°Ñ… Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ ÑĞµĞ¼Ğ¸Ğ½Ğ°Ñ€Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸:\n",
        "\n",
        "$$\\text{HitRate@k} = \\frac{1}{|S|} \\sum_{S^u \\in S}{ \\mathbb{I} [ \\text{positive} \\in \\text{recommended}[:\\text{k}]] },$$\n",
        "\n",
        "$$\\text{DCG@k} = \\frac{1}{|S|}\\sum_{S^u \\in S}{}{\\sum_{i = 1}^{k} \\frac{\\mathbb{I} [ \\text{recommended}^u_i = \\text{positive} ] }{\\log_2(i + 1)}},$$\n",
        "\n",
        "$$\\text{Coverage@k} = \\frac{ \\bigcup_{S^u \\in S}{ \\bigcup_{i=1}^{k}{ \\text{recommended}^u_i}} }{|\\mathcal{I}|},$$\n",
        "\n",
        "Ğ³Ğ´Ğµ $\\text{positive}$ - ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞµ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ, Ğ° $\\text{recommended}$ - ÑƒĞ¿Ğ¾Ñ€ÑĞ´Ğ¾Ñ‡ĞµĞ½Ğ½Ğ°Ñ Ğ²Ñ‹Ğ´Ğ°Ñ‡Ğ°, ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ°Ğ¹Ğ´Ğ¸ÑˆĞ½Ğ¸ĞºĞ¾Ğ² ÑƒĞ¿Ğ¾Ñ€ÑĞ´Ğ¾Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾ ÑƒĞ±Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ. $\\mathcal{I}$ - Ğ²ĞµÑÑŒ ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³ Ğ°Ğ¹Ñ‚ĞµĞ¼Ğ¾Ğ².\n",
        "\n",
        "Ğ’Ğ°Ğ¶Ğ½Ğ¾ Ğ·Ğ°Ğ¼ĞµÑ‚Ğ¸Ñ‚ÑŒ, Ñ‡Ñ‚Ğ¾ Ñ‚Ğ°Ğº ĞºĞ°Ğº Ñƒ Ğ½Ğ°Ñ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ğ´Ğ¸Ğ½ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ², Ñ‚Ğ¾ Ğ´Ğ»Ñ Ğ½Ğ°ÑˆĞµĞ³Ğ¾ ÑĞ»ÑƒÑ‡Ğ°Ñ $\\text{HitRate@k} = \\text{Recall@k}$ Ğ¸ $\\text{DCG@k} = \\text{nDCG@k}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb7fEmVrfjjY"
      },
      "outputs": [],
      "source": [
        "def compute_hitrate(all_scores: torch.Tensor, positive_scores: torch.Tensor, k: int) -> List[float]:\n",
        "    \"\"\"\n",
        "    Computes Hit Rate@k for each sample in the batch.\n",
        "\n",
        "    Hit Rate measures whether the ground truth positive item appears in the top-k\n",
        "    ranked items. For each user, it's a binary metric: 1 if the positive item is\n",
        "    in top-k, 0 otherwise.\n",
        "\n",
        "    Hit Rate@k = 1 if rank(positive_item) < k, else 0\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    all_scores : torch.Tensor\n",
        "        Relevance scores for all items in the catalog, shape (batch_size, num_items).\n",
        "        Higher scores indicate higher relevance.\n",
        "    positive_scores : torch.Tensor\n",
        "        Relevance scores for the ground truth positive items (targets),\n",
        "        shape (batch_size,).\n",
        "    k : int\n",
        "        Cutoff for top-k evaluation. Typical values: 1, 5, 10, 20, 50, 100.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[float]\n",
        "        Hit Rate values for each sample in the batch, shape (batch_size,).\n",
        "        Each value is either 0.0 (miss) or 1.0 (hit).\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    pass\n",
        "\n",
        "\n",
        "def compute_dcg(all_scores: torch.Tensor, positive_scores: torch.Tensor, k: int) -> List[float]:\n",
        "    \"\"\"\n",
        "    Computes DCG@k for each sample in the batch.\n",
        "\n",
        "    DCG (Discounted Cumulative Gain) measures ranking quality with position discount.\n",
        "    For a single positive item at position p (0-indexed):\n",
        "        DCG@k = 1 / log2(p + 2) if p < k else 0\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    all_scores : torch.Tensor\n",
        "        Scores for all items, shape (batch_size, num_items).\n",
        "    positive_scores : torch.Tensor\n",
        "        Scores for the ground truth positive items, shape (batch_size,).\n",
        "    k : int\n",
        "        Cutoff for evaluation (top-k).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[float]\n",
        "        DCG@k values for each sample in the batch.\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    pass\n",
        "\n",
        "\n",
        "def compute_metrics(all_scores: torch.Tensor, positive_scores: torch.Tensor) -> Dict[str, float]:\n",
        "    return {\n",
        "        'dcg@10': compute_dcg(all_scores, positive_scores, k=10),\n",
        "        'dcg@100': compute_dcg(all_scores, positive_scores, k=100),\n",
        "        'dcg@1000': compute_dcg(all_scores, positive_scores, k=1000),\n",
        "\n",
        "        'hitrate@10': compute_hitrate(all_scores, positive_scores, k=10),\n",
        "        'hitrate@100': compute_hitrate(all_scores, positive_scores, k=100),\n",
        "        'hitrate@1000': compute_hitrate(all_scores, positive_scores, k=1000),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOdVHjr8fjjY"
      },
      "outputs": [],
      "source": [
        "def test_compute_hitrate():\n",
        "    assert compute_hitrate(torch.tensor([[0.9, 0.5]]), torch.tensor([0.9]), k=1) == [1.0]\n",
        "    assert compute_hitrate(torch.tensor([[0.9, 0.5]]), torch.tensor([0.5]), k=1) == [0.0]\n",
        "    assert compute_hitrate(torch.tensor([[0.9, 0.5]]), torch.tensor([0.5]), k=2) == [1.0]\n",
        "\n",
        "    all_scores = torch.tensor([[0.9, 0.5, 0.3], [0.9, 0.8, 0.7]])\n",
        "    positive = torch.tensor([0.9, 0.8])\n",
        "    assert compute_hitrate(all_scores, positive, k=2) == [1.0, 1.0]\n",
        "\n",
        "    print('âœ… test_compute_hitrate: OK')\n",
        "\n",
        "\n",
        "def test_compute_dcg():\n",
        "    import math\n",
        "\n",
        "    assert abs(compute_dcg(torch.tensor([[0.9, 0.5]]), torch.tensor([0.9]), k=2)[0] - 1.0) < 1e-5\n",
        "\n",
        "    expected = 1.0 / math.log2(3)\n",
        "    assert abs(compute_dcg(torch.tensor([[0.9, 0.5]]), torch.tensor([0.5]), k=2)[0] - expected) < 1e-5\n",
        "\n",
        "    assert abs(compute_dcg(torch.tensor([[0.9, 0.8, 0.5]]), torch.tensor([0.5]), k=3)[0] - 0.5) < 1e-5\n",
        "\n",
        "    assert compute_dcg(torch.tensor([[0.9, 0.8, 0.7, 0.5]]), torch.tensor([0.5]), k=2)[0] == 0.0\n",
        "\n",
        "    print('âœ… test_compute_dcg: OK')\n",
        "\n",
        "\n",
        "test_compute_hitrate()\n",
        "test_compute_dcg()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNy5CVEXfjjY"
      },
      "source": [
        "# ğŸ”¥ ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfKzTo1fjjY"
      },
      "source": [
        "## ğŸ° Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ / ÑĞ²Ğ°Ğ» Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3V_FSkPfjjY"
      },
      "outputs": [],
      "source": [
        "def evaluation(\n",
        "        dataloader: DataLoader,\n",
        "        model: SASRecModel,\n",
        "        device: str = 'cpu',\n",
        "        num_batches: Optional[int] = None\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    eval_metrics = defaultdict(list)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for idx, batch in tqdm(enumerate(dataloader)):\n",
        "        for key in batch:\n",
        "            if isinstance(batch[key], dict):\n",
        "                for sub_key in batch[key]:\n",
        "                    batch[key][sub_key] = batch[key][sub_key].to(device)\n",
        "            else:\n",
        "                assert isinstance(batch[key], torch.Tensor)\n",
        "                batch[key] = batch[key].to(device)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            model_output = model(batch)\n",
        "            batch_metrics = compute_metrics(model_output['all_scores'], model_output['positive_scores'])\n",
        "        for key, values in batch_metrics.items():\n",
        "            eval_metrics[key].extend(values)\n",
        "\n",
        "        if num_batches is not None and idx + 1 >= num_batches:\n",
        "            break\n",
        "\n",
        "    for key, values in eval_metrics.items():\n",
        "        eval_metrics[key] = np.mean(values)\n",
        "\n",
        "    return eval_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw--Hmi6fjjZ"
      },
      "source": [
        "## ğŸ” Ğ¦Ğ¸ĞºĞ» Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JMC0jMAfjjZ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(\n",
        "        train_dataloader: DataLoader,\n",
        "        valid_dataloader: DataLoader,\n",
        "        model: torch.nn.Module,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        num_epochs: int | None = None,\n",
        "        device: str = 'cpu',\n",
        "        num_valid_batches: Optional[int] = None\n",
        "    ) -> torch.nn.Module:\n",
        "    step_num = 0\n",
        "    epoch_num = 0\n",
        "\n",
        "    best_checkpoint = None\n",
        "    best_metric_name = 'dcg@1000'\n",
        "    best_metric_value = float('-inf')\n",
        "\n",
        "    while num_epochs is None or epoch_num < num_epochs:\n",
        "        print(f'Start epoch {epoch_num + 1}')\n",
        "        running_loss = []\n",
        "\n",
        "        for batch in tqdm(train_dataloader):\n",
        "            model.train()\n",
        "\n",
        "            for key in batch:\n",
        "                if isinstance(batch[key], dict):\n",
        "                    for sub_key in batch[key]:\n",
        "                        batch[key][sub_key] = batch[key][sub_key].to(device)\n",
        "                else:\n",
        "                    assert isinstance(batch[key], torch.Tensor)\n",
        "                    batch[key] = batch[key].to(device)\n",
        "\n",
        "            loss = model(batch)['loss']\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            step_num += 1\n",
        "\n",
        "            running_loss.append(loss.item())\n",
        "\n",
        "        valid_metrics = evaluation(valid_dataloader, model, device, num_valid_batches)\n",
        "\n",
        "        if best_metric_value is None or best_metric_value < valid_metrics[best_metric_name]:\n",
        "            best_metric_value = valid_metrics[best_metric_name]\n",
        "            best_checkpoint = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "        msgs = []\n",
        "        for metric_name, metrinc_value in valid_metrics.items():\n",
        "            msgs.append(f'{metric_name}: {round(metrinc_value, 5)}')\n",
        "        msg = ', '.join(msgs)\n",
        "        print(msg)\n",
        "\n",
        "        print(f'Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ»Ğ¾ÑÑ Ğ½Ğ° ÑĞ¿Ğ¾Ñ…Ğµ #{epoch_num + 1}: {round(np.mean(running_loss), 5)}')\n",
        "\n",
        "        epoch_num += 1\n",
        "\n",
        "    print('ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾!')\n",
        "\n",
        "    return best_checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn_BUqnQfjjZ"
      },
      "source": [
        "## ğŸ Ğ’ÑĞµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UanC70x9fjjZ"
      },
      "source": [
        "1ï¸âƒ£ Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-BbvO4DcAQs"
      },
      "outputs": [],
      "source": [
        "train_dataset = YambdaDataset(\n",
        "    dataframe=train_data,\n",
        "    max_seq_len=MAX_SEQ_LEN\n",
        ")\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=2,\n",
        "    prefetch_factor=4,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmmO725-cF9h"
      },
      "outputs": [],
      "source": [
        "valid_dataset = YambdaDataset(\n",
        "  dataframe=valid_data,\n",
        "  max_seq_len=MAX_SEQ_LEN\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=False,\n",
        "    num_workers=2,\n",
        "    prefetch_factor=4,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dl8ADMOfjjZ"
      },
      "outputs": [],
      "source": [
        "eval_dataset = YambdaDataset(\n",
        "    dataframe=eval_data,\n",
        "    max_seq_len=MAX_SEQ_LEN\n",
        "  )\n",
        "eval_dataloader = DataLoader(\n",
        "    dataset=eval_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=False,\n",
        "    num_workers=2,\n",
        "    prefetch_factor=4,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cupZrWKrfjjZ"
      },
      "source": [
        "2ï¸âƒ£ ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ `SASRecReal`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WZcnsmbfjjZ"
      },
      "outputs": [],
      "source": [
        "model_real = SASRecReal(\n",
        "    backbone=SASRecBackbone(\n",
        "        num_items=len(item_mapping),\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        num_heads=NUM_HEADS,\n",
        "        max_seq_len=MAX_SEQ_LEN,\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        num_transformer_layers=NUM_TRANSFORMER_LAYERS\n",
        "    )\n",
        ").to(DEVICE)\n",
        "optimizer_real = torch.optim.Adam(params=model_real.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "best_checkpoint_real = train(\n",
        "    train_dataloader=train_dataloader,\n",
        "    valid_dataloader=valid_dataloader,\n",
        "    model=model_real,\n",
        "    optimizer=optimizer_real,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2KBYEIBfjjZ"
      },
      "source": [
        "3ï¸âƒ£ ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ `SASRecInBatch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "burfluTefjjZ"
      },
      "outputs": [],
      "source": [
        "model_in_batch = SASRecInBatch(\n",
        "    backbone=SASRecBackbone(\n",
        "        num_items=len(item_mapping),\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        num_heads=NUM_HEADS,\n",
        "        max_seq_len=MAX_SEQ_LEN,\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        num_transformer_layers=NUM_TRANSFORMER_LAYERS\n",
        "    ),\n",
        "    num_negatives=TRAIN_BATCH_SIZE\n",
        ").to(DEVICE)\n",
        "optimizer_in_batch = torch.optim.Adam(params=model_in_batch.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "best_checkpoint_in_batch = train(\n",
        "    train_dataloader=train_dataloader,\n",
        "    valid_dataloader=valid_dataloader,\n",
        "    model=model_in_batch,\n",
        "    optimizer=optimizer_in_batch,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDsrrxt2fjjZ"
      },
      "source": [
        "4ï¸âƒ£ ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ `SASRecInBatchWithLogQ`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XECzSR7dfjjZ"
      },
      "outputs": [],
      "source": [
        "item_freqs = torch.zeros(len(item_mapping), dtype=torch.float32)\n",
        "\n",
        "item_statistics, num_labels = compute_item_statistics(train_dataset)\n",
        "for key, val in item_statistics.items():\n",
        "    item_freqs[key] = val / num_labels\n",
        "    assert 0 <= item_freqs[key] < 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCoWYEC9PQYM"
      },
      "outputs": [],
      "source": [
        "model_inbatch_logq = SASRecInBatchWithLogQ(\n",
        "    backbone=SASRecBackbone(\n",
        "        num_items=len(item_mapping),\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        num_heads=NUM_HEADS,\n",
        "        max_seq_len=MAX_SEQ_LEN,\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        num_transformer_layers=NUM_TRANSFORMER_LAYERS\n",
        "    ),\n",
        "    num_negatives=TRAIN_BATCH_SIZE,\n",
        "    item_freqs=item_freqs\n",
        ").to(DEVICE)\n",
        "optimizer_inbatch_logq = torch.optim.Adam(params=model_inbatch_logq.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "best_checkpoint_inbatch_logq = train(\n",
        "    train_dataloader=train_dataloader,\n",
        "    valid_dataloader=valid_dataloader,\n",
        "    model=model_inbatch_logq,\n",
        "    optimizer=optimizer_inbatch_logq,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOhXysIYfjjZ"
      },
      "source": [
        "# Task 7. ĞŸĞ¾Ğ±Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ñ€Ğ¾Ğ³Ğ¸ Ğ½Ğ° Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞµ (1 Ğ±Ğ°Ğ»Ğ»)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmJaplVefjjZ"
      },
      "source": [
        "1ï¸âƒ£ Ğ˜Ğ·Ğ¼ĞµÑ€ÑĞµĞ¼ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ° Ñ‚ĞµÑÑ‚Ğµ Ğ´Ğ»Ñ `SASRecReal`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcmJplYwfjjZ"
      },
      "outputs": [],
      "source": [
        "def test_model_real_quality():\n",
        "    model_real.load_state_dict(best_checkpoint_real)\n",
        "    eval_metrics = evaluation(valid_dataloader, model_real, device=DEVICE)\n",
        "    print(eval_metrics)\n",
        "\n",
        "    thresholds = {\n",
        "        'dcg@10': 0.0016,\n",
        "        'dcg@100': 0.006,\n",
        "        'dcg@1000': 0.021,\n",
        "        'hitrate@10': 0.0035,\n",
        "        'hitrate@100': 0.027,\n",
        "        'hitrate@1000': 0.15\n",
        "    }\n",
        "\n",
        "    for metric_name, threshold in thresholds.items():\n",
        "        actual = eval_metrics[metric_name]\n",
        "        assert actual >= threshold, \\\n",
        "            f'âŒ {metric_name}: {actual} < {threshold}'\n",
        "        print(f'âœ… {metric_name}: {actual} >= {threshold}')\n",
        "\n",
        "    print('\\nâœ… test_model_real_quality: OK')\n",
        "test_model_real_quality()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1k2dZMJfjjZ"
      },
      "source": [
        "2ï¸âƒ£ Ğ˜Ğ·Ğ¼ĞµÑ€ÑĞµĞ¼ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ° Ñ‚ĞµÑÑ‚Ğµ Ğ´Ğ»Ñ `SASRecInBatch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sdr6ZgV7fjjZ"
      },
      "outputs": [],
      "source": [
        "def test_model_in_batch_quality():\n",
        "    model_in_batch.load_state_dict(best_checkpoint_in_batch)\n",
        "    eval_metrics = evaluation(valid_dataloader, model_in_batch, device=DEVICE)\n",
        "    print(eval_metrics)\n",
        "\n",
        "    thresholds = {\n",
        "        'dcg@10': 0.007,\n",
        "        'dcg@100': 0.015,\n",
        "        'dcg@1000': 0.034,\n",
        "        'hitrate@10': 0.012,\n",
        "        'hitrate@100': 0.059,\n",
        "        'hitrate@1000': 0.23\n",
        "    }\n",
        "\n",
        "    for metric_name, threshold in thresholds.items():\n",
        "        actual = eval_metrics[metric_name]\n",
        "        assert actual >= threshold, \\\n",
        "            f'âŒ {metric_name}: {actual} < {threshold}'\n",
        "        print(f'âœ… {metric_name}: {actual} >= {threshold}')\n",
        "\n",
        "    print('\\nâœ… test_model_in_batch_quality: OK')\n",
        "\n",
        "test_model_in_batch_quality()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BivKLlo8fjjZ"
      },
      "source": [
        "3ï¸âƒ£ Ğ˜Ğ·Ğ¼ĞµÑ€ÑĞµĞ¼ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ° Ñ‚ĞµÑÑ‚Ğµ Ğ´Ğ»Ñ `SASRecInBatchWithLogq`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8fXEIydfjjZ"
      },
      "outputs": [],
      "source": [
        "def test_model_in_batch_logq_quality():\n",
        "    model_inbatch_logq.load_state_dict(best_checkpoint_inbatch_logq)\n",
        "    eval_metrics = evaluation(valid_dataloader, model_inbatch_logq, device=DEVICE)\n",
        "    print(eval_metrics)\n",
        "\n",
        "    thresholds = {\n",
        "        'dcg@10': 0.007,\n",
        "        'dcg@100': 0.015,\n",
        "        'dcg@1000': 0.035,\n",
        "        'hitrate@10': 0.013,\n",
        "        'hitrate@100': 0.059,\n",
        "        'hitrate@1000': 0.23\n",
        "    }\n",
        "\n",
        "    for metric_name, threshold in thresholds.items():\n",
        "        actual = eval_metrics[metric_name]\n",
        "        assert actual >= threshold, \\\n",
        "            f'âŒ {metric_name}: {actual} < {threshold}'\n",
        "        print(f'âœ… {metric_name}: {actual} >= {threshold}')\n",
        "\n",
        "    print('\\nâœ… test_model_in_batch_logq_quality: OK')\n",
        "\n",
        "test_model_in_batch_logq_quality()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtILpQlHfjjZ"
      },
      "source": [
        "# ğŸ§  ĞĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ñ‹\n",
        "\n",
        "Ğ¡Ñ‚Ğ°Ñ‚ÑŒĞ¸ Ğ¸Ğ· Ğ¸Ğ½Ğ´ÑƒÑÑ‚Ñ€Ğ¸Ğ¸:\n",
        "1. [PinnerFormer: Sequence Modeling for User Representation at Pinterest](https://arxiv.org/pdf/2205.04507)\n",
        "1. [Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations](https://arxiv.org/pdf/2402.17152v1)\n",
        "1. [Better Generalization with Semantic IDs: A Case Study in Ranking for Recommendations](https://arxiv.org/pdf/2306.08121)\n",
        "1. [Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations](https://research.google/pubs/sampling-bias-corrected-neural-modeling-for-large-corpus-item-recommendations/)\n",
        "1. [Correcting the LogQ Correction: Revisiting Sampled Softmax for Large-Scale Retrieval](https://arxiv.org/abs/2507.09331)\n",
        "\n",
        "\n",
        "ĞŸÑ€Ğ¾ Ñ‚Ğ¾, ĞºĞ°Ğº Ğ½Ğ°Ğ´Ğ¾ Ğ¸ Ğ½Ğµ Ğ½Ğ°Ğ´Ğ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ:\n",
        "1. [A Critical Study on Data Leakage in Recommender System Offline Evaluation](https://dl.acm.org/doi/full/10.1145/3569930)\n",
        "1. [Exploring Data Splitting Strategies for the Evaluation of Recommendation Models](https://arxiv.org/pdf/2007.13237)\n",
        "\n",
        "\n",
        "Ğ¡Ñ‚Ğ°Ñ‚ÑŒĞ¸ Ğ¸Ğ· Ğ°ĞºĞ°Ğ´ĞµĞ¼Ğ¸Ğ¸:\n",
        "1. [SASRec: Self-Attentive Sequential Recommendation](https://arxiv.org/abs/1808.09781)\n",
        "1. [BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer](https://arxiv.org/abs/1904.06690)\n",
        "1. [A Systematic Review and Replicability Study of BERT4Rec for Sequential Recommendation](https://dl.acm.org/doi/10.1145/3523227.3548487)\n",
        "1. [CL4SRec Contrastive Learning for Sequential Recommendation](https://arxiv.org/abs/2010.14395)\n",
        "1. [DuoRec: Contrastive Learning for Representation Degeneration Problem in Sequential Recommendation](https://arxiv.org/abs/2110.05730)\n",
        "\n",
        "\n",
        "ĞŸÑ€Ğ¾ Ğ¸Ğ½Ñ„Ñ€Ñƒ:\n",
        "1. [Semantic Product Search](https://dl.acm.org/doi/10.1145/3292500.3330759)\n",
        "1. [Monolith: Real Time Recommendation System With Collisionless Embedding Table](https://arxiv.org/pdf/2209.07663)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y0Fg-OPIFA2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "896906065c584429a30b87fa8ecece77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5167e8aba3041db8b3640d4ccc7bfd5",
              "IPY_MODEL_736da6a3af7947e98e6fdbddb7f65b17",
              "IPY_MODEL_5eee93bc201f449f925145b1bdcf7d7c"
            ],
            "layout": "IPY_MODEL_a5afb48f05f24900a4583449761a2a53"
          }
        },
        "a5167e8aba3041db8b3640d4ccc7bfd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af2aab6be0914eb1b44d0a09bf0d7872",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3229bd8ddc2e4e7cb0e7b600a81bf3cc",
            "value": "README.md:â€‡"
          }
        },
        "736da6a3af7947e98e6fdbddb7f65b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_244ddee70bc54ffd931684f5476895d8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33ea386224ca4cb4b8c2054c35045fa9",
            "value": 1
          }
        },
        "5eee93bc201f449f925145b1bdcf7d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bf35498384c49389384882d0424c375",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1391e50346664bd38751e34c0b3cdfcd",
            "value": "â€‡11.8k/?â€‡[00:00&lt;00:00,â€‡868kB/s]"
          }
        },
        "a5afb48f05f24900a4583449761a2a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af2aab6be0914eb1b44d0a09bf0d7872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3229bd8ddc2e4e7cb0e7b600a81bf3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "244ddee70bc54ffd931684f5476895d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "33ea386224ca4cb4b8c2054c35045fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5bf35498384c49389384882d0424c375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1391e50346664bd38751e34c0b3cdfcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45b9161d378e4bfeaa63abc5789d3619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_577f69a4d2224d88a165f8b7fdb8a457",
              "IPY_MODEL_13920066e6894dcfba5829bade837b4d",
              "IPY_MODEL_6621b53cd77c42dca7eddd84a246d41e"
            ],
            "layout": "IPY_MODEL_084eb831d4ff44518041a30e30c6ea72"
          }
        },
        "577f69a4d2224d88a165f8b7fdb8a457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb8df16bf5ce46ba87effb97a015e952",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d851d59547b941c4b8dddb953092778c",
            "value": "sequential/50m/listens.parquet:â€‡100%"
          }
        },
        "13920066e6894dcfba5829bade837b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4593be00b2824d7e92e0d027e39eee2b",
            "max": 426248769,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a16c66a5e2bf424ca1a626daad50b61c",
            "value": 426248769
          }
        },
        "6621b53cd77c42dca7eddd84a246d41e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea4579b08c94e9db5ae075d3c57f2c6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9723066ecd0a48eb96649402c01d5f8c",
            "value": "â€‡426M/426Mâ€‡[00:05&lt;00:00,â€‡162MB/s]"
          }
        },
        "084eb831d4ff44518041a30e30c6ea72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb8df16bf5ce46ba87effb97a015e952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d851d59547b941c4b8dddb953092778c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4593be00b2824d7e92e0d027e39eee2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a16c66a5e2bf424ca1a626daad50b61c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cea4579b08c94e9db5ae075d3c57f2c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9723066ecd0a48eb96649402c01d5f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebcbfa4c89a1443e83a2e61198f79fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b42b38942e444b1d976b9ad765624aed",
              "IPY_MODEL_e49cc2b11b5a4e26b5a4c742303e9185",
              "IPY_MODEL_8d0c16081f194dd4bac266720c40ba9c"
            ],
            "layout": "IPY_MODEL_fd53aa388bff4a8dbbc1d45367174510"
          }
        },
        "b42b38942e444b1d976b9ad765624aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b728c6caa51a45c2be731b2ea4cb2653",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9a2bcfac6818463babf6d1d32be88133",
            "value": "Generatingâ€‡trainâ€‡split:â€‡"
          }
        },
        "e49cc2b11b5a4e26b5a4c742303e9185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d321e2e9651f4fa6950ee2156b4a8baf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_615272daed2547449b2d64130dc6d887",
            "value": 1
          }
        },
        "8d0c16081f194dd4bac266720c40ba9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_361d40ae0a564700bf96e68ac827d117",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bea2ef05e89f4a68830f7f6fde20f07a",
            "value": "â€‡9238/0â€‡[00:16&lt;00:00,â€‡552.76â€‡examples/s]"
          }
        },
        "fd53aa388bff4a8dbbc1d45367174510": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b728c6caa51a45c2be731b2ea4cb2653": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a2bcfac6818463babf6d1d32be88133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d321e2e9651f4fa6950ee2156b4a8baf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "615272daed2547449b2d64130dc6d887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "361d40ae0a564700bf96e68ac827d117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bea2ef05e89f4a68830f7f6fde20f07a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}