# Deep Learning Tasks Repository

Welcome to my Deep Learning Tasks repository! 🚀  
This repo contains a collection of completed deep learning exercises and experiments, implemented in Jupyter Notebooks (.ipynb). Each notebook explores a different aspect of deep learning — from fundamentals to advanced architectures.  

All tasks were completed as part of the *Deep Learning course (minor: Intellectual Data Analysis)* at HSE.  
Each notebook is self-contained; imports are provided inline, and main libraries are also listed in `requirements.txt`.  

---

## 📂 Repository Structure  

├── DL1_introductory_tasks.ipynb  
├── DL2_image_classification.ipynb  
├── DL3_time_series.ipynb  
├── DL4_text_classification.ipynb  
├── requirements.txt  
└── README.md  

---

## 📑 Task Overview  

| Notebook | Topic | Key Concepts | Notes |
|----------|-------|--------------|-------|
| `DL1_introductory_tasks.ipynb` | 🔰 Introduction to Deep Learning | PyTorch basics, tensors, autograd | Introductory exercises to get familiar with PyTorch and essential DL libraries. |
| `DL2_image_classification.ipynb` | 🌱 Plant Species Classification | CNNs, custom architectures, optimization | Built and trained CNNs in PyTorch for image classification, experimented with model customization and training strategies. |
| `DL3_time_series.ipynb` | 📈 Time Series Forecasting | ETNA library, forecasting models, evaluation | Real-world case study: forecasting cash demand for ATMs. Used multi-segment daily data and ETNA toolkit to improve prediction quality — a critical task for financial institutions. |
| `DL4_text_classification.ipynb` | 📰 News & Comment Classification | NLP, text classification, Hugging Face models | Trained models to classify news articles, predicted categories for unseen items, applied sentiment analysis with Hugging Face, and built analytics on most positive/negative news/comment categories. |

---

## ⚙️ Setup & Installation  

To run the notebooks locally, you’ll need Python 3.8+ and the dependencies listed in `requirements.txt`.  

```bash
git clone https://github.com/yourusername/deep-learning-tasks.git
cd deep-learning-tasks
pip install -r requirements.txt
```

Or, open directly in Google Colab.  

---

## 🧑‍💻 Usage  

1. Launch Jupyter Notebook or Jupyter Lab:  

```bash
jupyter notebook
```

2. Open the notebook of interest (e.g., `DL1_introductory_tasks.ipynb`).  
3. Run cells step by step to explore code, results, and commentary.  

---

## 📊 Results & Visualizations  

Each notebook includes:  
 • Explanations of the approach  
 • Training/validation metrics (accuracy, loss curves)  
 • Key visualizations (e.g., confusion matrices, generated images)  
 • Reflections on results and limitations  

---

## 🛠 Dependencies  

Main libraries used across notebooks:  
 • [PyTorch](https://pytorch.org/)  
 • NumPy, Pandas  
 • Matplotlib, Seaborn  
 • scikit-learn  

See `requirements.txt` for the full list.  

---

## 🌟 Future Work  

Planned extensions:  
 • More tasks on NLP and transformers  
 • Advanced optimization and hyperparameter tuning experiments  
 • Applied case studies (healthcare, finance, etc.)  

---

## 📜 License  

This repository is released under the MIT License.  
Feel free to fork, explore, and build upon it!  

---

## 👤 Author  

Created by [Anastasiia Lapshina](https://github.com/lapshinaaa).  
Feel free to reach out via GitHub Issues if you’d like to collaborate or discuss ideas.  
